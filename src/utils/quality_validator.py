#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è³‡æ–™å“è³ªé©—è­‰å™¨
æä¾›è³‡æ–™å“è³ªæª¢æŸ¥å’Œçµ±è¨ˆåŠŸèƒ½
"""

import json
import os
from datetime import datetime
from typing import Any, Dict, List, Tuple

from .logger import logger


class QualityValidator:
    """è³‡æ–™å“è³ªé©—è­‰å™¨"""

    def __init__(self):
        self.logger = logger

    def validate_questions(self, questions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        é©—è­‰é¡Œç›®è³‡æ–™å“è³ª

        Args:
            questions: é¡Œç›®åˆ—è¡¨

        Returns:
            é©—è­‰çµæœçµ±è¨ˆ
        """
        stats = {
            "total_questions": len(questions),
            "valid_questions": 0,
            "invalid_questions": 0,
            "quality_issues": [],
            "option_statistics": {"A": 0, "B": 0, "C": 0, "D": 0, "empty": 0},
            "answer_statistics": {"A": 0, "B": 0, "C": 0, "D": 0, "empty": 0},
            "question_length_stats": {"min": 0, "max": 0, "avg": 0},
            "option_diversity_score": 0.0,
        }

        if not questions:
            return stats

        valid_count = 0
        question_lengths = []

        for i, question in enumerate(questions):
            # æª¢æŸ¥é¡Œç›®å®Œæ•´æ€§
            issues = self._check_question_quality(question, i + 1)
            if issues:
                stats["quality_issues"].extend(issues)
                stats["invalid_questions"] += 1
            else:
                valid_count += 1

            # çµ±è¨ˆé¸é …
            self._count_options(question, stats["option_statistics"])

            # çµ±è¨ˆç­”æ¡ˆ
            self._count_answers(question, stats["answer_statistics"])

            # çµ±è¨ˆé¡Œç›®é•·åº¦
            question_text = question.get("é¡Œç›®", "")
            if question_text:
                question_lengths.append(len(question_text))

        stats["valid_questions"] = valid_count

        # è¨ˆç®—é¡Œç›®é•·åº¦çµ±è¨ˆ
        if question_lengths:
            stats["question_length_stats"] = {
                "min": min(question_lengths),
                "max": max(question_lengths),
                "avg": sum(question_lengths) / len(question_lengths),
            }

        # è¨ˆç®—é¸é …å¤šæ¨£æ€§åˆ†æ•¸
        stats["option_diversity_score"] = self._calculate_diversity_score(stats["option_statistics"])

        return stats

    def _check_question_quality(self, question: Dict[str, Any], question_num: int) -> List[str]:
        """æª¢æŸ¥å–®å€‹é¡Œç›®çš„å“è³ª"""
        issues = []

        # æª¢æŸ¥å¿…è¦æ¬„ä½
        required_fields = ["é¡Œè™Ÿ", "é¡Œç›®", "é¸é …A", "é¸é …B", "é¸é …C", "é¸é …D"]
        for field in required_fields:
            value = question.get(field, "")
            if value is None or (isinstance(value, str) and not value.strip()):
                issues.append(f"ç¬¬{question_num}é¡Œç¼ºå°‘{field}")

        # æª¢æŸ¥é¡Œç›®é•·åº¦
        question_text = question.get("é¡Œç›®", "")
        if len(question_text) < 10:
            issues.append(f"ç¬¬{question_num}é¡Œé¡Œç›®éçŸ­")
        elif len(question_text) > 1000:
            issues.append(f"ç¬¬{question_num}é¡Œé¡Œç›®éé•·")

        # æª¢æŸ¥é¸é …æ•¸é‡
        option_count = sum(1 for opt in ["A", "B", "C", "D"] if question.get(f"é¸é …{opt}", "").strip())
        if option_count < 2:
            issues.append(f"ç¬¬{question_num}é¡Œé¸é …ä¸è¶³ï¼ˆåªæœ‰{option_count}å€‹ï¼‰")

        # æª¢æŸ¥é¸é …é‡è¤‡
        options = [
            question.get(f"é¸é …{opt}", "").strip()
            for opt in ["A", "B", "C", "D"]
            if question.get(f"é¸é …{opt}", "").strip()
        ]
        if len(options) != len(set(options)):
            issues.append(f"ç¬¬{question_num}é¡Œæœ‰é‡è¤‡é¸é …")

        # æª¢æŸ¥ç­”æ¡ˆæ ¼å¼
        answer = question.get("æœ€çµ‚ç­”æ¡ˆ", "") or question.get("æ­£ç¢ºç­”æ¡ˆ", "")
        if answer and answer not in ["A", "B", "C", "D"]:
            issues.append(f"ç¬¬{question_num}é¡Œç­”æ¡ˆæ ¼å¼ä¸æ­£ç¢º: {answer}")

        return issues

    def _count_options(self, question: Dict[str, Any], stats: Dict[str, int]):
        """çµ±è¨ˆé¸é …"""
        for opt in ["A", "B", "C", "D"]:
            option_text = question.get(f"é¸é …{opt}", "").strip()
            if option_text:
                stats[opt] += 1
            else:
                stats["empty"] += 1

    def _count_answers(self, question: Dict[str, Any], stats: Dict[str, int]):
        """çµ±è¨ˆç­”æ¡ˆ"""
        answer = question.get("æœ€çµ‚ç­”æ¡ˆ", "") or question.get("æ­£ç¢ºç­”æ¡ˆ", "")
        if answer in ["A", "B", "C", "D"]:
            stats[answer] += 1
        else:
            stats["empty"] += 1

    def _calculate_diversity_score(self, option_stats: Dict[str, int]) -> float:
        """è¨ˆç®—é¸é …å¤šæ¨£æ€§åˆ†æ•¸"""
        total_options = sum(option_stats.values()) - option_stats["empty"]
        if total_options == 0:
            return 0.0

        # è¨ˆç®—å„é¸é …çš„åˆ†å¸ƒå‡å‹»åº¦
        option_counts = [option_stats[opt] for opt in ["A", "B", "C", "D"]]
        max_count = max(option_counts)
        min_count = min(option_counts)

        if max_count == 0:
            return 0.0

        # å¤šæ¨£æ€§åˆ†æ•¸ = 1 - (æœ€å¤§å·®ç•° / ç¸½æ•¸)
        diversity = 1 - (max_count - min_count) / total_options
        return round(diversity, 3)

    def generate_quality_report(self, stats: Dict[str, Any], output_path: str = None) -> str:
        """ç”Ÿæˆå“è³ªå ±å‘Š"""
        if not output_path:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            reports_dir = "reports"
            os.makedirs(reports_dir, exist_ok=True)
            output_path = os.path.join(reports_dir, f"è³‡æ–™å“è³ªå ±å‘Š_{timestamp}.md")

        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        output_dir = os.path.dirname(output_path)
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)

        with open(output_path, "w", encoding="utf-8") as f:
            f.write("# è³‡æ–™å“è³ªé©—è­‰å ±å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ™‚é–“**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n\n")

            # åŸºæœ¬çµ±è¨ˆ
            f.write("## ğŸ“Š åŸºæœ¬çµ±è¨ˆ\n\n")
            f.write(f"- **ç¸½é¡Œæ•¸**: {stats['total_questions']}\n")
            f.write(f"- **æœ‰æ•ˆé¡Œæ•¸**: {stats['valid_questions']}\n")
            f.write(f"- **ç„¡æ•ˆé¡Œæ•¸**: {stats['invalid_questions']}\n")
            # é¿å…é™¤é›¶éŒ¯èª¤
            valid_rate = (
                stats["valid_questions"] / stats["total_questions"] * 100 if stats["total_questions"] > 0 else 0
            )
            f.write(f"- **æœ‰æ•ˆç‡**: {valid_rate:.1f}%\n\n")

            # é¸é …çµ±è¨ˆ
            f.write("## ğŸ”¤ é¸é …çµ±è¨ˆ\n\n")
            f.write("| é¸é … | æ•¸é‡ | æ¯”ä¾‹ |\n")
            f.write("|------|------|------|\n")
            total_options = sum(stats["option_statistics"].values()) - stats["option_statistics"]["empty"]
            for opt in ["A", "B", "C", "D"]:
                count = stats["option_statistics"][opt]
                percentage = count / total_options * 100 if total_options > 0 else 0
                f.write(f"| {opt} | {count} | {percentage:.1f}% |\n")
            f.write(f"| ç©ºç™½ | {stats['option_statistics']['empty']} | - |\n\n")

            # ç­”æ¡ˆçµ±è¨ˆ
            f.write("## âœ… ç­”æ¡ˆçµ±è¨ˆ\n\n")
            f.write("| ç­”æ¡ˆ | æ•¸é‡ | æ¯”ä¾‹ |\n")
            f.write("|------|------|------|\n")
            total_answers = sum(stats["answer_statistics"].values()) - stats["answer_statistics"]["empty"]
            for ans in ["A", "B", "C", "D"]:
                count = stats["answer_statistics"][ans]
                percentage = count / total_answers * 100 if total_answers > 0 else 0
                f.write(f"| {ans} | {count} | {percentage:.1f}% |\n")
            f.write(f"| ç©ºç™½ | {stats['answer_statistics']['empty']} | - |\n\n")

            # é¡Œç›®é•·åº¦çµ±è¨ˆ
            f.write("## ğŸ“ é¡Œç›®é•·åº¦çµ±è¨ˆ\n\n")
            length_stats = stats["question_length_stats"]
            f.write(f"- **æœ€çŸ­**: {length_stats['min']} å­—å…ƒ\n")
            f.write(f"- **æœ€é•·**: {length_stats['max']} å­—å…ƒ\n")
            f.write(f"- **å¹³å‡**: {length_stats['avg']:.1f} å­—å…ƒ\n\n")

            # å“è³ªåˆ†æ•¸
            f.write("## ğŸ¯ å“è³ªåˆ†æ•¸\n\n")
            f.write(f"- **é¸é …å¤šæ¨£æ€§åˆ†æ•¸**: {stats['option_diversity_score']:.3f}\n")
            f.write(f"- **è³‡æ–™å®Œæ•´æ€§**: {stats['valid_questions']/stats['total_questions']*100:.1f}%\n\n")

            # å“è³ªå•é¡Œ
            if stats["quality_issues"]:
                f.write("## âš ï¸ å“è³ªå•é¡Œ\n\n")
                for issue in stats["quality_issues"]:
                    f.write(f"- {issue}\n")
                f.write("\n")
            else:
                f.write("## âœ… å“è³ªç‹€æ³\n\n")
                f.write("æœªç™¼ç¾å“è³ªå•é¡Œï¼Œè³‡æ–™å“è³ªè‰¯å¥½ï¼\n\n")

            # å»ºè­°
            f.write("## ğŸ’¡ æ”¹é€²å»ºè­°\n\n")
            if stats["option_diversity_score"] < 0.7:
                f.write("- é¸é …å¤šæ¨£æ€§è¼ƒä½ï¼Œå»ºè­°æª¢æŸ¥é¸é …ç”Ÿæˆé‚è¼¯\n")
            if stats["valid_questions"] / stats["total_questions"] < 0.9:
                f.write("- è³‡æ–™å®Œæ•´æ€§ä¸è¶³ï¼Œå»ºè­°æª¢æŸ¥é¡Œç›®è§£æé‚è¼¯\n")
            if stats["answer_statistics"]["empty"] > stats["total_questions"] * 0.1:
                f.write("- ç­”æ¡ˆç¼ºå¤±è¼ƒå¤šï¼Œå»ºè­°æª¢æŸ¥ç­”æ¡ˆæå–é‚è¼¯\n")

            if not any(
                [
                    stats["option_diversity_score"] < 0.7,
                    stats["valid_questions"] / stats["total_questions"] < 0.9,
                    stats["answer_statistics"]["empty"] > stats["total_questions"] * 0.1,
                ]
            ):
                f.write("- è³‡æ–™å“è³ªè‰¯å¥½ï¼Œç„¡éœ€ç‰¹åˆ¥æ”¹é€²\n")

        self.logger.success(f"å“è³ªå ±å‘Šå·²ç”Ÿæˆ: {output_path}")
        return output_path
