import os
import pdfplumber
import pandas as pd
import re
import json
import hashlib
from typing import List, Dict, Any, Optional, Tuple
import glob
from datetime import datetime, timedelta
from google import genai
from google.generativeai.client import configure
from google.generativeai.generative_models import GenerativeModel
from google.generativeai.files import upload_file, get_file
import time

class PDFCacheManager:
    """PDFå¿«å–ç®¡ç†å™¨"""
    def __init__(self, cache_file: str = "pdf_cache.json"):
        self.cache_file = cache_file
        self.cache = self.load_cache()
        self.client: Optional[genai.Client] = None

    def load_cache(self) -> Dict[str, Any]:
        if os.path.exists(self.cache_file):
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                return {}
        return {}

    def save_cache(self):
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
        except:
            pass

    def get_pdf_hash(self, pdf_path: str) -> str:
        sha256_hash = hashlib.sha256()
        with open(pdf_path, "rb") as f:
            for byte_block in iter(lambda: f.read(4096), b""):
                sha256_hash.update(byte_block)
        return sha256_hash.hexdigest()

    def get_cached_result(self, pdf_hash: str) -> Optional[Dict[str, Any]]:
        if pdf_hash in self.cache:
            cache_entry = self.cache[pdf_hash]
            cached_time = datetime.fromisoformat(cache_entry.get('timestamp', '2000-01-01'))
            if datetime.now() - cached_time < timedelta(days=7):
                print(f"âœ… ä½¿ç”¨å¿«å–çµæœ")
                return cache_entry.get('result')
        return None

    def set_cached_result(self, pdf_hash: str, result: Dict[str, Any]):
        self.cache[pdf_hash] = {
            'result': result,
            'timestamp': datetime.now().isoformat()
        }
        self.save_cache()

    def cleanup_expired_cache(self):
        expired = [k for k, v in self.cache.items() 
                  if datetime.now() - datetime.fromisoformat(v.get('timestamp', '2000-01-01')) >= timedelta(days=7)]
        for k in expired:
            del self.cache[k]
        if expired:
            self.save_cache()

class PDFFeatureAnalyzer:
    @staticmethod
    def analyze_pdf(pdf_path: str) -> Dict[str, Any]:
        features = {
            'page_count': 0,
            'file_size_mb': 0.0,
            'expected_question_count': None
        }

        try:
            features['file_size_mb'] = os.path.getsize(pdf_path) / (1024 * 1024)

            with pdfplumber.open(pdf_path) as pdf:
                features['page_count'] = len(pdf.pages)
                full_text = ""
                for page in pdf.pages:
                    text = page.extract_text()
                    if text:
                        full_text += text + "\n"

                # æå–é æœŸé¡Œæ•¸
                count_match = re.search(r'å…±\s*(\d+)\s*é¡Œ', full_text)
                if count_match:
                    features['expected_question_count'] = int(count_match.group(1))
        except:
            pass

        return features

class ValidationResult:
    def __init__(self):
        self.status = 'success'
        self.issues = []
        self.warnings = []
        self.summary = {}

    def add_issue(self, message: str):
        self.issues.append(message)
        self.status = 'error'

    def add_warning(self, message: str):
        self.warnings.append(message)
        if self.status == 'success':
            self.status = 'warning'

    def print_result(self):
        icons = {'success': 'âœ…', 'warning': 'âš ï¸', 'error': 'âŒ'}
        print(f"\n{icons.get(self.status, 'â“')} é©—è­‰çµæœ:")

        for key, value in self.summary.items():
            print(f"   {key}: {value}")

        if self.issues:
            print(f"   åš´é‡å•é¡Œ:")
            for issue in self.issues:
                print(f"     âŒ {issue}")

        if self.warnings:
            print(f"   è­¦å‘Š:")
            for warning in self.warnings[:3]:
                print(f"     âš ï¸ {warning}")

cache_manager = PDFCacheManager()

def setup_gemini_api(api_key: str):
    configure(api_key=api_key)
    cache_manager.client = genai.Client(api_key=api_key)

# ============ æ–°å¢ï¼šæª”æ¡ˆéæ¿¾åŠŸèƒ½ ============
def should_skip_file(filename: str) -> bool:
    """åˆ¤æ–·æ˜¯å¦æ‡‰è©²è·³éæ­¤æª”æ¡ˆ"""
    # ç­”æ¡ˆæª”æ¡ˆé—œéµå­—
    skip_keywords = ['ç­”æ¡ˆ', 'è§£ç­”', 'æ›´æ­£ç­”æ¡ˆ', 'answer', 'Answer', 'ANSWER']

    # æª¢æŸ¥æª”åæ˜¯å¦åŒ…å«è·³éé—œéµå­—
    for keyword in skip_keywords:
        if keyword in filename:
            return True
    return False

def is_answer_file(pdf_path: str) -> bool:
    """æª¢æ¸¬PDFæ˜¯å¦ç‚ºç­”æ¡ˆæª”æ¡ˆï¼ˆé€šéå…§å®¹åˆ†æï¼‰"""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            # åªæª¢æŸ¥ç¬¬ä¸€é 
            if len(pdf.pages) > 0:
                text = pdf.pages[0].extract_text()
                if text:
                    # ç­”æ¡ˆæª”æ¡ˆçš„ç‰¹å¾µï¼š
                    # 1. åŒ…å«å¤§é‡çš„ (A) (B) (C) (D) æ ¼å¼
                    # 2. è¡Œæ•¸å¾ˆå°‘ï¼ˆé€šå¸¸1é 25é¡Œï¼‰
                    # 3. æ²’æœ‰é•·æ–‡å­—æ®µè½

                    lines = text.split('\n')
                    short_lines = [l for l in lines if len(l.strip()) < 20]

                    # å¦‚æœè¶…é80%çš„è¡Œéƒ½å¾ˆçŸ­ï¼Œå¾ˆå¯èƒ½æ˜¯ç­”æ¡ˆå·
                    if len(short_lines) / max(len(lines), 1) > 0.8:
                        # æª¢æŸ¥æ˜¯å¦æœ‰å¤§é‡æ‹¬è™Ÿé¸é …
                        option_pattern = r'\([A-D]\)'
                        option_count = len(re.findall(option_pattern, text))

                        # å¦‚æœæœ‰10å€‹ä»¥ä¸Šçš„é¸é …æ¨™è¨˜ï¼Œå¾ˆå¯èƒ½æ˜¯ç­”æ¡ˆå·
                        if option_count >= 10:
                            return True
    except:
        pass

    return False
# ============================================

def extract_text_from_pdf(pdf_path: str) -> str:
    try:
        with pdfplumber.open(pdf_path) as pdf:
            text = ""
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
        return text
    except:
        return ""

def upload_pdf_to_gemini(pdf_path: str) -> Optional[str]:
    if cache_manager.client is None:
        print("âŒ Gemini client æœªåˆå§‹åŒ–")
        return None

    try:
        print(f"ğŸ“¤ ä¸Šå‚³PDFåˆ°Gemini...")

        sample_file = upload_file(pdf_path, mime_type='application/pdf')

        print(f"â³ ç­‰å¾…è™•ç†...")
        max_wait = 60
        wait_time = 0

        while sample_file.state.name == "PROCESSING" and wait_time < max_wait:
            time.sleep(2)
            wait_time += 2
            sample_file = get_file(sample_file.name)

        if sample_file.state.name == "FAILED":
            return None

        print(f"âœ… ä¸Šå‚³æˆåŠŸ")
        return sample_file.uri
    except Exception as e:
        print(f"âŒ ä¸Šå‚³å¤±æ•—: {e}")
        return None

def parse_with_pdf_upload(pdf_path: str, use_pro: bool = False) -> List[Dict[str, Any]]:
    try:
        file_uri = upload_pdf_to_gemini(pdf_path)
        if not file_uri:
            return []

        sample_file = get_file(file_uri.split('/')[-1])

        # é¸æ“‡æ¨¡å‹ï¼šå„ªå…ˆä½¿ç”¨ Flashï¼Œå¤±æ•—æ™‚å¯åˆ‡æ›åˆ° Pro
        model_name = 'gemini-2.5-pro' if use_pro else 'gemini-2.5-flash'
        model = GenerativeModel(model_name)

        # å¾PDFè·¯å¾‘æå–é æœŸé¡Œæ•¸ï¼Œç”¨æ–¼æ›´ç²¾ç¢ºçš„è§£æ
        pdf_features = PDFFeatureAnalyzer.analyze_pdf(pdf_path)
        expected_count = pdf_features.get('expected_question_count', 0)

        if use_pro:
            print(f"ğŸ”„ ä½¿ç”¨ Gemini 2.5 Pro é‡æ–°è§£æ...")

        prompt = f"""åˆ†æé€™ä»½PDFè€ƒå¤é¡Œï¼Œç²¾ç¢ºæå–æ‰€æœ‰è©¦é¡Œï¼š

é æœŸé¡Œæ•¸ï¼š{expected_count}é¡Œ

å¦‚æœé€™æ˜¯ç­”æ¡ˆå·ï¼ˆåªæœ‰é¡Œè™Ÿå’Œç­”æ¡ˆé¸é …ï¼‰ï¼Œè¿”å› []

å¦å‰‡è¿”å›JSONæ ¼å¼ï¼š
[{{"é¡Œè™Ÿ": "1", "é¡Œç›®": "å®Œæ•´é¡Œç›®å…§å®¹", "é¸é …A": "...", "é¸é …B": "...", "é¸é …C": "...", "é¸é …D": "...", "é¡Œå‹": "é¸æ“‡é¡Œ"}}]

é‡è¦è¦å‰‡ï¼š
1. ç­”æ¡ˆå·ç›´æ¥è¿”å› []
2. é¡Œè™Ÿå¿…é ˆå¾1é–‹å§‹ï¼Œé€£çºŒç·¨è™Ÿåˆ°{expected_count}
3. é¡Œç›®å…§å®¹å¿…é ˆå®Œæ•´ï¼Œè‡³å°‘15å­—
4. é¸æ“‡é¡Œå¿…é ˆæœ‰Aã€Bã€Cã€Då››å€‹é¸é …
5. ç¸½é¡Œæ•¸å¿…é ˆç‚º{expected_count}é¡Œï¼Œçµ•å°ä¸èƒ½å¤šä¹Ÿä¸èƒ½å°‘
6. ä¸è¦å°‡é é¦–ã€é å°¾ã€èªªæ˜ã€è¨»è§£èª¤èªç‚ºé¡Œç›®
7. ä»”ç´°æª¢æŸ¥æ¯ä¸€é¡Œçš„å®Œæ•´æ€§"""

        response = model.generate_content([sample_file, prompt])
        text = response.text.strip()

        # è™•ç†ç©ºè¿”å›ï¼ˆç­”æ¡ˆå·ï¼‰
        if text == '[]' or text == '[ ]':
            print("âœ“ æª¢æ¸¬åˆ°ç­”æ¡ˆå·ï¼Œè·³é")
            return []

        if text.startswith('```json'):
            text = text[7:]
        if text.startswith('```'):
            text = text[3:]
        if text.endswith('```'):
            text = text[:-3]

        questions = json.loads(text.strip())

        # éæ¿¾å’Œé©—è­‰é¡Œç›®
        validated = []
        seen_numbers = set()

        for q in questions:
            if isinstance(q, dict) and 'é¡Œè™Ÿ' in q and 'é¡Œç›®' in q:
                # æª¢æŸ¥é¡Œè™Ÿæ˜¯å¦ç‚ºæ•¸å­—ä¸”ä¸é‡è¤‡
                try:
                    num = int(str(q.get('é¡Œè™Ÿ', '')).strip())
                    if num in seen_numbers:
                        continue  # è·³éé‡è¤‡é¡Œè™Ÿ
                    seen_numbers.add(num)
                except:
                    continue  # é¡Œè™Ÿç„¡æ•ˆè·³é

                # æª¢æŸ¥é¡Œç›®å…§å®¹é•·åº¦
                title = str(q.get('é¡Œç›®', '')).strip()
                if len(title) < 15:  # æ”¾å¯¬åˆ°15å­—
                    continue  # é¡Œç›®å¤ªçŸ­è·³é

                validated.append({
                    'é¡Œè™Ÿ': str(num),
                    'é¡Œç›®': title,
                    'é¸é …A': str(q.get('é¸é …A', '')),
                    'é¸é …B': str(q.get('é¸é …B', '')),
                    'é¸é …C': str(q.get('é¸é …C', '')),
                    'é¸é …D': str(q.get('é¸é …D', '')),
                    'é¡Œå‹': str(q.get('é¡Œå‹', 'é¸æ“‡é¡Œ'))
                })

        # å¦‚æœè§£æå‡ºçš„é¡Œæ•¸æ˜é¡¯åé›¢é æœŸï¼Œå˜—è©¦ä¿®æ­£
        if expected_count and abs(len(validated) - expected_count) > 2:  # ç¸®å°å·®è·é–¾å€¼
            print(f"âš ï¸ è§£æé¡Œæ•¸({len(validated)})èˆ‡é æœŸ({expected_count})å·®è·éå¤§ï¼Œå¯èƒ½æœ‰èª¤")
            # å°æ–¼Proæ¨¡å‹ï¼Œå¦‚æœå·®è·ä¸å¤§ï¼Œå˜—è©¦æ™ºèƒ½ä¿®æ­£
            if use_pro and abs(len(validated) - expected_count) <= 5:
                if len(validated) > expected_count:
                    validated = validated[:expected_count]
                elif len(validated) < expected_count:
                    # è£œå……ç¼ºå¤±çš„é¡Œè™Ÿï¼ˆå¦‚æœæœ‰è·³è™Ÿï¼‰
                    existing_nums = sorted([int(q['é¡Œè™Ÿ']) for q in validated])
                    missing_nums = []
                    for i in range(1, expected_count + 1):
                        if i not in existing_nums:
                            missing_nums.append(i)
                    print(f"  ç™¼ç¾ç¼ºå¤±é¡Œè™Ÿ: {missing_nums}")

        print(f"âœ… è§£ææˆåŠŸï¼Œæ‰¾åˆ° {len(validated)} é¡Œ")
        return validated
    except Exception as e:
        print(f"âŒ è§£æå¤±æ•—: {e}")
        return []

def parse_questions_with_text_gemini(text: str, expected_count: int = 0) -> List[Dict[str, Any]]:
    try:
        # ä½¿ç”¨ Gemini 2.5 Flash
        model = GenerativeModel('gemini-2.5-flash')

        prompt = f"""åˆ†æä»¥ä¸‹è€ƒå¤é¡Œæ–‡å­—ï¼Œå¦‚æœæ˜¯ç­”æ¡ˆå·è¿”å›[]ï¼Œå¦‚æœæ˜¯è©¦é¡Œè«‹ç²¾ç¢ºæå–æ‰€æœ‰é¡Œç›®ã€‚

é æœŸé¡Œæ•¸ï¼š{expected_count}é¡Œ

è«‹è¿”å›JSONæ ¼å¼ï¼š
[{{"é¡Œè™Ÿ": "1", "é¡Œç›®": "å®Œæ•´é¡Œç›®å…§å®¹è‡³å°‘20å­—", "é¸é …A": "...", "é¸é …B": "...", "é¸é …C": "...", "é¸é …D": "...", "é¡Œå‹": "é¸æ“‡é¡Œ"}}]

é‡è¦è¦å‰‡ï¼š
1. ç­”æ¡ˆå·ç›´æ¥è¿”å› []
2. é¡Œè™Ÿå¿…é ˆå¾1é–‹å§‹é€£çºŒç·¨è™Ÿ
3. é¡Œç›®å…§å®¹å¿…é ˆå®Œæ•´ï¼Œè‡³å°‘20å­—
4. é¸æ“‡é¡Œå¿…é ˆæœ‰Aã€Bã€Cã€Då››å€‹é¸é …
5. ç¸½é¡Œæ•¸æ‡‰ç‚º{expected_count}é¡Œï¼Œå‹¿å¤šå‹¿å°‘
6. ä¸è¦å°‡é é¦–ã€é å°¾ã€èªªæ˜æ–‡å­—èª¤èªç‚ºé¡Œç›®

æ–‡å­—å…§å®¹ï¼š
{text[:15000]}"""

        response = model.generate_content(prompt)
        text = response.text.strip()

        if text == '[]':
            return []

        if text.startswith('```json'):
            text = text[7:]
        if text.startswith('```'):
            text = text[3:]
        if text.endswith('```'):
            text = text[:-3]

        questions = json.loads(text.strip())

        # éæ¿¾å’Œé©—è­‰é¡Œç›®
        validated = []
        seen_numbers = set()

        for q in questions:
            if isinstance(q, dict) and 'é¡Œè™Ÿ' in q and 'é¡Œç›®' in q:
                # æª¢æŸ¥é¡Œè™Ÿæ˜¯å¦ç‚ºæ•¸å­—ä¸”ä¸é‡è¤‡
                try:
                    num = int(str(q.get('é¡Œè™Ÿ', '')).strip())
                    if num in seen_numbers:
                        continue  # è·³éé‡è¤‡é¡Œè™Ÿ
                    seen_numbers.add(num)
                except:
                    continue  # é¡Œè™Ÿç„¡æ•ˆè·³é

                # æª¢æŸ¥é¡Œç›®å…§å®¹é•·åº¦
                title = str(q.get('é¡Œç›®', '')).strip()
                if len(title) < 20:
                    continue  # é¡Œç›®å¤ªçŸ­è·³é

                validated.append({
                    'é¡Œè™Ÿ': str(num),
                    'é¡Œç›®': title,
                    'é¸é …A': str(q.get('é¸é …A', '')),
                    'é¸é …B': str(q.get('é¸é …B', '')),
                    'é¸é …C': str(q.get('é¸é …C', '')),
                    'é¸é …D': str(q.get('é¸é …D', '')),
                    'é¡Œå‹': str(q.get('é¡Œå‹', 'é¸æ“‡é¡Œ'))
                })

        # å¦‚æœè§£æå‡ºçš„é¡Œæ•¸æ˜é¡¯åé›¢é æœŸï¼Œå˜—è©¦ä¿®æ­£
        if expected_count and abs(len(validated) - expected_count) > 3:
            print(f"âš ï¸ æ–‡å­—è§£æé¡Œæ•¸({len(validated)})èˆ‡é æœŸ({expected_count})å·®è·éå¤§ï¼Œå¯èƒ½æœ‰èª¤")
            # è¿”å›è¼ƒå°‘çš„é¡Œç›®ï¼ˆé€šå¸¸æ˜¯éåº¦è§£æçš„å•é¡Œï¼‰
            if len(validated) > expected_count:
                validated = validated[:expected_count]

        return validated
    except Exception as e:
        print(f"âŒ æ–‡å­—è§£æå¤±æ•—: {e}")
        return []

def validate_questions(questions: List[Dict[str, Any]], pdf_features: Dict[str, Any]) -> ValidationResult:
    """é›¶èª¤å·®é©—è­‰"""
    result = ValidationResult()

    total = len(questions)
    choice = len([q for q in questions if q.get('é¡Œå‹') == 'é¸æ“‡é¡Œ'])
    essay = len([q for q in questions if q.get('é¡Œå‹') == 'å•ç­”é¡Œ'])

    result.summary['å¯¦éš›é¡Œæ•¸'] = total
    result.summary['é¸æ“‡é¡Œ'] = choice
    result.summary['å•ç­”é¡Œ'] = essay

    expected = pdf_features.get('expected_question_count')
    if expected:
        result.summary['é æœŸé¡Œæ•¸'] = expected
        if total != expected:
            result.add_issue(f"é¡Œæ•¸ä¸ç¬¦: é æœŸ{expected}é¡Œï¼Œå¯¦éš›{total}é¡Œï¼ˆå·®{abs(expected-total)}é¡Œï¼‰")

    # é¡Œè™Ÿé©—è­‰
    nums = []
    for i, q in enumerate(questions):
        try:
            num = q.get('é¡Œè™Ÿ')
            if isinstance(num, str) and num.isdigit():
                nums.append(int(num))
            elif isinstance(num, int):
                nums.append(num)
        except:
            pass

    if nums:
        nums.sort()
        result.summary['é¡Œè™Ÿç¯„åœ'] = f"{nums[0]}-{nums[-1]}"

        if nums[0] != 1:
            result.add_issue(f"é¡Œè™Ÿä¸å¾1é–‹å§‹ï¼ˆå¾{nums[0]}é–‹å§‹ï¼‰")

        expected_range = set(range(nums[0], nums[-1] + 1))
        missing = expected_range - set(nums)
        if missing:
            result.add_issue(f"éºå¤±é¡Œè™Ÿ: {sorted(list(missing))}")

        duplicates = [n for n in set(nums) if nums.count(n) > 1]
        if duplicates:
            result.add_issue(f"é‡è¤‡é¡Œè™Ÿ: {sorted(duplicates)}")

        if expected and nums[-1] != expected:
            result.add_issue(f"æœ€å¾Œé¡Œè™Ÿæ‡‰ç‚º{expected}ï¼Œå¯¦éš›ç‚º{nums[-1]}")

    # å…§å®¹é©—è­‰
    for i, q in enumerate(questions):
        text = q.get('é¡Œç›®', '').strip()
        if not text:
            result.add_issue(f"ç¬¬{i+1}é¡Œç‚ºç©º")
        elif len(text) < 8:
            result.add_issue(f"ç¬¬{i+1}é¡ŒéçŸ­({len(text)}å­—)")

    # é¸é …é©—è­‰
    for i, q in enumerate(questions):
        if q.get('é¡Œå‹') == 'é¸æ“‡é¡Œ':
            missing = [opt[-1] for opt in ['é¸é …A', 'é¸é …B', 'é¸é …C', 'é¸é …D'] 
                      if not q.get(opt, '').strip()]
            if missing:
                result.add_issue(f"ç¬¬{i+1}é¡Œç¼ºé¸é …: {','.join(missing)}")

    return result

def process_pdf_to_csv(pdf_path: str, output_dir: str = "") -> Tuple[List[str], ValidationResult]:
    """é›¶èª¤å·®è™•ç†"""
    print(f"\n{'='*70}")
    print(f"ğŸ“„ {os.path.basename(pdf_path)}")
    print(f"{'='*70}")

    # ============ æ–°å¢ï¼šæª”æ¡ˆæª¢æŸ¥ ============
    filename = os.path.basename(pdf_path)

    # å…ˆé€šéæª”åæª¢æŸ¥
    if should_skip_file(filename):
        print(f"â­ï¸ è·³éç­”æ¡ˆæª”æ¡ˆï¼ˆæª”ååˆ¤æ–·ï¼‰")
        return [], ValidationResult()

    # å†é€šéå…§å®¹æª¢æŸ¥
    if is_answer_file(pdf_path):
        print(f"â­ï¸ è·³éç­”æ¡ˆæª”æ¡ˆï¼ˆå…§å®¹åˆ¤æ–·ï¼‰")
        return [], ValidationResult()
    # ========================================

    pdf_features = PDFFeatureAnalyzer.analyze_pdf(pdf_path)
    print(f"é æ•¸: {pdf_features['page_count']}, å¤§å°: {pdf_features['file_size_mb']:.2f}MB")
    if pdf_features.get('expected_question_count'):
        print(f"é æœŸé¡Œæ•¸: {pdf_features['expected_question_count']}")

    # å››æ¬¡é‡è©¦ï¼šå¢åŠ Proæ¨¡å‹é‡è©¦
    strategies = [
        ('text', 'æ–‡å­—æ¨¡å¼ - Gemini 2.5 Flash'),
        ('pdf', 'PDFä¸Šå‚³ - Gemini 2.5 Flash'),
        ('pdf', 'PDFä¸Šå‚³é‡è©¦ - Gemini 2.5 Flash'),
        ('pdf_pro', 'PDFä¸Šå‚³ - Gemini 2.5 Pro')
    ]

    best_q = []
    best_v = ValidationResult()

    for i, (stype, sdesc) in enumerate(strategies, 1):
        print(f"\nç¬¬{i}/{len(strategies)}æ¬¡: {sdesc}")

        if stype == 'text':
            text = extract_text_from_pdf(pdf_path)
            expected_count = pdf_features.get('expected_question_count', 0)
            q = parse_questions_with_text_gemini(text, expected_count) if text else []
        elif stype == 'pdf_pro':
            q = parse_with_pdf_upload(pdf_path, use_pro=True)
        else:
            q = parse_with_pdf_upload(pdf_path)

        if not q:
            print("âš ï¸ æœªæ‰¾åˆ°é¡Œç›®")
            continue

        v = validate_questions(q, pdf_features)
        v.print_result()

        if not best_q or v.status == 'success' or len(q) > len(best_q):
            best_q = q
            best_v = v

        if v.status == 'success':
            print("\nâœ… é›¶èª¤å·®é©—è­‰é€šéï¼")
            break

        if i < len(strategies):
            print("â³ æº–å‚™é‡è©¦...")
            time.sleep(2)

    print(f"\n{'='*70}")
    print("æœ€çµ‚çµæœ")
    print(f"{'='*70}")
    if best_v:
        best_v.print_result()

    if best_v and best_v.status == 'error':
        print(f"\nâš ï¸âš ï¸âš ï¸ éœ€è¦äººå·¥æª¢æŸ¥ âš ï¸âš ï¸âš ï¸")
        print(f"æª”æ¡ˆ: {pdf_path}")

    if not best_q:
        return [], ValidationResult()

    os.makedirs(output_dir, exist_ok=True)
    base = os.path.splitext(os.path.basename(pdf_path))[0]
    saved = []

    choice = [q for q in best_q if q['é¡Œå‹'] == 'é¸æ“‡é¡Œ']
    essay = [q for q in best_q if q['é¡Œå‹'] == 'å•ç­”é¡Œ']

    if choice:
        path = os.path.join(output_dir, f"{base}_é¸æ“‡é¡Œ.csv")
        pd.DataFrame(choice).to_csv(path, index=False, encoding='utf-8-sig')
        print(f"\nâœ… {path} ({len(choice)}é¡Œ)")
        saved.append(path)

    if essay:
        path = os.path.join(output_dir, f"{base}_å•ç­”é¡Œ.csv")
        pd.DataFrame(essay).to_csv(path, index=False, encoding='utf-8-sig')
        print(f"âœ… {path} ({len(essay)}é¡Œ)")
        saved.append(path)

    return saved, best_v

def process_directory(input_dir: str, output_dir: str = "") -> Dict[str, Any]:
    pdf_files = glob.glob(os.path.join(input_dir, "**", "*.pdf"), recursive=True)

    if not pdf_files:
        print("æœªæ‰¾åˆ°PDF")
        return {}

    # ============ æ–°å¢ï¼šçµ±è¨ˆéæ¿¾è³‡è¨Š ============
    print(f"\næ‰¾åˆ° {len(pdf_files)} å€‹PDF")

    # é å…ˆéæ¿¾ç­”æ¡ˆæª”æ¡ˆ
    filtered_files = []
    skipped_files = []

    for pdf_file in pdf_files:
        filename = os.path.basename(pdf_file)
        if should_skip_file(filename):
            skipped_files.append(filename)
        else:
            filtered_files.append(pdf_file)

    print(f"â­ï¸  éæ¿¾æ‰ {len(skipped_files)} å€‹ç­”æ¡ˆæª”æ¡ˆ")
    print(f"ğŸ“„ å°‡è™•ç† {len(filtered_files)} å€‹è©¦é¡Œæª”æ¡ˆ\n")
    # ==========================================

    cache_manager.cleanup_expired_cache()

    results = []
    success = warning = error = 0

    for i, pdf in enumerate(filtered_files, 1):
        try:
            print(f"\n[{i}/{len(filtered_files)}]")

            rel = os.path.relpath(pdf, input_dir)
            out = os.path.join(output_dir, os.path.dirname(rel)) if output_dir else os.path.dirname(pdf)

            _, v = process_pdf_to_csv(pdf, out)

            results.append({
                'file': os.path.basename(pdf),
                'status': v.status,
                'summary': v.summary,
                'issues': v.issues
            })

            if v.status == 'success':
                success += 1
            elif v.status == 'warning':
                warning += 1
            else:
                error += 1
        except Exception as e:
            print(f"âŒ éŒ¯èª¤: {e}")
            error += 1

    print(f"\n{'='*70}")
    print("çµ±è¨ˆ")
    print(f"{'='*70}")
    print(f"ç¸½è©¦é¡ŒPDF: {len(filtered_files)}")
    print(f"âœ… æˆåŠŸ: {success} ({success/max(len(filtered_files),1)*100:.1f}%)")
    print(f"âš ï¸ è­¦å‘Š: {warning} ({warning/max(len(filtered_files),1)*100:.1f}%)")
    print(f"âŒ éŒ¯èª¤: {error} ({error/max(len(filtered_files),1)*100:.1f}%)")
    print(f"\nâ­ï¸  å·²è·³é {len(skipped_files)} å€‹ç­”æ¡ˆæª”æ¡ˆ")

    if error > 0:
        print(f"\néœ€æª¢æŸ¥:")
        for r in results:
            if r['status'] == 'error':
                print(f"  - {r['file']}")

    report = os.path.join(output_dir if output_dir else input_dir, "validation_report.json")
    with open(report, 'w', encoding='utf-8') as f:
        json.dump({
            'summary': {
                'total_files': len(pdf_files),
                'processed': len(filtered_files),
                'skipped': len(skipped_files),
                'success': success, 
                'warning': warning, 
                'error': error
            }, 
            'skipped_files': skipped_files,
            'details': results
        }, f, ensure_ascii=False, indent=2)

    print(f"\nå ±å‘Š: {report}")
    return {'total': len(filtered_files), 'success': success, 'warning': warning, 'error': error}

def main():
    print("PDFè½‰CSVå·¥å…· - é›¶èª¤å·®ç‰ˆ + ç­”æ¡ˆæª”æ¡ˆéæ¿¾")
    print("="*70)

    api_key = "AIzaSyDkeFFssyn-Srci1zJPBF8FxXPbILrKj6k"  # è«‹æ›¿æ›ç‚ºæ‚¨çš„API key
    setup_gemini_api(api_key)

    input_dir = r"è€ƒé¸éƒ¨è€ƒå¤é¡Œå®Œæ•´åº«\æ°‘åœ‹114å¹´"
    output_dir = r"è€ƒé¸éƒ¨è€ƒå¤é¡Œå®Œæ•´åº«\æ°‘åœ‹114å¹´_csv"

    print(f"è¼¸å…¥: {input_dir}")
    print(f"è¼¸å‡º: {output_dir}\n")

    results = process_directory(input_dir, output_dir)

    print(f"\nå®Œæˆï¼æˆåŠŸç‡: {results['success']/(results['total'] or 1)*100:.1f}%")

if __name__ == "__main__":
    main()
