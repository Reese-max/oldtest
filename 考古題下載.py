import os
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from bs4 import BeautifulSoup, Tag
from bs4.element import NavigableString, PageElement
import time
import re
from urllib.parse import urljoin
import html
import json
from datetime import datetime
from typing import List, Dict, Any, Union, Optional, Tuple
import warnings
import urllib3

# éš±è— urllib3 çš„ SSL è­¦å‘Š
warnings.filterwarnings('ignore', category=urllib3.exceptions.InsecureRequestWarning)

# é¡å‹è¨»è§£åˆ¥å
BeautifulSoupElement = Union[Tag, NavigableString]

# --- åŸºæœ¬è¨­å®š ---
BASE_URL = "https://wwwq.moex.gov.tw/exam/"
DEFAULT_SAVE_DIR = "è€ƒé¸éƒ¨è€ƒå¤é¡Œå®Œæ•´åº«"
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7',
    'Connection': 'keep-alive'
}

# å‹•æ…‹è¨ˆç®—å¹´ä»½ç¯„åœï¼ˆæ°‘åœ‹å¹´ï¼‰
def get_available_years():
    """å‹•æ…‹è¨ˆç®—å¯ç”¨çš„å¹´ä»½ç¯„åœ"""
    from datetime import datetime
    current_year = datetime.now().year
    current_minguo_year = current_year - 1911

    # å¾æ°‘åœ‹81å¹´é–‹å§‹åˆ°ç•¶å‰å¹´ä»½ï¼ˆåŒ…å«æ˜å¹´ï¼Œä»¥é˜²è¬ä¸€ï¼‰
    return list(range(81, current_minguo_year + 2))

AVAILABLE_YEARS = get_available_years()
# --- ---

def print_banner():
    """é¡¯ç¤ºç¨‹å¼æ¨™é¡Œ"""
    print("\n" + "="*70)
    print(" " * 20 + "è€ƒé¸éƒ¨è€ƒå¤é¡Œæ‰¹é‡ä¸‹è¼‰å·¥å…·")
    print("="*70)
    print("ğŸ“š è³‡æ–™ä¾†æº: è€ƒé¸éƒ¨è€ƒç•¢è©¦é¡ŒæŸ¥è©¢å¹³è‡º")
    print(f"ğŸ—“ï¸  å¯ç”¨å¹´ä»½: æ°‘åœ‹ {AVAILABLE_YEARS[0]} å¹´ ~ {AVAILABLE_YEARS[-1]} å¹´")
    print("="*70 + "\n")

def get_save_folder():
    """äº’å‹•å¼è¼¸å…¥å„²å­˜è³‡æ–™å¤¾"""
    print("ã€æ­¥é©Ÿ 1/3ã€‘è¨­å®šå„²å­˜è³‡æ–™å¤¾")
    print("-" * 70)
    print("ğŸ’¡ è¼¸å…¥æ–¹å¼:")
    print(f"   1. ç›´æ¥æŒ‰ Enter â†’ ä½¿ç”¨é è¨­è³‡æ–™å¤¾ ({DEFAULT_SAVE_DIR})")
    print("   2. è¼¸å…¥è³‡æ–™å¤¾åç¨± â†’ åœ¨ç›®å‰ç›®éŒ„å»ºç«‹è©²è³‡æ–™å¤¾ (ä¾‹å¦‚: è€ƒå¤é¡Œ)")
    print("   3. è¼¸å…¥å®Œæ•´è·¯å¾‘ â†’ ä½¿ç”¨çµ•å°è·¯å¾‘ (ä¾‹å¦‚: D:/Downloads/è€ƒå¤é¡Œ)")
    print("   4. è¼¸å…¥ç›¸å°è·¯å¾‘ â†’ ç›¸å°æ–¼ç›®å‰ç›®éŒ„ (ä¾‹å¦‚: ../è€ƒå¤é¡Œ)")
    print("-" * 70)
    
    while True:
        current_dir = os.getcwd()
        print(f"ğŸ“‚ ç›®å‰å·¥ä½œç›®éŒ„: {current_dir}")
        user_input = input("ğŸ’¾ è«‹è¼¸å…¥å„²å­˜è³‡æ–™å¤¾ (ç›´æ¥æŒ‰ Enter ä½¿ç”¨é è¨­): ").strip()
        
        # ä½¿ç”¨é è¨­è³‡æ–™å¤¾
        if not user_input:
            save_dir = DEFAULT_SAVE_DIR
        else:
            save_dir = user_input
        
        # è½‰æ›ç‚ºçµ•å°è·¯å¾‘
        abs_path = os.path.abspath(save_dir)
        
        # æª¢æŸ¥è·¯å¾‘æ˜¯å¦æœ‰æ•ˆ
        try:
            # å˜—è©¦å»ºç«‹è³‡æ–™å¤¾ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            os.makedirs(abs_path, exist_ok=True)
            
            # æª¢æŸ¥æ˜¯å¦å¯å¯«å…¥
            test_file = os.path.join(abs_path, '.test_write')
            with open(test_file, 'w') as f:
                f.write('test')
            os.remove(test_file)
            
            print(f"âœ… å·²è¨­å®šå„²å­˜ä½ç½®: {abs_path}\n")
            return abs_path
            
        except PermissionError:
            print(f"âŒ æ²’æœ‰å¯«å…¥æ¬Šé™: {abs_path}")
            print("   è«‹é¸æ“‡å…¶ä»–è³‡æ–™å¤¾æˆ–ä»¥ç®¡ç†å“¡èº«ä»½åŸ·è¡Œç¨‹å¼\n")
        except Exception as e:
            print(f"âŒ è³‡æ–™å¤¾è¨­å®šå¤±æ•—: {e}")
            print("   è«‹é‡æ–°è¼¸å…¥\n")

def get_year_input():
    """äº’å‹•å¼è¼¸å…¥å¹´ä»½ç¯„åœ"""
    print("ã€æ­¥é©Ÿ 2/3ã€‘è¨­å®šä¸‹è¼‰å¹´ä»½")
    print("-" * 70)
    print("ğŸ’¡ è¼¸å…¥æ–¹å¼:")
    print("   1. å–®ä¸€å¹´ä»½: 113")
    print("   2. å¹´ä»½ç¯„åœ: 110-114")
    print("   3. å¤šå€‹å¹´ä»½: 110,112,113")
    print("   4. å…¨éƒ¨å¹´ä»½: all æˆ– *")
    print("-" * 70)
    
    while True:
        user_input = input("ğŸ“… è«‹è¼¸å…¥å¹´ä»½ (æ°‘åœ‹å¹´): ").strip()
        
        if not user_input:
            print("âŒ è¼¸å…¥ä¸å¯ç‚ºç©ºï¼Œè«‹é‡æ–°è¼¸å…¥\n")
            continue
        
        try:
            # å…¨éƒ¨å¹´ä»½
            if user_input.lower() in ['all', '*', 'å…¨éƒ¨']:
                return AVAILABLE_YEARS
            
            # å¹´ä»½ç¯„åœ
            elif '-' in user_input:
                parts = user_input.split('-')
                if len(parts) != 2:
                    raise ValueError
                start = int(parts[0].strip())
                end = int(parts[1].strip())

                # å‹•æ…‹æª¢æŸ¥å¹´ä»½ç¯„åœ
                max_year = AVAILABLE_YEARS[-1] if AVAILABLE_YEARS else 114
                if not (AVAILABLE_YEARS[0] <= start <= max_year and AVAILABLE_YEARS[0] <= end <= max_year and start <= end):
                    print(f"âŒ å¹´ä»½ç¯„åœå¿…é ˆåœ¨ {AVAILABLE_YEARS[0]}-{max_year} ä¹‹é–“ï¼Œä¸”èµ·å§‹å¹´ä»½ä¸å¯å¤§æ–¼çµæŸå¹´ä»½\n")
                    continue

                years = list(range(start, end + 1))
                print(f"âœ… å·²é¸æ“‡: æ°‘åœ‹ {start} å¹´ ~ {end} å¹´ (å…± {len(years)} å¹´)\n")
                return years
            
            # å¤šå€‹å¹´ä»½
            elif ',' in user_input:
                years = [int(y.strip()) for y in user_input.split(',')]

                # å‹•æ…‹æª¢æŸ¥å¹´ä»½ç¯„åœ
                max_year = AVAILABLE_YEARS[-1] if AVAILABLE_YEARS else 114
                if not all(AVAILABLE_YEARS[0] <= y <= max_year for y in years):
                    print(f"âŒ æ‰€æœ‰å¹´ä»½å¿…é ˆåœ¨ {AVAILABLE_YEARS[0]}-{max_year} ä¹‹é–“\n")
                    continue

                years = sorted(list(set(years)))
                print(f"âœ… å·²é¸æ“‡: {len(years)} å€‹å¹´ä»½: {', '.join(map(str, years))}\n")
                return years

            # å–®ä¸€å¹´ä»½
            else:
                year = int(user_input)
                max_year = AVAILABLE_YEARS[-1] if AVAILABLE_YEARS else 114
                if not (AVAILABLE_YEARS[0] <= year <= max_year):
                    print(f"âŒ å¹´ä»½å¿…é ˆåœ¨ {AVAILABLE_YEARS[0]}-{max_year} ä¹‹é–“\n")
                    continue

                print(f"âœ… å·²é¸æ“‡: æ°‘åœ‹ {year} å¹´\n")
                return [year]
        
        except ValueError:
            print("âŒ è¼¸å…¥æ ¼å¼éŒ¯èª¤ï¼Œè«‹é‡æ–°è¼¸å…¥\n")
            continue

def get_filter_input():
    """äº’å‹•å¼è¼¸å…¥è€ƒè©¦é¡å‹ç¯©é¸"""
    print("ã€æ­¥é©Ÿ 3/3ã€‘è¨­å®šè€ƒè©¦é¡å‹ç¯©é¸")
    print("-" * 70)
    print("ğŸ’¡ é è¨­è€ƒè©¦é¡å‹:")
    print("   1. è­¦å¯Ÿäººå“¡è€ƒè©¦ï¼ˆå…§è»Œï¼‰")
    print("   2. ä¸€èˆ¬è­¦å¯Ÿäººå“¡è€ƒè©¦ï¼ˆå¤–è»Œï¼‰")
    print("   3. å¸æ³•äººå“¡è€ƒè©¦ï¼ˆç›£ç„å®˜ã€è§€è­·äººï¼‰")
    print("   4. åœ‹å®¶å®‰å…¨æƒ…å ±äººå“¡è€ƒè©¦")
    print("   5. ç§»æ°‘è¡Œæ”¿äººå“¡è€ƒè©¦")
    print("-" * 70)

    # è¿”å›è€ƒè©¦ç´šåˆ¥çš„é—œéµå­—
    target_keywords = [
        "è­¦å¯Ÿäººå“¡è€ƒè©¦",
        "ä¸€èˆ¬è­¦å¯Ÿäººå“¡è€ƒè©¦",
        "å¸æ³•äººå“¡è€ƒè©¦",
        "åœ‹å®¶å®‰å…¨æƒ…å ±äººå“¡è€ƒè©¦",
        "ç§»æ°‘è¡Œæ”¿äººå“¡è€ƒè©¦"
    ]

    print("âœ… å·²è‡ªå‹•è¨­å®š: è­¦å¯Ÿèˆ‡å¸æ³•ç›¸é—œè€ƒè©¦ç¯©é¸\n")
    return target_keywords

def confirm_settings(save_dir, years, keywords):
    """ç¢ºèªè¨­å®š"""
    print("="*70)
    print("ğŸ“‹ ç›®å‰è¨­å®š")
    print("="*70)
    
    # é¡¯ç¤ºå„²å­˜ä½ç½®
    print(f"ğŸ’¾ å„²å­˜ä½ç½®: {save_dir}")
    
    # é¡¯ç¤ºå¹´ä»½
    if len(years) == 1:
        print(f"ğŸ“… ä¸‹è¼‰å¹´ä»½: æ°‘åœ‹ {years[0]} å¹´")
    elif len(years) <= 5:
        print(f"ğŸ“… ä¸‹è¼‰å¹´ä»½: æ°‘åœ‹ {', '.join(map(str, years))} å¹´")
    else:
        print(f"ğŸ“… ä¸‹è¼‰å¹´ä»½: æ°‘åœ‹ {years[0]} ~ {years[-1]} å¹´ (å…± {len(years)} å¹´)")
    
    # é¡¯ç¤ºç¯©é¸
    if keywords:
        print(f"ğŸ” è€ƒè©¦ç¯©é¸: {', '.join(keywords)}")
    else:
        print(f"ğŸ” è€ƒè©¦ç¯©é¸: å…¨éƒ¨è€ƒè©¦")
    
    # é¡¯ç¤ºç£ç¢Ÿç©ºé–“
    try:
        if os.name == 'nt':  # Windows
            import shutil
            total, used, free = shutil.disk_usage(save_dir)
            print(f"ğŸ’¿ å¯ç”¨ç©ºé–“: {free / (1024**3):.2f} GB")
    except (ImportError, OSError, AttributeError):
        # å¿½ç•¥ç£ç¢Ÿç©ºé–“æª¢æŸ¥å¤±æ•—ï¼ˆéé—œéµåŠŸèƒ½ï¼‰
        pass
    
    print("="*70)
    
    while True:
        confirm = input("\nç¢ºèªé–‹å§‹ä¸‹è¼‰? (Y/N): ").strip().upper()
        if confirm == 'Y':
            return True
        elif confirm == 'N':
            return False
        else:
            print("âŒ è«‹è¼¸å…¥ Y æˆ– N")

def create_robust_session():
    """å‰µå»ºå¢å¼·å‹Session - æå‡æˆåŠŸç‡è‡³95-99%"""
    session = requests.Session()

    # é…ç½®é‡è©¦ç­–ç•¥
    retry_strategy = Retry(
        total=10,  # ç¸½å…±10æ¬¡é‡è©¦ï¼ˆåŸ5æ¬¡ï¼‰
        backoff_factor=1,  # æŒ‡æ•¸é€€é¿å› å­ï¼š1s, 2s, 4s, 8s...
        status_forcelist=[429, 500, 502, 503, 504],  # éœ€è¦é‡è©¦çš„HTTPç‹€æ…‹ç¢¼
        allowed_methods=["GET", "POST"],  # å…è¨±é‡è©¦çš„æ–¹æ³•
        raise_on_status=False  # ä¸åœ¨é‡è©¦æ™‚æ‹‹å‡ºç•°å¸¸
    )

    # é…ç½®HTTPé©é…å™¨
    adapter = HTTPAdapter(
        max_retries=retry_strategy,
        pool_connections=10,  # é€£æ¥æ± å¤§å°
        pool_maxsize=20,      # æœ€å¤§é€£æ¥æ•¸
        pool_block=False      # éé˜»å¡æ¨¡å¼
    )

    session.mount("http://", adapter)
    session.mount("https://", adapter)
    session.headers.update(HEADERS)

    return session

def verify_pdf_file(file_path: str) -> Tuple[bool, Any]:
    """
    é©—è­‰PDFæ–‡ä»¶å®Œæ•´æ€§

    Returns:
        (æ˜¯å¦æœ‰æ•ˆ, æ–‡ä»¶å¤§å°æˆ–éŒ¯èª¤è¨Šæ¯)
    """
    try:
        # æª¢æŸ¥æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(file_path)
        if file_size < 1024:
            return False, "æ–‡ä»¶éå°"

        # æª¢æŸ¥PDFæ–‡ä»¶é ­ï¼ˆ%PDF-ï¼‰
        with open(file_path, 'rb') as f:
            header = f.read(5)
            if not header.startswith(b'%PDF-'):
                return False, "éPDFæ–‡ä»¶"

        # å˜—è©¦ç”¨pdfplumberæ‰“é–‹é©—è­‰ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            import pdfplumber
            with pdfplumber.open(file_path) as pdf:
                # æª¢æŸ¥æ˜¯å¦è‡³å°‘æœ‰ä¸€é 
                if len(pdf.pages) == 0:
                    return False, "PDFç„¡å…§å®¹"
        except ImportError:
            # å¦‚æœæ²’æœ‰pdfplumberï¼Œè·³éæ·±åº¦é©—è­‰
            pass
        except Exception as e:
            return False, f"PDFæå£: {str(e)[:30]}"

        return True, file_size

    except Exception as e:
        return False, f"é©—è­‰å¤±æ•—: {str(e)[:30]}"

def sanitize_filename(name):
    """æ¸…ç†æª”åä¸­çš„éæ³•å­—å…ƒ"""
    name = html.unescape(name)
    name = re.sub(r'[\\/*?:"<>|]', "", name)
    if len(name) > 150:
        name = name[:150]
    return name.strip()

def get_exam_list_by_year(session, year, keywords):
    """ç²å–æŒ‡å®šå¹´ä»½çš„è€ƒè©¦åˆ—è¡¨"""
    try:
        url = f"{BASE_URL}wFrmExamQandASearch.aspx?y={year + 1911}"
        response = session.get(url, timeout=30, verify=False)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        exam_select = soup.find("select", id=re.compile(r'ddlExamCode'))
        if not exam_select:
            return []
        
        exams = []
        for option in exam_select.find_all("option"):  # type: ignore
            if isinstance(option, Tag) and option.has_attr('value') and option['value']:
                exam_code = option['value']
                exam_name = option.get_text(strip=True)
                
                if keywords:
                    # ä½¿ç”¨è€ƒè©¦ç´šåˆ¥çš„é—œéµå­—ç¯©é¸
                    if any(keyword in exam_name for keyword in keywords):
                        exams.append({
                            'code': exam_code,
                            'name': exam_name,
                            'year': year
                        })
                        print(f"   âœ… æ‰¾åˆ°è€ƒè©¦: {exam_name}")
                else:
                    exams.append({
                        'code': exam_code,
                        'name': exam_name,
                        'year': year
                    })
        
        return exams
    except Exception as e:
        print(f"   âŒ ç²å– {year} å¹´è€ƒè©¦åˆ—è¡¨å¤±æ•—: {e}")
        return []

def parse_exam_page(html_content, exam_name=""):
    """
    è§£æè€ƒè©¦é é¢ï¼ŒåŸºæ–¼ç§‘ç›®ç‰¹å¾µè­˜åˆ¥é¡ç§‘
    é©ç”¨å¹´ä»½ï¼š90-114å¹´
    ç›®æ¨™é¡ç§‘ï¼šè­¦å¯Ÿäººå“¡ä¸‰ç­‰14é¡ + å¸æ³•ä¸‰ç­‰2é¡ï¼ˆç›£ç„å®˜ï¼‰
    """
    from bs4 import BeautifulSoup, Tag
    import re
    import html as html_module
    from collections import defaultdict

    soup = BeautifulSoup(html_content, 'html.parser')

    # æ­¥é©Ÿ1ï¼šæ”¶é›†æ‰€æœ‰é¡ç§‘ä»£ç¢¼çš„ç§‘ç›®å’Œä¸‹è¼‰é€£çµ
    raw_structure = defaultdict(lambda: defaultdict(dict))

    links = soup.find_all('a', href=re.compile(r'wHandExamQandA_File\.ashx'))

    for link in links:
        if not isinstance(link, Tag):
            continue

        href = link.get('href', '')
        if not href:
            continue

        # è§£æURLåƒæ•¸
        href_str = str(href)
        code_match = re.search(r'[&?]c=(\d+)', href_str)
        type_match = re.search(r'[&?]t=([QSMR])', href_str)

        if not code_match:
            continue

        category_code = code_match.group(1)
        file_type_code = type_match.group(1) if type_match else 'Q'
        file_type = {
            'Q': 'è©¦é¡Œ',
            'S': 'ç­”æ¡ˆ',
            'M': 'æ›´æ­£ç­”æ¡ˆ',
            'R': 'åƒè€ƒç­”æ¡ˆ'
        }.get(file_type_code, 'è©¦é¡Œ')

        # æ‰¾ç§‘ç›®åç¨±
        tr = link.find_parent('tr')
        if not tr or not isinstance(tr, Tag):
            continue

        label = tr.find('label', {'class': 'exam-title'})
        if not label:
            label = tr.find('label')
        if not label or not isinstance(label, Tag):
            continue

        subject_name = label.get_text(strip=True)
        if not subject_name or subject_name in ['è©¦é¡Œ', 'ç­”æ¡ˆ', 'æ›´æ­£ç­”æ¡ˆ', 'åƒè€ƒç­”æ¡ˆ']:
            continue

        # å„²å­˜è³‡æ–™ - ç¢ºä¿æ‰€æœ‰å¿…è¦çš„éµéƒ½å­˜åœ¨
        subject_dict = raw_structure[category_code][subject_name]
        if 'subject' not in subject_dict:
            subject_dict['subject'] = sanitize_filename(subject_name)
        if 'original_name' not in subject_dict:
            subject_dict['original_name'] = subject_name
        if 'downloads' not in subject_dict:
            subject_dict['downloads'] = []

        subject_dict['downloads'].append({
            'type': file_type,
            'url': html_module.unescape(str(href))
        })

    # æ­¥é©Ÿ2ï¼šæ ¹æ“šç§‘ç›®ç‰¹å¾µè­˜åˆ¥é¡ç§‘
    def identify_category(subjects_list):
        """
        æ ¹æ“š111å¹´å¯¦éš›ç§‘ç›®åç¨±è­˜åˆ¥é¡ç§‘
        æ¯å€‹é¡ç§‘éƒ½æœ‰1-3å€‹ç¨ç‰¹ç§‘ç›®å¯ä»¥è­˜åˆ¥
        """
        if not subjects_list:
            return None

        # å»ºç«‹ç§‘ç›®é›†åˆï¼ˆç”¨æ–¼å¿«é€ŸæŸ¥æ‰¾ï¼‰
        subjects_text = '|||'.join(subjects_list)

        # === å…§è»Œåˆ¤å®šï¼šå¿…é ˆæœ‰é€™ä¸‰ç¨®è‹±æ–‡ç§‘ç›®ä¹‹ä¸€ ===
        is_internal = (
            'ä¸­è¯æ°‘åœ‹æ†²æ³•èˆ‡è­¦å¯Ÿå°ˆæ¥­è‹±æ–‡' in subjects_text or
            'ä¸­è¯æ°‘åœ‹æ†²æ³•èˆ‡æ¶ˆé˜²è­¦å¯Ÿå°ˆæ¥­è‹±æ–‡' in subjects_text or
            'ä¸­è¯æ°‘åœ‹æ†²æ³•èˆ‡æ°´ä¸Šè­¦å¯Ÿå°ˆæ¥­è‹±æ–‡' in subjects_text
        )

        if not is_internal:
            # æª¢æŸ¥å¸æ³•ç‰¹è€ƒ - ä¸‰ç­‰ç›£ç„å®˜çš„å®Œæ•´ç§‘ç›®åˆ—è¡¨
            judicial_subjects = [
                'åœ‹æ–‡(ä½œæ–‡ã€å…¬æ–‡èˆ‡æ¸¬é©—)',
                'æ³•å­¸çŸ¥è­˜èˆ‡è‹±æ–‡(åŒ…æ‹¬ä¸­è¯æ°‘åœ‹æ†²æ³•ã€æ³•å­¸ç·’è«–ã€è‹±æ–‡)',
                'åˆ‘æ³•èˆ‡å°‘å¹´äº‹ä»¶è™•ç†æ³•',
                'åˆ‘äº‹æ”¿ç­–',
                'çŠ¯ç½ªå­¸èˆ‡å†çŠ¯é æ¸¬',
                'ç›£ç„è¡Œåˆ‘æ³•èˆ‡ç¾ˆæŠ¼æ³•',
                'ç›£ç„å­¸',
                'è«®å•†èˆ‡çŸ¯æ­£è¼”å°'
            ]

            # æ’é™¤å››ç­‰ç›£æ‰€ç®¡ç†å“¡çš„æ¦‚è¦ç§‘ç›®
            exclude_subjects = [
                'çŠ¯ç½ªå­¸æ¦‚è¦',
                'åˆ‘æ³•æ¦‚è¦',
                'ç›£ç„è¡Œåˆ‘æ³•æ¦‚è¦',
                'ç›£ç„å­¸æ¦‚è¦'
            ]

            # æª¢æŸ¥æ˜¯å¦åŒ…å«æ’é™¤ç§‘ç›®ï¼ˆå¦‚æœæ˜¯æ¦‚è¦ç§‘ç›®ï¼Œå‰‡ä¸å±¬æ–¼ä¸‰ç­‰ç›£ç„å®˜ï¼‰
            has_exclude_subjects = any(subject in subjects_text for subject in exclude_subjects)

            if has_exclude_subjects:
                return None

            # æª¢æŸ¥æ˜¯å¦åŒ…å«è¶³å¤ çš„ä¸‰ç­‰ç›£ç„å®˜ç§‘ç›®ï¼ˆè‡³å°‘4å€‹ä¸»è¦ç§‘ç›®ï¼‰
            judicial_matches = sum(1 for subject in judicial_subjects if subject in subjects_text)
            if judicial_matches >= 4:
                # æ ¹æ“šè€ƒè©¦åç¨±åˆ¤æ–·æ˜¯ç”·é‚„æ˜¯å¥³
                if exam_name and ('(ç”·)' in exam_name or 'ç”·' in exam_name):
                    return 'å¸æ³•ä¸‰ç­‰è€ƒè©¦_ç›£ç„å®˜(ç”·)'
                elif exam_name and ('(å¥³)' in exam_name or 'å¥³' in exam_name):
                    return 'å¸æ³•ä¸‰ç­‰è€ƒè©¦_ç›£ç„å®˜(å¥³)'
                else:
                    return 'å¸æ³•ä¸‰ç­‰è€ƒè©¦_ç›£ç„å®˜'
            return None

        # === ä»¥ä¸‹ç‚ºå…§è»Œ14å€‹é¡ç§‘ ===

        # 1. è¡Œæ”¿è­¦å¯Ÿäººå“¡ï¼šè­¦å¯Ÿå­¸èˆ‡è­¦å¯Ÿå‹¤å‹™ + è­¦å¯Ÿæ”¿ç­–èˆ‡çŠ¯ç½ªé é˜²
        if 'è­¦å¯Ÿå­¸èˆ‡è­¦å¯Ÿå‹¤å‹™' in subjects_text:
            return 'è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_è¡Œæ”¿è­¦å¯Ÿäººå“¡'

        # 2. å¤–äº‹è­¦å¯Ÿäººå“¡ï¼šå¤–äº‹è­¦å¯Ÿå­¸
        if 'å¤–äº‹è­¦å¯Ÿå­¸' in subjects_text:
            return 'è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_å¤–äº‹è­¦å¯Ÿäººå“¡'

        # 3. åˆ‘äº‹è­¦å¯Ÿäººå“¡ï¼šçŠ¯ç½ªåµæŸ¥å­¸ + åˆ‘æ¡ˆç¾å ´è™•ç†
        if 'çŠ¯ç½ªåµæŸ¥å­¸' in subjects_text and 'åˆ‘æ¡ˆç¾å ´è™•ç†' in subjects_text:
            return 'è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_åˆ‘äº‹è­¦å¯Ÿäººå“¡'

        # 4. å…¬å…±å®‰å…¨äººå“¡ï¼šæƒ…å ±å­¸ + åœ‹å®¶å®‰å…¨æƒ…å ±æ³•åˆ¶
        if 'æƒ…å ±å­¸' in subjects_text and 'åœ‹å®¶å®‰å…¨æƒ…å ±æ³•åˆ¶' in subjects_text:
            return 'è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_å…¬å…±å®‰å…¨äººå“¡'

        # 5. çŠ¯ç½ªé˜²æ²»äººå“¡é é˜²çµ„ï¼šè«®å•†è¼”å°èˆ‡å©¦å¹¼ä¿è­· + çŠ¯ç½ªåˆ†æ
        if 'è«®å•†è¼”å°èˆ‡å©¦å¹¼ä¿è­·' in subjects_text and 'çŠ¯ç½ªåˆ†æ' in subjects_text:
            return 'è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_çŠ¯ç½ªé˜²æ²»äººå“¡é é˜²çµ„'

        # 6. æ¶ˆé˜²è­¦å¯Ÿäººå“¡ï¼šç«ç½å­¸èˆ‡æ¶ˆé˜²åŒ–å­¸ + æ¶ˆé˜²å®‰å…¨è¨­å‚™
        if 'ç«ç½å­¸èˆ‡æ¶ˆé˜²åŒ–å­¸' in subjects_text and 'æ¶ˆé˜²å®‰å…¨è¨­å‚™' in subjects_text:
            return 'è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_æ¶ˆé˜²è­¦å¯Ÿäººå“¡'

        # 7. äº¤é€šè­¦å¯Ÿäººå“¡äº¤é€šçµ„ï¼šäº¤é€šè­¦å¯Ÿå­¸ + äº¤é€šçµ±è¨ˆèˆ‡åˆ†æ
        if 'äº¤é€šè­¦å¯Ÿå­¸' in subjects_text and 'äº¤é€šçµ±è¨ˆèˆ‡åˆ†æ' in subjects_text:
            return 'è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_äº¤é€šè­¦å¯Ÿäººå“¡äº¤é€šçµ„'

        # 8. äº¤é€šè­¦å¯Ÿäººå“¡é›»è¨Šçµ„ï¼šé€šè¨ŠçŠ¯ç½ªåµæŸ¥ + é€šè¨Šç³»çµ± + é›»è·¯å­¸
        # æ”¾å¯¬æ¢ä»¶ï¼šåªè¦æœ‰é€šè¨Šç›¸é—œç§‘ç›®å³å¯è­˜åˆ¥
        if ('é€šè¨ŠçŠ¯ç½ªåµæŸ¥' in subjects_text or 'é€šè¨Šç³»çµ±' in subjects_text or 'é›»è·¯å­¸' in subjects_text) and 'äº¤é€šè­¦å¯Ÿå­¸' not in subjects_text:
            return 'è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_äº¤é€šè­¦å¯Ÿäººå“¡é›»è¨Šçµ„'

        # 9. è­¦å¯Ÿè³‡è¨Šç®¡ç†äººå“¡ï¼šé›»è…¦çŠ¯ç½ªåµæŸ¥ + æ•¸ä½é‘‘è­˜åŸ·æ³• + è­¦æ”¿è³‡è¨Šç®¡ç†èˆ‡æ‡‰ç”¨
        if 'é›»è…¦çŠ¯ç½ªåµæŸ¥' in subjects_text and 'æ•¸ä½é‘‘è­˜åŸ·æ³•' in subjects_text:
            return 'è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_è­¦å¯Ÿè³‡è¨Šç®¡ç†äººå“¡'

        # 10. åˆ‘äº‹é‘‘è­˜äººå“¡ï¼šç‰©ç†é‘‘è­˜ + åˆ‘äº‹åŒ–å­¸ + åˆ‘äº‹ç”Ÿç‰©
        if 'ç‰©ç†é‘‘è­˜' in subjects_text and 'åˆ‘äº‹åŒ–å­¸' in subjects_text and 'åˆ‘äº‹ç”Ÿç‰©' in subjects_text:
            return 'è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_åˆ‘äº‹é‘‘è­˜äººå“¡'

        # 11. åœ‹å¢ƒè­¦å¯Ÿäººå“¡ï¼šç§»æ°‘æƒ…å‹¢èˆ‡æ”¿ç­–åˆ†æ + åœ‹å¢ƒåŸ·æ³•
        if 'ç§»æ°‘æƒ…å‹¢èˆ‡æ”¿ç­–åˆ†æ' in subjects_text and 'åœ‹å¢ƒåŸ·æ³•' in subjects_text:
            return 'è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_åœ‹å¢ƒè­¦å¯Ÿäººå“¡'

        # 12. æ°´ä¸Šè­¦å¯Ÿäººå“¡ï¼šæ°´ä¸Šè­¦å¯Ÿå­¸ + æµ·ä¸ŠçŠ¯ç½ªåµæŸ¥æ³•å­¸ + åœ‹éš›æµ·æ´‹æ³•
        if 'æ°´ä¸Šè­¦å¯Ÿå­¸' in subjects_text and 'æµ·ä¸ŠçŠ¯ç½ªåµæŸ¥æ³•å­¸' in subjects_text:
            return 'è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_æ°´ä¸Šè­¦å¯Ÿäººå“¡'

        # 13. è­¦å¯Ÿæ³•åˆ¶äººå“¡ï¼šè­¦å¯Ÿæ³•åˆ¶ä½œæ¥­ + è¡Œæ”¿æ³•èˆ‡è­¦å¯Ÿè¡Œæ”¿é•è¦èª¿æŸ¥è£è™•ä½œæ¥­
        if 'è­¦å¯Ÿæ³•åˆ¶ä½œæ¥­' in subjects_text and 'è¡Œæ”¿æ³•èˆ‡è­¦å¯Ÿè¡Œæ”¿é•è¦èª¿æŸ¥è£è™•ä½œæ¥­' in subjects_text:
            return 'è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_è­¦å¯Ÿæ³•åˆ¶äººå“¡'

        # 14. è¡Œæ”¿ç®¡ç†äººå“¡ï¼šè­¦å¯Ÿäººäº‹è¡Œæ”¿èˆ‡æ³•åˆ¶ + è­¦å¯Ÿçµ„ç¹”èˆ‡äº‹å‹™ç®¡ç†
        if 'è­¦å¯Ÿäººäº‹è¡Œæ”¿èˆ‡æ³•åˆ¶' in subjects_text and 'è­¦å¯Ÿçµ„ç¹”èˆ‡äº‹å‹™ç®¡ç†' in subjects_text:
            return 'è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_è¡Œæ”¿ç®¡ç†äººå“¡'

        return None

    # æ­¥é©Ÿ3ï¼šæ•´ç†æˆæœ€çµ‚çµæ§‹
    exam_structure = {}

    for category_code, subjects_dict in raw_structure.items():
        subjects_list = list(subjects_dict.keys())
        category_name = identify_category(subjects_list)

        if not category_name:
            continue

        if category_name not in exam_structure:
            exam_structure[category_name] = []

        for subject_name, subject_info in subjects_dict.items():
            exam_structure[category_name].append({
                'subject': subject_info['subject'],
                'original_name': subject_info['original_name'],
                'downloads': subject_info['downloads']
            })

    # èª¿è©¦è¼¸å‡º
    print(f"   ğŸ” èª¿è©¦: è§£æå‡º {len(exam_structure)} å€‹ç›®æ¨™é¡ç§‘")
    for cat_name, subjects in exam_structure.items():
        print(f"   ğŸ” èª¿è©¦:   {cat_name}: {len(subjects)} å€‹ç§‘ç›®")
    
    # é¡¯ç¤ºæœªè­˜åˆ¥çš„é¡ç§‘
    unidentified_categories = []
    for category_code, subjects_dict in raw_structure.items():
        subjects_list = list(subjects_dict.keys())
        category_name = identify_category(subjects_list)
        if not category_name:
            unidentified_categories.append((category_code, subjects_list))
    
    if unidentified_categories:
        print(f"   âš ï¸  æœªè­˜åˆ¥çš„é¡ç§‘ ({len(unidentified_categories)} å€‹):")
        for code, subjects in unidentified_categories[:3]:  # åªé¡¯ç¤ºå‰3å€‹
            print(f"   âš ï¸     ä»£ç¢¼ {code}: {', '.join(subjects[:5])}{'...' if len(subjects) > 5 else ''}")

    return exam_structure

def download_file(session, url, file_path, max_retries=10):
    """
    å¢å¼·å‹æ–‡ä»¶ä¸‹è¼‰ - æ”¯æ´æ›´å¤šç•°å¸¸è™•ç†å’ŒPDFé©—è­‰

    Args:
        session: requests.Sessionå¯¦ä¾‹
        url: ä¸‹è¼‰URL
        file_path: å„²å­˜è·¯å¾‘
        max_retries: æœ€å¤§é‡è©¦æ¬¡æ•¸ï¼ˆé»˜èª10æ¬¡ï¼‰

    Returns:
        (æˆåŠŸ, æ–‡ä»¶å¤§å°æˆ–éŒ¯èª¤è¨Šæ¯)
    """
    for attempt in range(max_retries):
        try:
            # åˆ†åˆ¥è¨­ç½®é€£æ¥è¶…æ™‚å’Œè®€å–è¶…æ™‚
            # (é€£æ¥è¶…æ™‚, è®€å–è¶…æ™‚)
            timeout = (10, 120)  # 10ç§’å»ºç«‹é€£æ¥ï¼Œ120ç§’è®€å–æ•¸æ“š

            response = session.get(
                url,
                headers=HEADERS,
                stream=True,
                timeout=timeout,
                verify=False
            )
            response.raise_for_status()

            content_type = response.headers.get('Content-Type', '')
            if 'pdf' not in content_type.lower() and 'application/octet-stream' not in content_type.lower():
                return False, "éPDFæª”æ¡ˆ"

            with open(file_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)

            # é©—è­‰PDFæ–‡ä»¶å®Œæ•´æ€§
            valid, result = verify_pdf_file(file_path)
            if valid:
                return True, result
            else:
                # æ–‡ä»¶ç„¡æ•ˆï¼Œåˆªé™¤ä¸¦é‡è©¦
                try:
                    os.remove(file_path)
                except Exception:
                    pass
                if attempt == max_retries - 1:
                    return False, result
                time.sleep(2 ** attempt)
                continue

        except requests.exceptions.Timeout:
            if attempt == max_retries - 1:
                return False, "è«‹æ±‚è¶…æ™‚"
            time.sleep(2 ** attempt)
            continue

        except requests.exceptions.HTTPError as e:
            # HTTPç‹€æ…‹éŒ¯èª¤
            if e.response and e.response.status_code in [404, 403, 401]:
                # é€™äº›éŒ¯èª¤ä¸éœ€è¦é‡è©¦
                return False, f"HTTP {e.response.status_code}"
            if attempt == max_retries - 1:
                return False, f"HTTPéŒ¯èª¤"
            time.sleep(2 ** attempt)
            continue

        except requests.exceptions.ConnectionError:
            if attempt == max_retries - 1:
                return False, "é€£ç·šéŒ¯èª¤"
            time.sleep(2 ** attempt)
            continue

        except requests.exceptions.ChunkedEncodingError:
            # åˆ†å¡Šç·¨ç¢¼éŒ¯èª¤ï¼Œé€šå¸¸æ˜¯å‚³è¼¸ä¸­æ–·
            if attempt == max_retries - 1:
                return False, "å‚³è¼¸ä¸­æ–·"
            time.sleep(2 ** attempt)
            continue

        except requests.exceptions.ContentDecodingError:
            # å…§å®¹è§£ç¢¼éŒ¯èª¤
            if attempt == max_retries - 1:
                return False, "å…§å®¹è§£ç¢¼å¤±æ•—"
            time.sleep(2 ** attempt)
            continue

        except (OSError, IOError) as e:
            # æ–‡ä»¶ç³»çµ±éŒ¯èª¤
            error_msg = str(e).lower()
            if "disk" in error_msg or "space" in error_msg:
                return False, "ç£ç¢Ÿç©ºé–“ä¸è¶³"
            if attempt == max_retries - 1:
                return False, f"æ–‡ä»¶éŒ¯èª¤: {str(e)[:30]}"
            time.sleep(2 ** attempt)
            continue

        except Exception as e:
            if attempt == max_retries - 1:
                return False, f"æœªçŸ¥éŒ¯èª¤: {str(e)[:30]}"
            time.sleep(2 ** attempt)
            continue

    return False, "è¶…éæœ€å¤§é‡è©¦æ¬¡æ•¸"

def download_exam(session, exam_info, base_folder, stats):
    """ä¸‹è¼‰å–®ä¸€è€ƒè©¦"""
    year = exam_info['year']
    exam_code = exam_info['code']
    exam_name = exam_info['name']
    
    print(f"\n{'='*70}")
    print(f"ğŸ“‹ æ°‘åœ‹ {year} å¹´ - {exam_name}")
    print(f"{'='*70}")
    
    try:
        url = f"{BASE_URL}wFrmExamQandASearch.aspx?y={year + 1911}&e={exam_code}"
        response = session.get(url, timeout=30, verify=False)
        response.raise_for_status()
        
        # å®šç¾©é¡ç§‘é—œéµå­—ï¼ˆç”¨æ–¼ç¬¬äºŒå±¤ç¯©é¸ï¼‰
        category_keywords = [
            # è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦é¡åˆ¥
            "è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_è¡Œæ”¿è­¦å¯Ÿäººå“¡é¡åˆ¥",
            "è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_å¤–äº‹è­¦å¯Ÿäººå“¡(é¸è©¦è‹±èª)é¡åˆ¥",
            "è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_åˆ‘äº‹è­¦å¯Ÿäººå“¡é¡åˆ¥",
            "è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_å…¬å…±å®‰å…¨äººå“¡é¡åˆ¥",
            "è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_çŠ¯ç½ªé˜²æ²»äººå“¡é¡åˆ¥é é˜²çµ„",
            "è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_æ¶ˆé˜²è­¦å¯Ÿäººå“¡é¡åˆ¥",
            "è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_äº¤é€šè­¦å¯Ÿäººå“¡é¡åˆ¥äº¤é€šçµ„",
            "è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_è­¦å¯Ÿè³‡è¨Šç®¡ç†äººå“¡é¡åˆ¥",
            "è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_åˆ‘äº‹é‘‘è­˜äººå“¡é¡åˆ¥",
            "è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_åœ‹å¢ƒè­¦å¯Ÿäººå“¡é¡åˆ¥",
            "è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_æ°´ä¸Šè­¦å¯Ÿäººå“¡é¡åˆ¥",
            "è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_è­¦å¯Ÿæ³•åˆ¶äººå“¡é¡åˆ¥",
            "è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_äº¤é€šè­¦å¯Ÿäººå“¡é›»è¨Šçµ„",
            "è­¦å¯Ÿäººå“¡è€ƒè©¦ä¸‰ç­‰è€ƒè©¦_è¡Œæ”¿ç®¡ç†äººå“¡é¡åˆ¥",

            # å¸æ³•è€ƒè©¦é¡åˆ¥
            "å¸æ³•ä¸‰ç­‰è€ƒè©¦_ç›£ç„å®˜(ç”·)",
            "å¸æ³•ä¸‰ç­‰è€ƒè©¦_ç›£ç„å®˜(å¥³)",
        ]

        exam_structure = parse_exam_page(response.text, exam_name)
        
        if not exam_structure:
            print("   âš ï¸ æ­¤è€ƒè©¦æ²’æœ‰å¯ä¸‹è¼‰çš„è©¦é¡Œ")
            stats['empty_exams'] += 1
            return
        
        # ç¸®çŸ­è€ƒè©¦è³‡æ–™å¤¾åç¨±ä»¥é¿å…è·¯å¾‘éé•·
        if "è­¦å¯Ÿäººå“¡è€ƒè©¦ã€ä¸€èˆ¬è­¦å¯Ÿäººå“¡è€ƒè©¦" in exam_name:
            short_exam_name = f"æ°‘åœ‹{year}å¹´_è­¦å¯Ÿç‰¹è€ƒ"
        elif "å¸æ³•äººå“¡è€ƒè©¦" in exam_name:
            short_exam_name = f"æ°‘åœ‹{year}å¹´_å¸æ³•ç‰¹è€ƒ"
        else:
            # å°æ–¼å…¶ä»–è€ƒè©¦ï¼Œä½¿ç”¨å‰50å€‹å­—ç¬¦
            short_exam_name = sanitize_filename(f"æ°‘åœ‹{year}å¹´_{exam_name[:50]}")

        exam_folder = os.path.join(base_folder, f"æ°‘åœ‹{year}å¹´", short_exam_name)
        os.makedirs(exam_folder, exist_ok=True)
        
        total_subjects = sum(len(subjects) for subjects in exam_structure.values())
        total_files = sum(
            len(subject['downloads']) 
            for subjects in exam_structure.values() 
            for subject in subjects
        )
        
        print(f"   ğŸ“Š é¡ç§‘: {len(exam_structure)} å€‹ | ç§‘ç›®: {total_subjects} å€‹ | æª”æ¡ˆ: {total_files} å€‹")
        print(f"   ğŸ” èª¿è©¦: è©³ç´°é¡ç§‘è³‡è¨Š")
        for cat_name, subjects in exam_structure.items():
            cat_files = sum(len(subject['downloads']) for subject in subjects)
            print(f"   ğŸ”     {cat_name}: {len(subjects)} ç§‘ç›®, {cat_files} æª”æ¡ˆ")
        
        file_count = 0
        for category_name, subjects in exam_structure.items():
            # ç¸®çŸ­é¡ç§‘è³‡æ–™å¤¾åç¨±
            if 'è¡Œæ”¿è­¦å¯Ÿäººå“¡' in category_name:
                short_category_name = 'è¡Œæ”¿è­¦å¯Ÿ'
            elif 'å¤–äº‹è­¦å¯Ÿäººå“¡' in category_name:
                short_category_name = 'å¤–äº‹è­¦å¯Ÿ'
            elif 'åˆ‘äº‹è­¦å¯Ÿäººå“¡' in category_name:
                short_category_name = 'åˆ‘äº‹è­¦å¯Ÿ'
            elif 'å…¬å…±å®‰å…¨äººå“¡' in category_name:
                short_category_name = 'å…¬å…±å®‰å…¨'
            elif 'çŠ¯ç½ªé˜²æ²»äººå“¡' in category_name:
                short_category_name = 'çŠ¯ç½ªé˜²æ²»'
            elif 'æ¶ˆé˜²è­¦å¯Ÿäººå“¡' in category_name:
                short_category_name = 'æ¶ˆé˜²è­¦å¯Ÿ'
            elif 'äº¤é€šè­¦å¯Ÿäººå“¡äº¤é€šçµ„' in category_name:
                short_category_name = 'äº¤é€šè­¦å¯Ÿ_äº¤é€š'
            elif 'äº¤é€šè­¦å¯Ÿäººå“¡é›»è¨Šçµ„' in category_name:
                short_category_name = 'äº¤é€šè­¦å¯Ÿ_é›»è¨Š'
            elif 'è­¦å¯Ÿè³‡è¨Šç®¡ç†äººå“¡' in category_name:
                short_category_name = 'è³‡è¨Šç®¡ç†'
            elif 'åˆ‘äº‹é‘‘è­˜äººå“¡' in category_name:
                short_category_name = 'åˆ‘äº‹é‘‘è­˜'
            elif 'åœ‹å¢ƒè­¦å¯Ÿäººå“¡' in category_name:
                short_category_name = 'åœ‹å¢ƒè­¦å¯Ÿ'
            elif 'æ°´ä¸Šè­¦å¯Ÿäººå“¡' in category_name:
                short_category_name = 'æ°´ä¸Šè­¦å¯Ÿ'
            elif 'è­¦å¯Ÿæ³•åˆ¶äººå“¡' in category_name:
                short_category_name = 'è­¦å¯Ÿæ³•åˆ¶'
            elif 'è¡Œæ”¿ç®¡ç†äººå“¡' in category_name:
                short_category_name = 'è¡Œæ”¿ç®¡ç†'
            elif 'ç›£ç„å®˜' in category_name:
                short_category_name = 'ç›£ç„å®˜'
            else:
                # å°æ–¼å…¶ä»–é¡ç§‘ï¼Œä½¿ç”¨å¾Œé¢çš„éƒ¨åˆ†
                short_category_name = category_name.split('_')[-1] if '_' in category_name else category_name[:20]

            category_folder = os.path.join(exam_folder, short_category_name)
            os.makedirs(category_folder, exist_ok=True)
            
            for subject_info in subjects:
                subject_name = subject_info['subject']
                
                # ç‚ºæ¯å€‹ç§‘ç›®å»ºç«‹å°ˆç”¨è³‡æ–™å¤¾
                subject_folder = os.path.join(category_folder, subject_name)
                os.makedirs(subject_folder, exist_ok=True)
                
                for download_info in subject_info['downloads']:
                    file_type = download_info['type']
                    url = download_info['url']
                    
                    # æ ¹æ“šæª”æ¡ˆé¡å‹é€²è¡Œæ›´æ¸…æ™°çš„å‘½å
                    file_type_mapping = {
                        "è©¦é¡Œ": "è©¦é¡Œ",
                        "ç­”æ¡ˆ": "ç­”æ¡ˆ",
                        "æ›´æ­£ç­”æ¡ˆ": "æ›´æ­£ç­”æ¡ˆ",
                        "é¡Œç›®": "è©¦é¡Œ",
                        "è§£ç­”": "ç­”æ¡ˆ",
                        "å‹˜èª¤": "æ›´æ­£ç­”æ¡ˆ"
                    }
                    
                    # ä½¿ç”¨æ˜ å°„è¡¨ä¾†æ¨™æº–åŒ–æª”æ¡ˆé¡å‹å‘½å
                    normalized_type = file_type_mapping.get(file_type, file_type)
                    
                    # å»ºç«‹åŒ…å«å¹´åº¦å’Œç§‘ç›®åçš„æª”æ¡ˆåç¨±
                    file_name = f"æ°‘åœ‹{year}å¹´_{subject_name}_{normalized_type}.pdf"
                    
                    file_path = os.path.join(subject_folder, file_name)

                    # ç§»é™¤æª”æ¡ˆå­˜åœ¨æª¢æŸ¥ï¼Œç¸½æ˜¯å˜—è©¦ä¸‹è¼‰ä»¥ç¢ºä¿å®Œæ•´æ€§
                    
                    pdf_url = urljoin(BASE_URL, url)
                    success, result = download_file(session, pdf_url, file_path)
                    
                    file_count += 1
                    if file_count % 10 == 0:
                        print(f"   â¬‡ï¸  é€²åº¦: {file_count}/{total_files}", end='\r')
                    
                    if success:
                        stats['success'] += 1
                        stats['total_size'] += result
                        # å°æ–¼æˆåŠŸä¸‹è¼‰çš„æª”æ¡ˆï¼Œç­‰å¾…çŸ­æ™‚é–“é¿å…éæ–¼é »ç¹çš„è«‹æ±‚
                        time.sleep(0.5)
                    else:
                        stats['failed'] += 1
                        stats['failed_list'].append({
                            'year': year,
                            'exam': exam_name,
                            'category': category_name,
                            'subject': subject_info['original_name'],
                            'type': file_type,
                            'reason': result,
                            'url': pdf_url,
                            'file_path': file_path,
                            'timestamp': datetime.now().isoformat()
                        })
                        # å°æ–¼å¤±æ•—çš„æª”æ¡ˆï¼Œç­‰å¾…æ›´é•·æ™‚é–“å†ç¹¼çºŒ
                        time.sleep(2)
        
        print(f"   âœ… å®Œæˆ: {file_count}/{total_files} å€‹æª”æ¡ˆ")
        stats['completed_exams'] += 1
        
    except Exception as e:
        print(f"   âŒ è™•ç†å¤±æ•—: {e}")
        stats['failed_exams'] += 1

def retry_failed_downloads(session, failed_list, base_folder):
    """
    é‡è©¦å¤±æ•—çš„ä¸‹è¼‰ï¼ˆç¬¬äºŒè¼ªï¼‰

    Args:
        session: requests.Sessionå¯¦ä¾‹
        failed_list: å¤±æ•—é …ç›®åˆ—è¡¨
        base_folder: åŸºç¤è³‡æ–™å¤¾

    Returns:
        é‡è©¦çµ±è¨ˆçµæœ
    """
    print("\n" + "="*70)
    print("ğŸ”„ é–‹å§‹é‡è©¦å¤±æ•—çš„ä¸‹è¼‰ï¼ˆç¬¬äºŒè¼ª - 15æ¬¡é‡è©¦ï¼‰")
    print("="*70)

    retry_stats = {
        'success': 0,
        'still_failed': 0,
        'still_failed_list': []
    }

    total = len(failed_list)
    for idx, item in enumerate(failed_list, 1):
        print(f"\nğŸ”„ [{idx}/{total}] é‡è©¦: {item['subject']} - {item['type']}")
        print(f"   ğŸ“ {item['file_path']}")

        # ç¬¬äºŒè¼ªä½¿ç”¨æ›´é•·çš„ç­‰å¾…æ™‚é–“
        time.sleep(3)

        success, result = download_file(
            session,
            item['url'],
            item['file_path'],
            max_retries=15  # ç¬¬äºŒè¼ªä½¿ç”¨æ›´å¤šé‡è©¦æ¬¡æ•¸
        )

        if success:
            retry_stats['success'] += 1
            print(f"   âœ… é‡è©¦æˆåŠŸï¼å¤§å°: {result/1024:.1f}KB")
        else:
            retry_stats['still_failed'] += 1
            retry_stats['still_failed_list'].append(item)
            print(f"   âŒ ä»ç„¶å¤±æ•—: {result}")

        # é¡¯ç¤ºé€²åº¦
        success_rate = (retry_stats['success'] / idx) * 100
        print(f"   ğŸ“Š ç•¶å‰é‡è©¦æˆåŠŸç‡: {success_rate:.1f}% ({retry_stats['success']}/{idx})")

    return retry_stats

def main():
    # é¡¯ç¤ºæ­¡è¿ç•«é¢
    print_banner()
    
    # è‡ªå‹•è¨­å®šæ°‘åœ‹114å¹´
    save_dir = "114å¹´è€ƒå¤é¡Œ_èª¿è©¦ç‰ˆ"
    years = [114]
    keywords = [
        "è­¦å¯Ÿäººå“¡è€ƒè©¦",
        "ä¸€èˆ¬è­¦å¯Ÿäººå“¡è€ƒè©¦",
        "å¸æ³•äººå“¡è€ƒè©¦",
        "åœ‹å®¶å®‰å…¨æƒ…å ±äººå“¡è€ƒè©¦",
        "ç§»æ°‘è¡Œæ”¿äººå“¡è€ƒè©¦"
    ]
    
    print(f"âœ… è‡ªå‹•è¨­å®š: æ°‘åœ‹114å¹´è€ƒå¤é¡Œä¸‹è¼‰")
    print(f"ğŸ“ å„²å­˜ä½ç½®: {os.path.abspath(save_dir)}")
    print(f"ğŸ” è€ƒè©¦ç¯©é¸: è­¦å¯Ÿèˆ‡å¸æ³•ç›¸é—œè€ƒè©¦")
    print("="*70)
    
    # å»ºç«‹å„²å­˜è³‡æ–™å¤¾
    os.makedirs(save_dir, exist_ok=True)
    
    # é–‹å§‹ä¸‹è¼‰
    stats = {
        'success': 0,
        'failed': 0,
        'skipped': 0,
        'total_size': 0,
        'completed_exams': 0,
        'failed_exams': 0,
        'empty_exams': 0,
        'failed_list': []
    }
    
    # ä½¿ç”¨å¢å¼·å‹Session
    session = create_robust_session()

    start_time = datetime.now()

    try:
        print("\n" + "="*70)
        print("ğŸš€ é–‹å§‹ä¸‹è¼‰ï¼ˆå¢å¼·æ¨¡å¼ï¼š10æ¬¡é‡è©¦ + PDFé©—è­‰ï¼‰")
        print("="*70)
        
        for year in years:
            print(f"\nğŸ” æ­£åœ¨æƒææ°‘åœ‹ {year} å¹´çš„è€ƒè©¦...")
            
            exams = get_exam_list_by_year(session, year, keywords)
            
            if not exams:
                print(f"   âš ï¸ æ°‘åœ‹ {year} å¹´æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„è€ƒè©¦")
                continue
            
            print(f"   âœ… æ‰¾åˆ° {len(exams)} å€‹è€ƒè©¦")
            
            for exam in exams:
                download_exam(session, exam, save_dir, stats)
                time.sleep(0.5)
        
        elapsed_time = datetime.now() - start_time

        # ç”¢ç”Ÿç¬¬ä¸€è¼ªå ±å‘Š
        print("\n" + "="*70)
        print("ğŸ“Š ç¬¬ä¸€è¼ªä¸‹è¼‰å®Œæˆçµ±è¨ˆ")
        print("="*70)
        print(f"â±ï¸  ç¸½è€—æ™‚: {elapsed_time}")
        print(f"âœ… æˆåŠŸä¸‹è¼‰: {stats['success']} å€‹æª”æ¡ˆ")
        print(f"â­ï¸  å·²è·³é: {stats['skipped']} å€‹æª”æ¡ˆ")
        print(f"âŒ å¤±æ•—: {stats['failed']} å€‹æª”æ¡ˆ")
        print(f"ğŸ“¦ ç¸½å¤§å°: {stats['total_size'] / (1024*1024):.2f} MB")

        if stats['failed'] > 0:
            first_round_success_rate = (stats['success'] / (stats['success'] + stats['failed'])) * 100
            print(f"ğŸ“ˆ ç¬¬ä¸€è¼ªæˆåŠŸç‡: {first_round_success_rate:.1f}%")

        # ç¬¬äºŒè¼ªï¼šé‡è©¦å¤±æ•—çš„ä¸‹è¼‰
        if stats['failed_list']:
            print(f"\nâš ï¸  ç¬¬ä¸€è¼ªæœ‰ {len(stats['failed_list'])} å€‹å¤±æ•—ï¼Œå•Ÿå‹•ç¬¬äºŒè¼ªé‡è©¦...")

            retry_stats = retry_failed_downloads(session, stats['failed_list'], save_dir)

            # æ›´æ–°çµ±è¨ˆ
            stats['success'] += retry_stats['success']
            stats['failed'] = retry_stats['still_failed']
            stats['failed_list'] = retry_stats['still_failed_list']

            print(f"\nğŸ“Š ç¬¬äºŒè¼ªé‡è©¦çµæœ:")
            print(f"   âœ… é‡è©¦æˆåŠŸ: {retry_stats['success']} å€‹")
            print(f"   âŒ ä»ç„¶å¤±æ•—: {retry_stats['still_failed']} å€‹")

        # æœ€çµ‚çµ±è¨ˆ
        elapsed_time = datetime.now() - start_time
        print("\n" + "="*70)
        print("ğŸ“Š æœ€çµ‚å®Œæ•´çµ±è¨ˆ")
        print("="*70)
        print(f"â±ï¸  ç¸½è€—æ™‚: {elapsed_time}")
        print(f"âœ… æˆåŠŸä¸‹è¼‰: {stats['success']} å€‹æª”æ¡ˆ")
        print(f"â­ï¸  å·²è·³é: {stats['skipped']} å€‹æª”æ¡ˆ")
        print(f"âŒ æœ€çµ‚å¤±æ•—: {stats['failed']} å€‹æª”æ¡ˆ")
        print(f"ğŸ“¦ ç¸½å¤§å°: {stats['total_size'] / (1024*1024):.2f} MB")

        # è¨ˆç®—æœ€çµ‚æˆåŠŸç‡
        if stats['success'] + stats['failed'] > 0:
            final_success_rate = (stats['success'] / (stats['success'] + stats['failed'])) * 100
            print(f"ğŸ“ˆ æœ€çµ‚æˆåŠŸç‡: {final_success_rate:.1f}%")

            if final_success_rate >= 99:
                print("ğŸ† å„ªç§€ï¼æˆåŠŸç‡é”åˆ°99%ä»¥ä¸Š")
            elif final_success_rate >= 95:
                print("âœ¨ è‰¯å¥½ï¼æˆåŠŸç‡é”åˆ°95%ä»¥ä¸Š")
            elif final_success_rate >= 90:
                print("ğŸ‘ ä¸éŒ¯ï¼æˆåŠŸç‡é”åˆ°90%ä»¥ä¸Š")
        print("="*70)
        
        # å„²å­˜å¤±æ•—æ¸…å–®
        if stats['failed_list']:
            log_file = os.path.join(save_dir, 'ä¸‹è¼‰å¤±æ•—æ¸…å–®.json')
            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump(stats['failed_list'], f, ensure_ascii=False, indent=2)
            
            txt_file = os.path.join(save_dir, 'ä¸‹è¼‰å¤±æ•—æ¸…å–®.txt')
            with open(txt_file, 'w', encoding='utf-8') as f:
                f.write(f"ä¸‹è¼‰å¤±æ•—æ¸…å–® (å…± {len(stats['failed_list'])} å€‹)\n")
                f.write("="*70 + "\n\n")
                for idx, item in enumerate(stats['failed_list'], 1):
                    f.write(f"{idx}. æ°‘åœ‹ {item['year']} å¹´ - {item['exam']}\n")
                    f.write(f"   é¡ç§‘: {item['category']}\n")
                    f.write(f"   ç§‘ç›®: {item['subject']}\n")
                    f.write(f"   é¡å‹: {item['type']}\n")
                    f.write(f"   åŸå› : {item['reason']}\n")
                    f.write("-"*70 + "\n\n")
            
            print(f"\nâš ï¸  å¤±æ•—æ¸…å–®å·²å„²å­˜è‡³: {txt_file}")
        
        print(f"\nğŸ‰ æ‰€æœ‰ä½œæ¥­å®Œæˆï¼æª”æ¡ˆä½æ–¼: {save_dir}")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ä½¿ç”¨è€…ä¸­æ–·ä¸‹è¼‰")
        print(f"å·²ä¸‹è¼‰: {stats['success']} å€‹æª”æ¡ˆ")
    except Exception as e:
        print(f"\nâŒ ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
    finally:
        session.close()

if __name__ == "__main__":
    main()
