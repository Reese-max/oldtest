#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡æ¸¬è©¦ç„¡æ¨™ç±¤æ ¼å¼æ”¯æ´
æ¸¬è©¦è€ƒé¸éƒ¨è€ƒå¤é¡Œå®Œæ•´åº«ä¸­çš„æ‰€æœ‰PDF
"""

import sys
import os
import json
from pathlib import Path
from datetime import datetime
from collections import defaultdict

sys.path.insert(0, '/home/user/oldtest')

from src.processors.archaeology_processor import ArchaeologyProcessor
from src.core.enhanced_pdf_processor import EnhancedPDFProcessor
from src.core.no_label_question_parser import NoLabelQuestionParser


def find_all_test_pdfs(base_path):
    """æŸ¥æ‰¾æ‰€æœ‰è©¦é¡ŒPDF"""
    pdf_files = []
    for pdf_path in Path(base_path).rglob("è©¦é¡Œ.pdf"):
        # æŸ¥æ‰¾å°æ‡‰çš„ç­”æ¡ˆPDF
        parent_dir = pdf_path.parent
        answer_path = parent_dir / "ç­”æ¡ˆ.pdf"

        # æå–ç§‘ç›®ä¿¡æ¯
        parts = str(pdf_path.parent).split('/')
        exam_type = parts[-3] if len(parts) >= 3 else "æœªçŸ¥"
        position = parts[-2] if len(parts) >= 2 else "æœªçŸ¥"
        subject = parts[-1] if len(parts) >= 1 else "æœªçŸ¥"

        pdf_files.append({
            'exam_type': exam_type,
            'position': position,
            'subject': subject,
            'pdf_path': str(pdf_path),
            'answer_path': str(answer_path) if answer_path.exists() else None,
            'full_name': f"{exam_type}/{position}/{subject}"
        })

    return pdf_files


def test_single_pdf(pdf_info, output_base_dir='batch_test_output'):
    """æ¸¬è©¦å–®ä¸€PDF"""
    result = {
        'name': pdf_info['full_name'],
        'subject': pdf_info['subject'],
        'exam_type': pdf_info['exam_type'],
        'position': pdf_info['position'],
        'success': False,
        'questions_count': 0,
        'answers_count': 0,
        'match_rate': 0.0,
        'errors': [],
        'warnings': [],
        'processing_time': 0,
        'pdf_quality': 0.0,
        'parser_used': None
    }

    try:
        start_time = datetime.now()

        # å‰µå»ºè™•ç†å™¨
        processor = ArchaeologyProcessor()

        # å…ˆæ¸¬è©¦PDFæå–è³ªé‡
        pdf_processor = EnhancedPDFProcessor()
        extraction_result = pdf_processor.extract_with_best_method(pdf_info['pdf_path'])
        result['pdf_quality'] = extraction_result.get('quality', 0.0)

        # æ¸¬è©¦é¡Œç›®è§£æ
        text = extraction_result['text']
        parser = NoLabelQuestionParser()
        questions = parser.parse_no_label_questions(text)

        result['questions_count'] = len(questions)
        result['parser_used'] = 'NoLabelQuestionParser'

        # å¦‚æœæœ‰ç­”æ¡ˆPDFï¼Œæå–ç­”æ¡ˆ
        if pdf_info['answer_path']:
            answer_text = pdf_processor.extract_text(pdf_info['answer_path'])
            from src.core.answer_processor import AnswerProcessor
            answer_proc = AnswerProcessor()
            answers = answer_proc.extract_answers(answer_text)
            result['answers_count'] = len(answers)

            # è¨ˆç®—ç­”æ¡ˆå°æ‡‰ç‡
            if questions and answers:
                matched = 0
                for q in questions:
                    q_num = str(q.get('é¡Œè™Ÿ', ''))
                    if q_num in answers:
                        matched += 1
                result['match_rate'] = (matched / len(questions)) * 100 if questions else 0

        # åˆ¤æ–·æˆåŠŸ
        if result['questions_count'] > 0:
            result['success'] = True

            # æª¢æŸ¥é¡Œç›®è³ªé‡
            if result['questions_count'] < 10:
                result['warnings'].append(f"é¡Œç›®æ•¸é‡è¼ƒå°‘: {result['questions_count']}é¡Œ")

            # æª¢æŸ¥ç­”æ¡ˆå°æ‡‰
            if pdf_info['answer_path'] and result['match_rate'] < 80:
                result['warnings'].append(f"ç­”æ¡ˆå°æ‡‰ç‡è¼ƒä½: {result['match_rate']:.1f}%")
        else:
            result['errors'].append("æœªè§£æåˆ°ä»»ä½•é¡Œç›®")

        end_time = datetime.now()
        result['processing_time'] = (end_time - start_time).total_seconds()

    except Exception as e:
        result['errors'].append(str(e))
        result['success'] = False

    return result


def main():
    print("="*80)
    print("ğŸ§ª è€ƒé¸éƒ¨å®˜æ–¹æ ¼å¼æ‰¹é‡æ¸¬è©¦")
    print("="*80)
    print()

    # æŸ¥æ‰¾æ‰€æœ‰PDF
    base_path = "è€ƒé¸éƒ¨è€ƒå¤é¡Œå®Œæ•´åº«/æ°‘åœ‹114å¹´"
    print(f"ğŸ“ æƒæç›®éŒ„: {base_path}")
    pdf_files = find_all_test_pdfs(base_path)
    print(f"âœ… æ‰¾åˆ° {len(pdf_files)} å€‹è©¦é¡ŒPDF")
    print()

    # æŒ‰è€ƒè©¦é¡å‹åˆ†çµ„
    by_exam_type = defaultdict(list)
    for pdf in pdf_files:
        by_exam_type[pdf['exam_type']].append(pdf)

    print("ğŸ“Š è€ƒè©¦é¡å‹åˆ†å¸ƒ:")
    for exam_type, pdfs in sorted(by_exam_type.items()):
        print(f"  {exam_type}: {len(pdfs)} å€‹")
    print()

    # æ‰¹é‡æ¸¬è©¦
    print("="*80)
    print("ğŸš€ é–‹å§‹æ‰¹é‡æ¸¬è©¦")
    print("="*80)
    print()

    results = []
    total = len(pdf_files)

    for i, pdf_info in enumerate(pdf_files, 1):
        print(f"[{i}/{total}] æ¸¬è©¦: {pdf_info['full_name']}")
        print(f"  PDF: {pdf_info['pdf_path']}")

        result = test_single_pdf(pdf_info)
        results.append(result)

        if result['success']:
            print(f"  âœ… æˆåŠŸ: {result['questions_count']} é¡Œ")
            if result['answers_count'] > 0:
                print(f"     ç­”æ¡ˆ: {result['answers_count']} å€‹ (å°æ‡‰ç‡: {result['match_rate']:.1f}%)")
            if result['warnings']:
                for warn in result['warnings']:
                    print(f"     âš ï¸  {warn}")
        else:
            print(f"  âŒ å¤±æ•—: {', '.join(result['errors'])}")

        print(f"  è™•ç†æ™‚é–“: {result['processing_time']:.2f}ç§’")
        print()

    # ç”Ÿæˆçµ±è¨ˆå ±å‘Š
    print("="*80)
    print("ğŸ“Š æ¸¬è©¦çµ±è¨ˆ")
    print("="*80)
    print()

    success_count = sum(1 for r in results if r['success'])
    success_rate = (success_count / total * 100) if total > 0 else 0

    total_questions = sum(r['questions_count'] for r in results)
    avg_questions = total_questions / success_count if success_count > 0 else 0

    total_answers = sum(r['answers_count'] for r in results)
    avg_match_rate = sum(r['match_rate'] for r in results if r['match_rate'] > 0) / len([r for r in results if r['match_rate'] > 0]) if any(r['match_rate'] > 0 for r in results) else 0

    print(f"ç¸½æ¸¬è©¦æ•¸: {total}")
    print(f"æˆåŠŸæ•¸: {success_count}")
    print(f"å¤±æ•—æ•¸: {total - success_count}")
    print(f"æˆåŠŸç‡: {success_rate:.1f}%")
    print()
    print(f"ç¸½é¡Œæ•¸: {total_questions}")
    print(f"å¹³å‡é¡Œæ•¸: {avg_questions:.1f} é¡Œ/PDF")
    print(f"ç¸½ç­”æ¡ˆæ•¸: {total_answers}")
    print(f"å¹³å‡ç­”æ¡ˆå°æ‡‰ç‡: {avg_match_rate:.1f}%")
    print()

    # æŒ‰è€ƒè©¦é¡å‹çµ±è¨ˆ
    print("æŒ‰è€ƒè©¦é¡å‹çµ±è¨ˆ:")
    for exam_type in sorted(by_exam_type.keys()):
        exam_results = [r for r in results if r['exam_type'] == exam_type]
        exam_success = sum(1 for r in exam_results if r['success'])
        exam_total = len(exam_results)
        exam_rate = (exam_success / exam_total * 100) if exam_total > 0 else 0
        exam_questions = sum(r['questions_count'] for r in exam_results)

        print(f"  {exam_type}:")
        print(f"    æ¸¬è©¦æ•¸: {exam_total}")
        print(f"    æˆåŠŸç‡: {exam_rate:.1f}% ({exam_success}/{exam_total})")
        print(f"    ç¸½é¡Œæ•¸: {exam_questions}")
    print()

    # åˆ—å‡ºå¤±æ•—çš„æ¡ˆä¾‹
    failed_results = [r for r in results if not r['success']]
    if failed_results:
        print("âŒ å¤±æ•—æ¡ˆä¾‹:")
        for r in failed_results:
            print(f"  {r['name']}")
            for err in r['errors']:
                print(f"    éŒ¯èª¤: {err}")
        print()

    # åˆ—å‡ºè­¦å‘Š
    warned_results = [r for r in results if r['warnings']]
    if warned_results:
        print("âš ï¸  è­¦å‘Šæ¡ˆä¾‹:")
        for r in warned_results:
            print(f"  {r['name']}")
            for warn in r['warnings']:
                print(f"    {warn}")
        print()

    # ä¿å­˜è©³ç´°çµæœ
    output_file = "batch_test_results.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'test_time': datetime.now().isoformat(),
            'total': total,
            'success': success_count,
            'success_rate': success_rate,
            'total_questions': total_questions,
            'total_answers': total_answers,
            'avg_match_rate': avg_match_rate,
            'results': results
        }, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“„ è©³ç´°çµæœå·²ä¿å­˜: {output_file}")
    print()

    # æœ€çµ‚è©•ä¼°
    print("="*80)
    print("âœ… æœ€çµ‚è©•ä¼°")
    print("="*80)
    print()

    if success_rate >= 90:
        print("ğŸ‰ å„ªç§€ï¼ç³»çµ±è¡¨ç¾å„ªç•°")
        rating = "â­â­â­â­â­"
    elif success_rate >= 75:
        print("âœ… è‰¯å¥½ï¼ç³»çµ±è¡¨ç¾ç©©å®š")
        rating = "â­â­â­â­â˜†"
    elif success_rate >= 60:
        print("âš ï¸  ä¸€èˆ¬ï¼Œä»æœ‰æ”¹é€²ç©ºé–“")
        rating = "â­â­â­â˜†â˜†"
    else:
        print("âŒ éœ€è¦æ”¹é€²")
        rating = "â­â­â˜†â˜†â˜†"

    print(f"ç³»çµ±è©•ç´š: {rating}")
    print(f"æˆåŠŸç‡: {success_rate:.1f}%")
    print(f"è™•ç†èƒ½åŠ›: {total_questions} é¡Œ")
    print()


if __name__ == "__main__":
    main()
