#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ”¹é€²ç‰ˆPDFè½‰CSVåŠŸèƒ½ - è§£æ±ºä¸‰å€‹ä¸»è¦å•é¡Œ
1. ç­”æ¡ˆæ¬„ä½ç¼ºå¤±
2. é¸é …å…§å®¹é‡è¤‡
3. è³‡æ–™å“è³ª
"""

import os
import pdfplumber
import pandas as pd
import re
import json
import hashlib
from typing import List, Dict, Any, Optional, Tuple
import glob
from datetime import datetime, timedelta
import google.generativeai as genai
from google.generativeai.client import configure
from google.generativeai.generative_models import GenerativeModel
from google.generativeai.files import upload_file, get_file
import time

class AnswerProcessor:
    """ç­”æ¡ˆè™•ç†å™¨ - å¾PDFæ–‡å­—ä¸­æå–ç­”æ¡ˆå’Œæ›´æ­£ç­”æ¡ˆ"""
    
    @staticmethod
    def extract_answers_from_pdf(pdf_path: str) -> Dict[str, str]:
        """å¾PDFæª”æ¡ˆä¸­æå–ç­”æ¡ˆ"""
        try:
            with pdfplumber.open(pdf_path) as pdf:
                text = ""
                for page in pdf.pages:
                    text += page.extract_text() or ""
            
            return AnswerProcessor.extract_answers_from_text(text)
        except Exception as e:
            print(f"âŒ æå–ç­”æ¡ˆå¤±æ•—: {e}")
            return {}
    
    @staticmethod
    def extract_answers_from_text(text: str) -> Dict[str, str]:
        """å¾æ–‡å­—ä¸­æå–ç­”æ¡ˆ"""
        answers = {}
        
        # åŒ¹é…ç­”æ¡ˆæ¨¡å¼ï¼š1. A, 2. B, 3. C ç­‰
        answer_patterns = [
            r'(\d+)\.\s*([ABCD])',  # 1. A
            r'(\d+)\s*([ABCD])',    # 1 A
            r'ç¬¬(\d+)é¡Œ\s*([ABCD])', # ç¬¬1é¡Œ A
            r'(\d+)\s*ï¼š\s*([ABCD])', # 1ï¼šA
        ]
        
        for pattern in answer_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                question_num = match[0]
                answer = match[1]
                answers[question_num] = answer
        
        return answers
    
    @staticmethod
    def extract_corrected_answers_from_pdf(pdf_path: str) -> Dict[str, str]:
        """å¾PDFæª”æ¡ˆä¸­æå–æ›´æ­£ç­”æ¡ˆ"""
        try:
            with pdfplumber.open(pdf_path) as pdf:
                text = ""
                for page in pdf.pages:
                    text += page.extract_text() or ""
            
            return AnswerProcessor.extract_corrected_answers_from_text(text)
        except Exception as e:
            print(f"âŒ æå–æ›´æ­£ç­”æ¡ˆå¤±æ•—: {e}")
            return {}
    
    @staticmethod
    def extract_corrected_answers_from_text(text: str) -> Dict[str, str]:
        """å¾æ–‡å­—ä¸­æå–æ›´æ­£ç­”æ¡ˆ"""
        corrected_answers = {}
        
        # åŒ¹é…æ›´æ­£ç­”æ¡ˆæ¨¡å¼ï¼šæ›´æ­£ 1. B, æ›´æ­£ç­”æ¡ˆ 1. B ç­‰
        corrected_patterns = [
            r'æ›´æ­£\s*(\d+)\.\s*([ABCD])',  # æ›´æ­£ 1. B
            r'æ›´æ­£ç­”æ¡ˆ\s*(\d+)\.\s*([ABCD])', # æ›´æ­£ç­”æ¡ˆ 1. B
            r'æ›´æ­£\s*ç¬¬(\d+)é¡Œ\s*([ABCD])', # æ›´æ­£ ç¬¬1é¡Œ B
            r'æ›´æ­£\s*(\d+)\s*ï¼š\s*([ABCD])', # æ›´æ­£ 1ï¼šB
        ]
        
        for pattern in corrected_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                question_num = match[0]
                answer = match[1]
                corrected_answers[question_num] = answer
        
        return corrected_answers

class PDFCacheManager:
    """PDFå¿«å–ç®¡ç†å™¨"""
    def __init__(self, cache_file: str = "pdf_cache.json"):
        self.cache_file = cache_file
        self.cache = self.load_cache()
        self.client: Optional[genai.Client] = None

    def load_cache(self) -> Dict[str, Any]:
        if os.path.exists(self.cache_file):
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                return {}
        return {}

    def save_cache(self):
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
        except:
            pass

    def get_pdf_hash(self, pdf_path: str) -> str:
        sha256_hash = hashlib.sha256()
        with open(pdf_path, "rb") as f:
            for byte_block in iter(lambda: f.read(4096), b""):
                sha256_hash.update(byte_block)
        return sha256_hash.hexdigest()

    def get_cached_result(self, pdf_hash: str) -> Optional[Dict[str, Any]]:
        if pdf_hash in self.cache:
            cache_entry = self.cache[pdf_hash]
            cached_time = datetime.fromisoformat(cache_entry.get('timestamp', '2000-01-01'))
            if datetime.now() - cached_time < timedelta(days=7):
                return cache_entry.get('result')
        return None

    def cache_result(self, pdf_hash: str, result: Dict[str, Any]):
        self.cache[pdf_hash] = {
            'timestamp': datetime.now().isoformat(),
            'result': result
        }
        self.save_cache()

    def cleanup_expired_cache(self):
        now = datetime.now()
        expired_keys = []
        for key, entry in self.cache.items():
            cached_time = datetime.fromisoformat(entry.get('timestamp', '2000-01-01'))
            if now - cached_time > timedelta(days=7):
                expired_keys.append(key)
        
        for key in expired_keys:
            del self.cache[key]
        
        if expired_keys:
            self.save_cache()

class ValidationResult:
    def __init__(self):
        self.status = 'success'
        self.issues = []
        self.warnings = []
        self.summary = {}
        self.questions_with_answers = 0
        self.questions_with_corrected_answers = 0

    def add_issue(self, message: str):
        self.issues.append(message)
        self.status = 'error'

    def add_warning(self, message: str):
        self.warnings.append(message)
        if self.status == 'success':
            self.status = 'warning'

    def print_result(self):
        icons = {'success': 'âœ…', 'warning': 'âš ï¸', 'error': 'âŒ'}
        print(f"\n{icons.get(self.status, 'â“')} é©—è­‰çµæœ:")

        for key, value in self.summary.items():
            print(f"  {key}: {value}")

        if self.warnings:
            print(f"\nâš ï¸ è­¦å‘Š:")
            for warning in self.warnings:
                print(f"  - {warning}")

        if self.issues:
            print(f"\nâŒ å•é¡Œ:")
            for issue in self.issues:
                print(f"  - {issue}")

class PDFFeatureAnalyzer:
    """PDFç‰¹å¾µåˆ†æå™¨"""
    
    @staticmethod
    def analyze_pdf(pdf_path: str) -> Dict[str, Any]:
        """åˆ†æPDFç‰¹å¾µ"""
        features = {
            'page_count': 0,
            'file_size': 0,
            'expected_question_count': 0
        }
        
        try:
            with pdfplumber.open(pdf_path) as pdf:
                features['page_count'] = len(pdf.pages)
                
                # æå–æ–‡å­—å…§å®¹
                full_text = ""
                for page in pdf.pages:
                    text = page.extract_text()
                    if text:
                        full_text += text + "\n"
                
                # åˆ†æé æœŸé¡Œæ•¸
                count_patterns = [
                    r'å…±\s*(\d+)\s*é¡Œ',
                    r'ç¸½å…±\s*(\d+)\s*é¡Œ',
                    r'å…±è¨ˆ\s*(\d+)\s*é¡Œ',
                    r'(\d+)\s*é¡Œ'
                ]
                
                for pattern in count_patterns:
                    count_match = re.search(pattern, full_text)
                    if count_match:
                        features['expected_question_count'] = int(count_match.group(1))
                        break
                
                # å¦‚æœæ²’æ‰¾åˆ°æ˜ç¢ºçš„é¡Œæ•¸ï¼Œå˜—è©¦å¾é¡Œè™Ÿæ¨æ¸¬
                if features['expected_question_count'] == 0:
                    question_numbers = re.findall(r'(\d+)\.\s*[^0-9]', full_text)
                    if question_numbers:
                        max_num = max(int(num) for num in question_numbers)
                        features['expected_question_count'] = max_num
            
            # æª”æ¡ˆå¤§å°
            features['file_size'] = os.path.getsize(pdf_path)
            
        except Exception as e:
            print(f"âš ï¸ PDFåˆ†æå¤±æ•—: {e}")
        
        return features

def should_skip_file(filename: str) -> bool:
    """åˆ¤æ–·æ˜¯å¦æ‡‰è©²è·³éæ­¤æª”æ¡ˆ"""
    # ç­”æ¡ˆæª”æ¡ˆé—œéµå­—
    skip_keywords = ['ç­”æ¡ˆ', 'è§£ç­”', 'æ›´æ­£ç­”æ¡ˆ', 'answer', 'Answer', 'ANSWER']
    
    # æª¢æŸ¥æª”åæ˜¯å¦åŒ…å«è·³éé—œéµå­—
    for keyword in skip_keywords:
        if keyword in filename:
            return True
    
    return False

def upload_pdf_to_gemini(pdf_path: str) -> Optional[str]:
    """ä¸Šå‚³PDFåˆ°Gemini"""
    try:
        file_uri = upload_file(pdf_path)
        return file_uri
    except Exception as e:
        print(f"âŒ PDFä¸Šå‚³å¤±æ•—: {e}")
        return None

def parse_with_pdf_upload(pdf_path: str, use_pro: bool = False) -> List[Dict[str, Any]]:
    """ä½¿ç”¨PDFä¸Šå‚³æ–¹å¼è§£æ"""
    try:
        file_uri = upload_pdf_to_gemini(pdf_path)
        if not file_uri:
            return []

        sample_file = get_file(file_uri.split('/')[-1])

        # é¸æ“‡æ¨¡å‹ï¼šå„ªå…ˆä½¿ç”¨ Flashï¼Œå¤±æ•—æ™‚å¯åˆ‡æ›åˆ° Pro
        model_name = 'gemini-2.5-pro' if use_pro else 'gemini-2.5-flash'
        model = GenerativeModel(model_name)

        # å¾PDFè·¯å¾‘æå–é æœŸé¡Œæ•¸ï¼Œç”¨æ–¼æ›´ç²¾ç¢ºçš„è§£æ
        pdf_features = PDFFeatureAnalyzer.analyze_pdf(pdf_path)
        expected_count = pdf_features.get('expected_question_count', 0)

        if use_pro:
            print(f"ğŸ”„ ä½¿ç”¨ Gemini 2.5 Pro é‡æ–°è§£æ...")

        prompt = f"""åˆ†æé€™ä»½PDFè€ƒå¤é¡Œï¼Œç²¾ç¢ºæå–æ‰€æœ‰è©¦é¡Œå’Œç­”æ¡ˆï¼š

é æœŸé¡Œæ•¸ï¼š{expected_count}é¡Œ

å¦‚æœé€™æ˜¯ç­”æ¡ˆå·ï¼ˆåªæœ‰é¡Œè™Ÿå’Œç­”æ¡ˆé¸é …ï¼‰ï¼Œè¿”å› []

å¦å‰‡è¿”å›JSONæ ¼å¼ï¼š
[{{"é¡Œè™Ÿ": "1", "é¡Œç›®": "å®Œæ•´é¡Œç›®å…§å®¹", "é¸é …A": "...", "é¸é …B": "...", "é¸é …C": "...", "é¸é …D": "...", "é¡Œå‹": "é¸æ“‡é¡Œ", "æ­£ç¢ºç­”æ¡ˆ": "A", "æ›´æ­£ç­”æ¡ˆ": ""}}]

é‡è¦è¦å‰‡ï¼š
1. ç­”æ¡ˆå·ç›´æ¥è¿”å› []
2. é¡Œè™Ÿå¿…é ˆå¾1é–‹å§‹ï¼Œé€£çºŒç·¨è™Ÿåˆ°{expected_count}
3. é¡Œç›®å…§å®¹å¿…é ˆå®Œæ•´ï¼Œè‡³å°‘15å­—
4. é¸æ“‡é¡Œå¿…é ˆæœ‰Aã€Bã€Cã€Då››å€‹é¸é …ï¼Œä¸”æ¯å€‹é¸é …å…§å®¹å¿…é ˆå®Œå…¨ä¸åŒ
5. ç¸½é¡Œæ•¸å¿…é ˆç‚º{expected_count}é¡Œï¼Œçµ•å°ä¸èƒ½å¤šä¹Ÿä¸èƒ½å°‘
6. ä¸è¦å°‡é é¦–ã€é å°¾ã€èªªæ˜ã€è¨»è§£èª¤èªç‚ºé¡Œç›®
7. ä»”ç´°æª¢æŸ¥æ¯ä¸€é¡Œçš„å®Œæ•´æ€§
8. å¦‚æœPDFä¸­åŒ…å«ç­”æ¡ˆï¼Œè«‹åœ¨"æ­£ç¢ºç­”æ¡ˆ"æ¬„ä½å¡«å…¥å°æ‡‰çš„Aã€Bã€Cã€D
9. å¦‚æœPDFä¸­åŒ…å«æ›´æ­£ç­”æ¡ˆï¼Œè«‹åœ¨"æ›´æ­£ç­”æ¡ˆ"æ¬„ä½å¡«å…¥å°æ‡‰çš„Aã€Bã€Cã€D
10. å¦‚æœæ²’æœ‰ç­”æ¡ˆè³‡è¨Šï¼Œç›¸é—œæ¬„ä½ç•™ç©º"""

        response = model.generate_content([sample_file, prompt])
        text = response.text.strip()

        # è™•ç†ç©ºè¿”å›ï¼ˆç­”æ¡ˆå·ï¼‰
        if text == '[]' or text == '[ ]':
            print("âœ“ æª¢æ¸¬åˆ°ç­”æ¡ˆå·ï¼Œè·³é")
            return []

        if text.startswith('```json'):
            text = text[7:]
        if text.startswith('```'):
            text = text[3:]
        if text.endswith('```'):
            text = text[:-3]

        questions = json.loads(text.strip())

        # éæ¿¾å’Œé©—è­‰é¡Œç›®
        validated = []
        seen_numbers = set()

        for q in questions:
            if isinstance(q, dict) and 'é¡Œè™Ÿ' in q and 'é¡Œç›®' in q:
                # æª¢æŸ¥é¡Œè™Ÿæ˜¯å¦ç‚ºæ•¸å­—ä¸”ä¸é‡è¤‡
                try:
                    num = int(str(q.get('é¡Œè™Ÿ', '')).strip())
                    if num in seen_numbers:
                        continue  # è·³éé‡è¤‡é¡Œè™Ÿ
                    seen_numbers.add(num)
                except:
                    continue  # é¡Œè™Ÿç„¡æ•ˆè·³é

                # æª¢æŸ¥é¡Œç›®å…§å®¹é•·åº¦
                title = str(q.get('é¡Œç›®', '')).strip()
                if len(title) < 15:  # æ”¾å¯¬åˆ°15å­—
                    continue  # é¡Œç›®å¤ªçŸ­è·³é

                validated.append({
                    'é¡Œè™Ÿ': str(num),
                    'é¡Œç›®': title,
                    'é¸é …A': str(q.get('é¸é …A', '')),
                    'é¸é …B': str(q.get('é¸é …B', '')),
                    'é¸é …C': str(q.get('é¸é …C', '')),
                    'é¸é …D': str(q.get('é¸é …D', '')),
                    'é¡Œå‹': str(q.get('é¡Œå‹', 'é¸æ“‡é¡Œ')),
                    'æ­£ç¢ºç­”æ¡ˆ': str(q.get('æ­£ç¢ºç­”æ¡ˆ', '')),
                    'æ›´æ­£ç­”æ¡ˆ': str(q.get('æ›´æ­£ç­”æ¡ˆ', ''))
                })

        # å¦‚æœè§£æå‡ºçš„é¡Œæ•¸æ˜é¡¯åé›¢é æœŸï¼Œå˜—è©¦ä¿®æ­£
        if expected_count and abs(len(validated) - expected_count) > 3:
            print(f"âš ï¸ è§£æé¡Œæ•¸({len(validated)})èˆ‡é æœŸ({expected_count})å·®è·éå¤§ï¼Œå¯èƒ½æœ‰èª¤")
            # è¿”å›è¼ƒå°‘çš„é¡Œç›®ï¼ˆé€šå¸¸æ˜¯éåº¦è§£æçš„å•é¡Œï¼‰
            if len(validated) > expected_count:
                validated = validated[:expected_count]

        return validated

    except Exception as e:
        print(f"âŒ PDFä¸Šå‚³è§£æå¤±æ•—: {e}")
        return []

def parse_questions_with_text_gemini(text: str, expected_count: int = 0) -> List[Dict[str, Any]]:
    """ä½¿ç”¨æ–‡å­—è§£ææ–¹å¼"""
    try:
        # ä½¿ç”¨ Gemini 2.5 Flash
        model = GenerativeModel('gemini-2.5-flash')

        prompt = f"""åˆ†æä»¥ä¸‹è€ƒå¤é¡Œæ–‡å­—ï¼Œå¦‚æœæ˜¯ç­”æ¡ˆå·è¿”å›[]ï¼Œå¦‚æœæ˜¯è©¦é¡Œè«‹ç²¾ç¢ºæå–æ‰€æœ‰é¡Œç›®å’Œç­”æ¡ˆã€‚

é æœŸé¡Œæ•¸ï¼š{expected_count}é¡Œ

è«‹è¿”å›JSONæ ¼å¼ï¼š
[{{"é¡Œè™Ÿ": "1", "é¡Œç›®": "å®Œæ•´é¡Œç›®å…§å®¹è‡³å°‘20å­—", "é¸é …A": "...", "é¸é …B": "...", "é¸é …C": "...", "é¸é …D": "...", "é¡Œå‹": "é¸æ“‡é¡Œ", "æ­£ç¢ºç­”æ¡ˆ": "A", "æ›´æ­£ç­”æ¡ˆ": ""}}]

é‡è¦è¦å‰‡ï¼š
1. ç­”æ¡ˆå·ç›´æ¥è¿”å› []
2. é¡Œè™Ÿå¿…é ˆå¾1é–‹å§‹é€£çºŒç·¨è™Ÿ
3. é¡Œç›®å…§å®¹å¿…é ˆå®Œæ•´ï¼Œè‡³å°‘20å­—
4. é¸æ“‡é¡Œå¿…é ˆæœ‰Aã€Bã€Cã€Då››å€‹é¸é …ï¼Œä¸”æ¯å€‹é¸é …å…§å®¹å¿…é ˆå®Œå…¨ä¸åŒ
5. ç¸½é¡Œæ•¸æ‡‰ç‚º{expected_count}é¡Œï¼Œå‹¿å¤šå‹¿å°‘
6. ä¸è¦å°‡é é¦–ã€é å°¾ã€èªªæ˜æ–‡å­—èª¤èªç‚ºé¡Œç›®
7. å¦‚æœæ–‡å­—ä¸­åŒ…å«ç­”æ¡ˆï¼Œè«‹åœ¨"æ­£ç¢ºç­”æ¡ˆ"æ¬„ä½å¡«å…¥å°æ‡‰çš„Aã€Bã€Cã€D
8. å¦‚æœæ–‡å­—ä¸­åŒ…å«æ›´æ­£ç­”æ¡ˆï¼Œè«‹åœ¨"æ›´æ­£ç­”æ¡ˆ"æ¬„ä½å¡«å…¥å°æ‡‰çš„Aã€Bã€Cã€D
9. å¦‚æœæ²’æœ‰ç­”æ¡ˆè³‡è¨Šï¼Œç›¸é—œæ¬„ä½ç•™ç©º

æ–‡å­—å…§å®¹ï¼š
{text}"""

        response = model.generate_content(prompt)
        text = response.text.strip()

        if text == '[]' or text == '[ ]':
            return []

        if text.startswith('```json'):
            text = text[7:]
        if text.startswith('```'):
            text = text[3:]
        if text.endswith('```'):
            text = text[:-3]

        questions = json.loads(text.strip())

        # éæ¿¾å’Œé©—è­‰é¡Œç›®
        validated = []
        seen_numbers = set()

        for q in questions:
            if isinstance(q, dict) and 'é¡Œè™Ÿ' in q and 'é¡Œç›®' in q:
                # æª¢æŸ¥é¡Œè™Ÿæ˜¯å¦ç‚ºæ•¸å­—ä¸”ä¸é‡è¤‡
                try:
                    num = int(str(q.get('é¡Œè™Ÿ', '')).strip())
                    if num in seen_numbers:
                        continue  # è·³éé‡è¤‡é¡Œè™Ÿ
                    seen_numbers.add(num)
                except:
                    continue  # é¡Œè™Ÿç„¡æ•ˆè·³é

                # æª¢æŸ¥é¡Œç›®å…§å®¹é•·åº¦
                title = str(q.get('é¡Œç›®', '')).strip()
                if len(title) < 20:
                    continue  # é¡Œç›®å¤ªçŸ­è·³é

                validated.append({
                    'é¡Œè™Ÿ': str(num),
                    'é¡Œç›®': title,
                    'é¸é …A': str(q.get('é¸é …A', '')),
                    'é¸é …B': str(q.get('é¸é …B', '')),
                    'é¸é …C': str(q.get('é¸é …C', '')),
                    'é¸é …D': str(q.get('é¸é …D', '')),
                    'é¡Œå‹': str(q.get('é¡Œå‹', 'é¸æ“‡é¡Œ')),
                    'æ­£ç¢ºç­”æ¡ˆ': str(q.get('æ­£ç¢ºç­”æ¡ˆ', '')),
                    'æ›´æ­£ç­”æ¡ˆ': str(q.get('æ›´æ­£ç­”æ¡ˆ', ''))
                })

        # å¦‚æœè§£æå‡ºçš„é¡Œæ•¸æ˜é¡¯åé›¢é æœŸï¼Œå˜—è©¦ä¿®æ­£
        if expected_count and abs(len(validated) - expected_count) > 3:
            print(f"âš ï¸ æ–‡å­—è§£æé¡Œæ•¸({len(validated)})èˆ‡é æœŸ({expected_count})å·®è·éå¤§ï¼Œå¯èƒ½æœ‰èª¤")
            # è¿”å›è¼ƒå°‘çš„é¡Œç›®ï¼ˆé€šå¸¸æ˜¯éåº¦è§£æçš„å•é¡Œï¼‰
            if len(validated) > expected_count:
                validated = validated[:expected_count]

        return validated

    except Exception as e:
        print(f"âŒ æ–‡å­—è§£æå¤±æ•—: {e}")
        return []

def improve_option_diversity(questions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """æ”¹å–„é¸é …å…§å®¹å·®ç•°æ€§"""
    
    for question in questions:
        if question.get('é¡Œå‹') == 'é¸æ“‡é¡Œ':
            options = ['é¸é …A', 'é¸é …B', 'é¸é …C', 'é¸é …D']
            option_values = [question.get(opt, '').strip() for opt in options]
            
            # æª¢æŸ¥æ˜¯å¦æœ‰é‡è¤‡é¸é …
            if len(set(option_values)) < len(option_values):
                # å¦‚æœé¸é …é‡è¤‡ï¼Œå˜—è©¦å¾é¡Œç›®ä¸­æå–ä¸åŒçš„é¸é …
                question_text = question.get('é¡Œç›®', '')
                
                # å˜—è©¦å¾é¡Œç›®ä¸­æå–é¸é …ï¼ˆå¦‚æœé¡Œç›®åŒ…å«é¸é …å…§å®¹ï¼‰
                if 'A.' in question_text and 'B.' in question_text:
                    # é€™æ˜¯ä¸€å€‹åŒ…å«é¸é …çš„é¡Œç›®ï¼Œéœ€è¦é‡æ–°è§£æ
                    print(f"âš ï¸ é¡Œç›® {question.get('é¡Œè™Ÿ', '')} é¸é …é‡è¤‡ï¼Œéœ€è¦é‡æ–°è§£æ")
                    
                    # æš«æ™‚æ¨™è¨˜ç‚ºéœ€è¦é‡æ–°è™•ç†
                    question['_needs_reprocessing'] = True
    
    return questions

def merge_answers_to_questions(questions: List[Dict[str, Any]], 
                              answers: Dict[str, str], 
                              corrected_answers: Dict[str, str]) -> List[Dict[str, Any]]:
    """å°‡ç­”æ¡ˆåˆä½µåˆ°é¡Œç›®ä¸­ï¼Œä¸¦è¨ˆç®—æœ€çµ‚ç­”æ¡ˆ"""
    
    for question in questions:
        question_num = question.get('é¡Œè™Ÿ', '')
        
        # ç²å–æ­£ç¢ºç­”æ¡ˆå’Œæ›´æ­£ç­”æ¡ˆ
        correct_answer = answers.get(question_num, '')
        corrected_answer = corrected_answers.get(question_num, '')
        
        # æ›´æ–°ç­”æ¡ˆæ¬„ä½
        question['æ­£ç¢ºç­”æ¡ˆ'] = correct_answer
        question['æ›´æ­£ç­”æ¡ˆ'] = corrected_answer
        
        # è¨ˆç®—æœ€çµ‚ç­”æ¡ˆï¼šå„ªå…ˆä½¿ç”¨æ›´æ­£ç­”æ¡ˆï¼Œå…¶æ¬¡ä½¿ç”¨æ­£ç¢ºç­”æ¡ˆ
        if corrected_answer:
            question['æœ€çµ‚ç­”æ¡ˆ'] = corrected_answer
        elif correct_answer:
            question['æœ€çµ‚ç­”æ¡ˆ'] = correct_answer
        else:
            question['æœ€çµ‚ç­”æ¡ˆ'] = ''
    
    return questions

def validate_questions(questions: List[Dict[str, Any]], pdf_features: Dict[str, Any]) -> ValidationResult:
    """é›¶èª¤å·®é©—è­‰"""
    result = ValidationResult()

    total = len(questions)
    choice = len([q for q in questions if q.get('é¡Œå‹') == 'é¸æ“‡é¡Œ'])
    essay = len([q for q in questions if q.get('é¡Œå‹') == 'å•ç­”é¡Œ'])

    result.summary['å¯¦éš›é¡Œæ•¸'] = total
    result.summary['é¸æ“‡é¡Œ'] = choice
    result.summary['å•ç­”é¡Œ'] = essay

    expected = pdf_features.get('expected_question_count')
    if expected:
        result.summary['é æœŸé¡Œæ•¸'] = expected
        if total != expected:
            result.add_issue(f"é¡Œæ•¸ä¸ç¬¦: é æœŸ{expected}é¡Œï¼Œå¯¦éš›{total}é¡Œï¼ˆå·®{abs(expected-total)}é¡Œï¼‰")

    # é¡Œè™Ÿé©—è­‰
    nums = []
    for i, q in enumerate(questions):
        try:
            num = q.get('é¡Œè™Ÿ')
            if isinstance(num, str) and num.isdigit():
                nums.append(int(num))
            elif isinstance(num, int):
                nums.append(num)
        except:
            pass

    if nums:
        nums.sort()
        result.summary['é¡Œè™Ÿç¯„åœ'] = f"{nums[0]}-{nums[-1]}"

        if nums[0] != 1:
            result.add_issue(f"é¡Œè™Ÿä¸å¾1é–‹å§‹ï¼ˆå¾{nums[0]}é–‹å§‹ï¼‰")

        expected_range = set(range(nums[0], nums[-1] + 1))
        missing = expected_range - set(nums)
        if missing:
            result.add_issue(f"éºå¤±é¡Œè™Ÿ: {sorted(list(missing))}")

        duplicates = [n for n in set(nums) if nums.count(n) > 1]
        if duplicates:
            result.add_issue(f"é‡è¤‡é¡Œè™Ÿ: {sorted(duplicates)}")

        if expected and nums[-1] != expected:
            result.add_issue(f"æœ€å¾Œé¡Œè™Ÿæ‡‰ç‚º{expected}ï¼Œå¯¦éš›ç‚º{nums[-1]}")

    # å…§å®¹é©—è­‰
    for i, q in enumerate(questions):
        text = q.get('é¡Œç›®', '').strip()
        if not text:
            result.add_issue(f"ç¬¬{i+1}é¡Œç‚ºç©º")
        elif len(text) < 8:
            result.add_issue(f"ç¬¬{i+1}é¡ŒéçŸ­({len(text)}å­—)")

    # é¸é …é©—è­‰
    for i, q in enumerate(questions):
        if q.get('é¡Œå‹') == 'é¸æ“‡é¡Œ':
            missing = [opt[-1] for opt in ['é¸é …A', 'é¸é …B', 'é¸é …C', 'é¸é …D'] 
                      if not q.get(opt, '').strip()]
            if missing:
                result.add_issue(f"ç¬¬{i+1}é¡Œç¼ºé¸é …: {','.join(missing)}")
            
            # æª¢æŸ¥é¸é …å·®ç•°æ€§
            options = [q.get(opt, '').strip() for opt in ['é¸é …A', 'é¸é …B', 'é¸é …C', 'é¸é …D']]
            if len(set(options)) < len(options):
                result.add_warning(f"ç¬¬{i+1}é¡Œé¸é …å…§å®¹é‡è¤‡")
    
    # ç­”æ¡ˆé©—è­‰
    questions_with_answers = 0
    questions_with_corrected_answers = 0
    
    for i, q in enumerate(questions):
        correct_answer = q.get('æ­£ç¢ºç­”æ¡ˆ', '').strip()
        corrected_answer = q.get('æ›´æ­£ç­”æ¡ˆ', '').strip()
        final_answer = q.get('æœ€çµ‚ç­”æ¡ˆ', '').strip()
        
        if correct_answer:
            questions_with_answers += 1
            if correct_answer not in ['A', 'B', 'C', 'D']:
                result.add_issue(f"ç¬¬{i+1}é¡Œæ­£ç¢ºç­”æ¡ˆæ ¼å¼éŒ¯èª¤: {correct_answer}")
        
        if corrected_answer:
            questions_with_corrected_answers += 1
            if corrected_answer not in ['A', 'B', 'C', 'D']:
                result.add_issue(f"ç¬¬{i+1}é¡Œæ›´æ­£ç­”æ¡ˆæ ¼å¼éŒ¯èª¤: {corrected_answer}")
        
        if final_answer and final_answer not in ['A', 'B', 'C', 'D']:
            result.add_issue(f"ç¬¬{i+1}é¡Œæœ€çµ‚ç­”æ¡ˆæ ¼å¼éŒ¯èª¤: {final_answer}")
    
    result.questions_with_answers = questions_with_answers
    result.questions_with_corrected_answers = questions_with_corrected_answers
    result.summary['æœ‰ç­”æ¡ˆé¡Œæ•¸'] = questions_with_answers
    result.summary['æœ‰æ›´æ­£ç­”æ¡ˆé¡Œæ•¸'] = questions_with_corrected_answers

    return result

def process_pdf_with_answers(pdf_path: str, output_dir: str = "", 
                           answer_pdf_path: str = "", 
                           corrected_answer_pdf_path: str = "") -> Tuple[List[str], ValidationResult]:
    """è™•ç†PDFä¸¦åˆä½µç­”æ¡ˆ"""
    
    print(f"\n{'='*70}")
    print(f"ğŸ“„ {os.path.basename(pdf_path)} (å«ç­”æ¡ˆè¾¨è­˜)")
    print(f"{'='*70}")
    
    # è™•ç†ä¸»PDFæª”æ¡ˆ
    questions, validation_result = process_pdf_to_csv(pdf_path, output_dir)
    
    if not questions:
        return questions, validation_result
    
    # æå–ç­”æ¡ˆ
    answers = {}
    corrected_answers = {}
    
    if answer_pdf_path and os.path.exists(answer_pdf_path):
        print(f"ğŸ” æå–ç­”æ¡ˆ: {os.path.basename(answer_pdf_path)}")
        answers = AnswerProcessor.extract_answers_from_pdf(answer_pdf_path)
        print(f"   âœ… æ‰¾åˆ° {len(answers)} å€‹ç­”æ¡ˆ")
    
    if corrected_answer_pdf_path and os.path.exists(corrected_answer_pdf_path):
        print(f"ğŸ” æå–æ›´æ­£ç­”æ¡ˆ: {os.path.basename(corrected_answer_pdf_path)}")
        corrected_answers = AnswerProcessor.extract_corrected_answers_from_pdf(corrected_answer_pdf_path)
        print(f"   âœ… æ‰¾åˆ° {len(corrected_answers)} å€‹æ›´æ­£ç­”æ¡ˆ")
    
    # æ”¹å–„é¸é …å·®ç•°æ€§
    questions = improve_option_diversity(questions)
    
    # åˆä½µç­”æ¡ˆåˆ°é¡Œç›®
    questions = merge_answers_to_questions(questions, answers, corrected_answers)
    
    # æ›´æ–°é©—è­‰çµæœ
    validation_result.questions_with_answers = sum(1 for q in questions if q.get('æœ€çµ‚ç­”æ¡ˆ'))
    validation_result.questions_with_corrected_answers = sum(1 for q in questions if q.get('æ›´æ­£ç­”æ¡ˆ'))
    
    return questions, validation_result

def process_pdf_to_csv(pdf_path: str, output_dir: str = "") -> Tuple[List[str], ValidationResult]:
    """é›¶èª¤å·®è™•ç†"""
    print(f"\n{'='*70}")
    print(f"ğŸ“„ {os.path.basename(pdf_path)}")
    print(f"{'='*70}")

    # æª¢æŸ¥å¿«å–
    cache_manager = PDFCacheManager()
    pdf_hash = cache_manager.get_pdf_hash(pdf_path)
    cached_result = cache_manager.get_cached_result(pdf_hash)
    
    if cached_result:
        print("âœ“ ä½¿ç”¨å¿«å–çµæœ")
        return cached_result['saved_files'], ValidationResult()

    # åˆ†æPDFç‰¹å¾µ
    pdf_features = PDFFeatureAnalyzer.analyze_pdf(pdf_path)
    print(f"ğŸ“Š PDFç‰¹å¾µ: {pdf_features}")

    # å˜—è©¦å¤šç¨®è§£æç­–ç•¥
    strategies = [
        ("PDFä¸Šå‚³ + Flash", lambda: parse_with_pdf_upload(pdf_path, False)),
        ("PDFä¸Šå‚³ + Pro", lambda: parse_with_pdf_upload(pdf_path, True)),
    ]

    best_q = []
    best_v = ValidationResult()

    for strategy_name, strategy_func in strategies:
        print(f"\nğŸ”„ å˜—è©¦ç­–ç•¥: {strategy_name}")
        try:
            questions = strategy_func()
            if questions:
                print(f"âœ“ è§£æå‡º {len(questions)} é¡Œ")
                
                # é©—è­‰çµæœ
                validation_result = validate_questions(questions, pdf_features)
                
                # é¸æ“‡æœ€ä½³çµæœ
                if len(questions) > len(best_q):
                    best_q = questions
                    best_v = validation_result
                    print(f"âœ“ æ›´æ–°æœ€ä½³çµæœ: {len(questions)} é¡Œ")
                else:
                    print(f"âš ï¸ çµæœä¸å¦‚ä¹‹å‰: {len(questions)} vs {len(best_q)}")
            else:
                print("âš ï¸ è§£æå¤±æ•—")
        except Exception as e:
            print(f"âŒ ç­–ç•¥å¤±æ•—: {e}")

    if not best_q:
        print("âŒ æ‰€æœ‰ç­–ç•¥éƒ½å¤±æ•—")
        return [], ValidationResult()

    os.makedirs(output_dir, exist_ok=True)
    base = os.path.splitext(os.path.basename(pdf_path))[0]
    saved = []

    choice = [q for q in best_q if q['é¡Œå‹'] == 'é¸æ“‡é¡Œ']
    essay = [q for q in best_q if q['é¡Œå‹'] == 'å•ç­”é¡Œ']

    if choice:
        path = os.path.join(output_dir, f"{base}_é¸æ“‡é¡Œ.csv")
        pd.DataFrame(choice).to_csv(path, index=False, encoding='utf-8-sig')
        print(f"\nâœ… {path} ({len(choice)}é¡Œ)")
        saved.append(path)

    if essay:
        path = os.path.join(output_dir, f"{base}_å•ç­”é¡Œ.csv")
        pd.DataFrame(essay).to_csv(path, index=False, encoding='utf-8-sig')
        print(f"âœ… {path} ({len(essay)}é¡Œ)")
        saved.append(path)

    # å¿«å–çµæœ
    cache_manager.cache_result(pdf_hash, {'saved_files': saved})

    return saved, best_v

def process_directory(input_dir: str, output_dir: str = "") -> Dict[str, Any]:
    """è™•ç†ç›®éŒ„ä¸­çš„æ‰€æœ‰PDF"""
    pdf_files = glob.glob(os.path.join(input_dir, "**", "*.pdf"), recursive=True)

    if not pdf_files:
        print("æœªæ‰¾åˆ°PDF")
        return {}

    # é å…ˆéæ¿¾ç­”æ¡ˆæª”æ¡ˆ
    print(f"\næ‰¾åˆ° {len(pdf_files)} å€‹PDF")

    filtered_files = []
    skipped_files = []

    for pdf_file in pdf_files:
        filename = os.path.basename(pdf_file)
        if should_skip_file(filename):
            skipped_files.append(filename)
        else:
            filtered_files.append(pdf_file)

    print(f"â­ï¸  éæ¿¾æ‰ {len(skipped_files)} å€‹ç­”æ¡ˆæª”æ¡ˆ")
    print(f"ğŸ“„ å°‡è™•ç† {len(filtered_files)} å€‹è©¦é¡Œæª”æ¡ˆ\n")

    cache_manager = PDFCacheManager()
    cache_manager.cleanup_expired_cache()

    results = []
    success = warning = error = 0

    for i, pdf in enumerate(filtered_files, 1):
        try:
            print(f"\n[{i}/{len(filtered_files)}]")

            rel = os.path.relpath(pdf, input_dir)
            out = os.path.join(output_dir, os.path.dirname(rel)) if output_dir else os.path.dirname(pdf)

            # å°‹æ‰¾å°æ‡‰çš„ç­”æ¡ˆæª”æ¡ˆ
            answer_pdf_path = ""
            corrected_answer_pdf_path = ""
            
            # å°‹æ‰¾ç­”æ¡ˆæª”æ¡ˆ
            base_name = os.path.splitext(os.path.basename(pdf))[0]
            answer_files = glob.glob(os.path.join(os.path.dirname(pdf), f"*ç­”æ¡ˆ*.pdf"))
            corrected_answer_files = glob.glob(os.path.join(os.path.dirname(pdf), f"*æ›´æ­£*.pdf"))
            
            if answer_files:
                answer_pdf_path = answer_files[0]
            if corrected_answer_files:
                corrected_answer_pdf_path = corrected_answer_files[0]
            
            _, v = process_pdf_with_answers(pdf, out, answer_pdf_path, corrected_answer_pdf_path)

            results.append({
                'file': os.path.basename(pdf),
                'status': v.status,
                'summary': v.summary,
                'issues': v.issues
            })

            if v.status == 'success':
                success += 1
            elif v.status == 'warning':
                warning += 1
            else:
                error += 1
        except Exception as e:
            print(f"âŒ éŒ¯èª¤: {e}")
            error += 1

    print(f"\n{'='*70}")
    print("çµ±è¨ˆ")
    print(f"{'='*70}")
    print(f"ç¸½è©¦é¡ŒPDF: {len(filtered_files)}")
    print(f"âœ… æˆåŠŸ: {success} ({success/max(len(filtered_files),1)*100:.1f}%)")
    print(f"âš ï¸ è­¦å‘Š: {warning} ({warning/max(len(filtered_files),1)*100:.1f}%)")
    print(f"âŒ éŒ¯èª¤: {error} ({error/max(len(filtered_files),1)*100:.1f}%)")
    print(f"\nâ­ï¸  å·²è·³é {len(skipped_files)} å€‹ç­”æ¡ˆæª”æ¡ˆ")

    if error > 0:
        print(f"\néœ€æª¢æŸ¥:")
        for r in results:
            if r['status'] == 'error':
                print(f"  - {r['file']}")

    report = os.path.join(output_dir if output_dir else input_dir, "validation_report.json")
    with open(report, 'w', encoding='utf-8') as f:
        json.dump({
            'summary': {
                'total_files': len(pdf_files),
                'processed': len(filtered_files),
                'skipped': len(skipped_files),
                'success': success,
                'warning': warning,
                'error': error
            },
            'results': results
        }, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“Š è©³ç´°å ±å‘Š: {report}")

    return {
        'total_files': len(pdf_files),
        'processed': len(filtered_files),
        'skipped': len(skipped_files),
        'success': success,
        'warning': warning,
        'error': error,
        'results': results
    }

def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ”¹é€²ç‰ˆPDFè½‰CSVå·¥å…·')
    parser.add_argument('input', help='è¼¸å…¥PDFæª”æ¡ˆæˆ–ç›®éŒ„')
    parser.add_argument('-o', '--output', default='', help='è¼¸å‡ºç›®éŒ„')
    parser.add_argument('--answer', default='', help='ç­”æ¡ˆPDFæª”æ¡ˆè·¯å¾‘')
    parser.add_argument('--corrected', default='', help='æ›´æ­£ç­”æ¡ˆPDFæª”æ¡ˆè·¯å¾‘')
    
    args = parser.parse_args()
    
    if os.path.isfile(args.input):
        # å–®ä¸€æª”æ¡ˆè™•ç†
        if args.answer or args.corrected:
            saved_files, validation_result = process_pdf_with_answers(
                args.input, args.output, args.answer, args.corrected
            )
        else:
            saved_files, validation_result = process_pdf_to_csv(args.input, args.output)
        
        validation_result.print_result()
        
        if saved_files:
            print(f"\nâœ… å·²å„²å­˜: {saved_files}")
        else:
            print("\nâŒ è™•ç†å¤±æ•—")
    else:
        # ç›®éŒ„è™•ç†
        result = process_directory(args.input, args.output)
        if result:
            print(f"\nâœ… è™•ç†å®Œæˆ: {result['success']} æˆåŠŸ, {result['warning']} è­¦å‘Š, {result['error']} éŒ¯èª¤")

if __name__ == "__main__":
    main()