#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ”¹é€²ç‰ˆPDFè½‰CSVåŠŸèƒ½ - å°ˆé–€è™•ç†é¡Œçµ„å•é¡Œ
è§£æ±ºè‹±æ–‡ç­‰ç§‘ç›®ä¸­5-6å€‹é¸æ“‡é¡Œç‚ºä¸€çµ„çš„æƒ…æ³
"""

import os
import pdfplumber
import pandas as pd
import re
import json
import hashlib
from typing import List, Dict, Any, Optional, Tuple
import glob
from datetime import datetime, timedelta

class QuestionGroupProcessor:
    """é¡Œçµ„è™•ç†å™¨ - å°ˆé–€è™•ç†é¡Œçµ„å•é¡Œ"""
    
    @staticmethod
    def detect_question_groups(text: str) -> List[Dict[str, Any]]:
        """æª¢æ¸¬é¡Œçµ„"""
        groups = []
        
        # æª¢æ¸¬é¡Œçµ„æ¨¡å¼ï¼šè«‹ä¾ä¸‹æ–‡å›ç­”ç¬¬Xé¡Œè‡³ç¬¬Yé¡Œ
        group_patterns = [
            r'è«‹ä¾ä¸‹æ–‡å›ç­”ç¬¬(\d+)é¡Œè‡³ç¬¬(\d+)é¡Œï¼š',
            r'è«‹ä¾ä¸Šæ–‡å›ç­”ç¬¬(\d+)é¡Œè‡³ç¬¬(\d+)é¡Œï¼š',
            r'è«‹ä¾ä¸‹åˆ—æ–‡ç« å›ç­”ç¬¬(\d+)é¡Œè‡³ç¬¬(\d+)é¡Œï¼š',
            r'è«‹ä¾ä¸‹åˆ—çŸ­æ–‡å›ç­”ç¬¬(\d+)é¡Œè‡³ç¬¬(\d+)é¡Œï¼š',
            r'è«‹ä¾ä¸‹åˆ—å…§å®¹å›ç­”ç¬¬(\d+)é¡Œè‡³ç¬¬(\d+)é¡Œï¼š',
        ]
        
        for pattern in group_patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                start_q = int(match.group(1))
                end_q = int(match.group(2))
                
                # æ‰¾åˆ°é¡Œçµ„é–‹å§‹ä½ç½®
                start_pos = match.end()
                
                # å°‹æ‰¾ä¸‹ä¸€å€‹é¡Œçµ„æˆ–æ–‡ç« çµæŸä½ç½®
                next_group_match = re.search(r'è«‹ä¾.*?å›ç­”ç¬¬\d+é¡Œè‡³ç¬¬\d+é¡Œï¼š', text[start_pos:])
                if next_group_match:
                    end_pos = start_pos + next_group_match.start()
                else:
                    # å¦‚æœæ²’æœ‰ä¸‹ä¸€å€‹é¡Œçµ„ï¼Œæ‰¾åˆ°æ–‡ç« çµæŸä½ç½®
                    end_pos = len(text)
                
                # æå–é¡Œçµ„å…§å®¹
                group_content = text[start_pos:end_pos].strip()
                
                groups.append({
                    'start_question': start_q,
                    'end_question': end_q,
                    'content': group_content,
                    'question_count': end_q - start_q + 1
                })
        
        return groups
    
    @staticmethod
    def extract_questions_from_group(group: Dict[str, Any], text: str) -> List[Dict[str, Any]]:
        """å¾é¡Œçµ„ä¸­æå–å€‹åˆ¥é¡Œç›®"""
        questions = []
        start_q = group['start_question']
        end_q = group['end_question']
        group_content = group['content']
        
        # åœ¨é¡Œçµ„å…§å®¹ä¸­å°‹æ‰¾é¡Œç›®
        for q_num in range(start_q, end_q + 1):
            # å°‹æ‰¾é¡Œç›®æ¨¡å¼
            question_patterns = [
                rf'{q_num}\s*[ï¼¡ï¼¢ï¼£ï¼¤]',  # é¡Œè™Ÿ + é¸é …
                rf'{q_num}\s*[ABCD]',      # é¡Œè™Ÿ + é¸é …
                rf'ç¬¬{q_num}é¡Œ',           # ç¬¬Xé¡Œ
            ]
            
            question_found = False
            for pattern in question_patterns:
                match = re.search(pattern, group_content)
                if match:
                    # æå–é¡Œç›®å…§å®¹
                    question_start = match.start()
                    
                    # å°‹æ‰¾é¸é …
                    options = []
                    option_pattern = r'[ï¼¡ï¼¢ï¼£ï¼¤][ï¼¡ï¼¢ï¼£ï¼¤][ï¼¡ï¼¢ï¼£ï¼¤][ï¼¡ï¼¢ï¼£ï¼¤]'
                    option_match = re.search(option_pattern, group_content[question_start:])
                    
                    if option_match:
                        option_text = option_match.group()
                        # åˆ†å‰²é¸é …
                        for i in range(0, len(option_text), 1):
                            if i + 1 < len(option_text):
                                option_letter = option_text[i]
                                option_content = option_text[i+1:i+2] if i+1 < len(option_text) else ""
                                options.append({
                                    'letter': option_letter,
                                    'content': option_content
                                })
                    
                    # å¦‚æœæ²’æœ‰æ‰¾åˆ°é¸é …ï¼Œå˜—è©¦å…¶ä»–æ¨¡å¼
                    if not options:
                        # å°‹æ‰¾å–®å€‹é¸é …æ¨¡å¼
                        single_option_pattern = r'[ï¼¡ï¼¢ï¼£ï¼¤][^ï¼¡ï¼¢ï¼£ï¼¤]*'
                        single_matches = re.findall(single_option_pattern, group_content[question_start:question_start+200])
                        for i, match in enumerate(single_matches[:4]):  # æœ€å¤š4å€‹é¸é …
                            if len(match) > 1:
                                options.append({
                                    'letter': match[0],
                                    'content': match[1:].strip()
                                })
                    
                    # å»ºç«‹é¡Œç›®
                    question = {
                        'é¡Œè™Ÿ': str(q_num),
                        'é¡Œç›®': f"é¡Œçµ„é¡Œç›®ï¼ˆç¬¬{q_num}é¡Œï¼‰",
                        'é¸é …A': options[0]['content'] if len(options) > 0 else '',
                        'é¸é …B': options[1]['content'] if len(options) > 1 else '',
                        'é¸é …C': options[2]['content'] if len(options) > 2 else '',
                        'é¸é …D': options[3]['content'] if len(options) > 3 else '',
                        'é¡Œå‹': 'é¸æ“‡é¡Œ',
                        'æ­£ç¢ºç­”æ¡ˆ': '',
                        'æ›´æ­£ç­”æ¡ˆ': '',
                        'é¡Œçµ„': True,
                        'é¡Œçµ„å…§å®¹': group_content[:200] + '...' if len(group_content) > 200 else group_content
                    }
                    
                    questions.append(question)
                    question_found = True
                    break
            
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°å…·é«”é¡Œç›®ï¼Œå‰µå»ºä¸€å€‹åŸºæœ¬é¡Œç›®
            if not question_found:
                question = {
                    'é¡Œè™Ÿ': str(q_num),
                    'é¡Œç›®': f"é¡Œçµ„é¡Œç›®ï¼ˆç¬¬{q_num}é¡Œï¼‰",
                    'é¸é …A': '',
                    'é¸é …B': '',
                    'é¸é …C': '',
                    'é¸é …D': '',
                    'é¡Œå‹': 'é¸æ“‡é¡Œ',
                    'æ­£ç¢ºç­”æ¡ˆ': '',
                    'æ›´æ­£ç­”æ¡ˆ': '',
                    'é¡Œçµ„': True,
                    'é¡Œçµ„å…§å®¹': group_content[:200] + '...' if len(group_content) > 200 else group_content
                }
                questions.append(question)
        
        return questions

class AnswerProcessor:
    """ç­”æ¡ˆè™•ç†å™¨ - å¾PDFæ–‡å­—ä¸­æå–ç­”æ¡ˆå’Œæ›´æ­£ç­”æ¡ˆ"""
    
    @staticmethod
    def extract_answers_from_pdf(pdf_path: str) -> Dict[str, str]:
        """å¾PDFæª”æ¡ˆä¸­æå–ç­”æ¡ˆ"""
        try:
            with pdfplumber.open(pdf_path) as pdf:
                text = ""
                for page in pdf.pages:
                    text += page.extract_text() or ""
            
            return AnswerProcessor.extract_answers_from_text(text)
        except Exception as e:
            print(f"âŒ æå–ç­”æ¡ˆå¤±æ•—: {e}")
            return {}
    
    @staticmethod
    def extract_answers_from_text(text: str) -> Dict[str, str]:
        """å¾æ–‡å­—ä¸­æå–ç­”æ¡ˆ"""
        answers = {}
        
        # åŒ¹é…ç­”æ¡ˆæ¨¡å¼ï¼š1. A, 2. B, 3. C ç­‰
        answer_patterns = [
            r'(\d+)\.\s*([ABCD])',  # 1. A
            r'(\d+)\s*([ABCD])',    # 1 A
            r'ç¬¬(\d+)é¡Œ\s*([ABCD])', # ç¬¬1é¡Œ A
            r'(\d+)\s*ï¼š\s*([ABCD])', # 1ï¼šA
        ]
        
        for pattern in answer_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                question_num = match[0]
                answer = match[1]
                answers[question_num] = answer
        
        return answers

def parse_questions_with_groups(text: str, expected_count: int = 0) -> List[Dict[str, Any]]:
    """è§£æåŒ…å«é¡Œçµ„çš„é¡Œç›®"""
    questions = []
    
    # æª¢æ¸¬é¡Œçµ„
    groups = QuestionGroupProcessor.detect_question_groups(text)
    print(f"ğŸ” æª¢æ¸¬åˆ° {len(groups)} å€‹é¡Œçµ„")
    
    if groups:
        # è™•ç†é¡Œçµ„
        for group in groups:
            print(f"   ğŸ“š é¡Œçµ„ {group['start_question']}-{group['end_question']}: {group['question_count']} é¡Œ")
            group_questions = QuestionGroupProcessor.extract_questions_from_group(group, text)
            questions.extend(group_questions)
    
    # è™•ç†éé¡Œçµ„çš„å–®ç¨é¡Œç›®
    # é€™è£¡å¯ä»¥æ·»åŠ è™•ç†å–®ç¨é¡Œç›®çš„é‚è¼¯
    
    return questions

def process_pdf_with_groups(pdf_path: str, output_dir: str = "", 
                           answer_pdf_path: str = "") -> Tuple[List[str], Dict[str, Any]]:
    """è™•ç†åŒ…å«é¡Œçµ„çš„PDF"""
    
    print(f"\n{'='*70}")
    print(f"ğŸ“„ {os.path.basename(pdf_path)} (å«é¡Œçµ„è™•ç†)")
    print(f"{'='*70}")
    
    try:
        # æå–PDFæ–‡å­—
        with pdfplumber.open(pdf_path) as pdf:
            text = ""
            for page in pdf.pages:
                text += page.extract_text() or ""
        
        print(f"ğŸ“Š æå–æ–‡å­—é•·åº¦: {len(text)} å­—å…ƒ")
        
        # è§£æé¡Œç›®ï¼ˆåŒ…å«é¡Œçµ„ï¼‰
        questions = parse_questions_with_groups(text)
        
        if not questions:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•é¡Œç›®")
            return [], {}
        
        print(f"âœ… è§£æå‡º {len(questions)} é¡Œ")
        
        # æå–ç­”æ¡ˆ
        answers = {}
        if answer_pdf_path and os.path.exists(answer_pdf_path):
            print(f"ğŸ” æå–ç­”æ¡ˆ: {os.path.basename(answer_pdf_path)}")
            answers = AnswerProcessor.extract_answers_from_pdf(answer_pdf_path)
            print(f"   âœ… æ‰¾åˆ° {len(answers)} å€‹ç­”æ¡ˆ")
        
        # åˆä½µç­”æ¡ˆåˆ°é¡Œç›®
        for question in questions:
            question_num = question.get('é¡Œè™Ÿ', '')
            correct_answer = answers.get(question_num, '')
            question['æ­£ç¢ºç­”æ¡ˆ'] = correct_answer
            question['æœ€çµ‚ç­”æ¡ˆ'] = correct_answer
        
        # å„²å­˜CSV
        os.makedirs(output_dir, exist_ok=True)
        base = os.path.splitext(os.path.basename(pdf_path))[0]
        
        # åˆ†é¡é¡Œç›®
        regular_questions = [q for q in questions if not q.get('é¡Œçµ„', False)]
        group_questions = [q for q in questions if q.get('é¡Œçµ„', False)]
        
        saved_files = []
        
        if regular_questions:
            path = os.path.join(output_dir, f"{base}_ä¸€èˆ¬é¡Œç›®.csv")
            pd.DataFrame(regular_questions).to_csv(path, index=False, encoding='utf-8-sig')
            print(f"âœ… {path} ({len(regular_questions)}é¡Œ)")
            saved_files.append(path)
        
        if group_questions:
            path = os.path.join(output_dir, f"{base}_é¡Œçµ„é¡Œç›®.csv")
            pd.DataFrame(group_questions).to_csv(path, index=False, encoding='utf-8-sig')
            print(f"âœ… {path} ({len(group_questions)}é¡Œ)")
            saved_files.append(path)
        
        # åˆä½µæ‰€æœ‰é¡Œç›®
        if questions:
            path = os.path.join(output_dir, f"{base}_å®Œæ•´é¡Œç›®.csv")
            pd.DataFrame(questions).to_csv(path, index=False, encoding='utf-8-sig')
            print(f"âœ… {path} ({len(questions)}é¡Œ)")
            saved_files.append(path)
        
        return saved_files, {'total_questions': len(questions), 'group_questions': len(group_questions)}
        
    except Exception as e:
        print(f"âŒ è™•ç†å¤±æ•—: {e}")
        return [], {}

def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description='PDFè½‰CSVå·¥å…· - æ”¯æ´é¡Œçµ„è™•ç†')
    parser.add_argument('input', help='è¼¸å…¥PDFæª”æ¡ˆ')
    parser.add_argument('-o', '--output', default='', help='è¼¸å‡ºç›®éŒ„')
    parser.add_argument('--answer', default='', help='ç­”æ¡ˆPDFæª”æ¡ˆè·¯å¾‘')
    
    args = parser.parse_args()
    
    if os.path.isfile(args.input):
        saved_files, stats = process_pdf_with_groups(args.input, args.output, args.answer)
        
        if saved_files:
            print(f"\nâœ… å·²å„²å­˜: {saved_files}")
            print(f"ğŸ“Š çµ±è¨ˆ: {stats}")
        else:
            print("\nâŒ è™•ç†å¤±æ•—")
    else:
        print("âŒ è¼¸å…¥æª”æ¡ˆä¸å­˜åœ¨")

if __name__ == "__main__":
    main()