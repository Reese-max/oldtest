#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è™•ç†æ‰€æœ‰ç§‘ç›® - å°‡ç¬¬114å¹´å¸æ³•ä¸‰ç­‰è€ƒè©¦ç›£ç„å®˜çš„æ‰€æœ‰ç§‘ç›®è½‰æ›ç‚ºCSV
"""

import os
import pdfplumber
import pandas as pd
import re
import json
from typing import List, Dict, Any, Optional, Tuple
import glob

class AllSubjectsProcessor:
    """æ‰€æœ‰ç§‘ç›®è™•ç†å™¨"""
    
    @staticmethod
    def process_all_subjects(base_dir: str, output_dir: str = "") -> Dict[str, Any]:
        """è™•ç†æ‰€æœ‰ç§‘ç›®"""
        
        print(f"\n{'='*70}")
        print(f"ğŸ“š è™•ç†ç¬¬114å¹´å¸æ³•ä¸‰ç­‰è€ƒè©¦ç›£ç„å®˜æ‰€æœ‰ç§‘ç›®")
        print(f"{'='*70}")
        
        # ç›£ç„å®˜ç§‘ç›®ç›®éŒ„
        subjects_dir = os.path.join(base_dir, "æ°‘åœ‹114å¹´", "æ°‘åœ‹114å¹´_å¸æ³•ç‰¹è€ƒ", "ç›£ç„å®˜")
        
        if not os.path.exists(subjects_dir):
            print(f"âŒ ç§‘ç›®ç›®éŒ„ä¸å­˜åœ¨: {subjects_dir}")
            return {}
        
        # ç²å–æ‰€æœ‰ç§‘ç›®
        subjects = os.listdir(subjects_dir)
        print(f"ğŸ“‹ æ‰¾åˆ° {len(subjects)} å€‹ç§‘ç›®")
        
        results = {}
        total_questions = 0
        
        for subject in subjects:
            subject_path = os.path.join(subjects_dir, subject)
            if os.path.isdir(subject_path):
                print(f"\nğŸ“– è™•ç†ç§‘ç›®: {subject}")
                
                # è™•ç†ç§‘ç›®
                subject_result = AllSubjectsProcessor.process_subject(subject_path, subject, output_dir)
                if subject_result:
                    results[subject] = subject_result
                    total_questions += subject_result.get('total_questions', 0)
        
        print(f"\n{'='*70}")
        print(f"ğŸ“Š è™•ç†å®Œæˆçµ±è¨ˆ")
        print(f"{'='*70}")
        print(f"âœ… è™•ç†ç§‘ç›®: {len(results)} å€‹")
        print(f"ğŸ“ ç¸½é¡Œæ•¸: {total_questions} é¡Œ")
        
        return results
    
    @staticmethod
    def process_subject(subject_path: str, subject_name: str, output_dir: str) -> Dict[str, Any]:
        """è™•ç†å–®ä¸€ç§‘ç›®"""
        
        # å°‹æ‰¾è©¦é¡Œå’Œç­”æ¡ˆæª”æ¡ˆ
        question_files = glob.glob(os.path.join(subject_path, "*è©¦é¡Œ*.pdf"))
        answer_files = glob.glob(os.path.join(subject_path, "*ç­”æ¡ˆ*.pdf"))
        
        if not question_files:
            print(f"   âš ï¸ æœªæ‰¾åˆ°è©¦é¡Œæª”æ¡ˆ")
            return {}
        
        question_file = question_files[0]
        answer_file = answer_files[0] if answer_files else None
        
        print(f"   ğŸ“„ è©¦é¡Œæª”æ¡ˆ: {os.path.basename(question_file)}")
        if answer_file:
            print(f"   ğŸ“„ ç­”æ¡ˆæª”æ¡ˆ: {os.path.basename(answer_file)}")
        
        # è™•ç†PDF
        questions = AllSubjectsProcessor.extract_questions_from_pdf(question_file, answer_file)
        
        if not questions:
            print(f"   âŒ æœªæå–åˆ°é¡Œç›®")
            return {}
        
        print(f"   âœ… æå–åˆ° {len(questions)} é¡Œ")
        
        # å„²å­˜CSV
        os.makedirs(output_dir, exist_ok=True)
        
        # æ¸…ç†ç§‘ç›®åç¨±
        clean_subject_name = re.sub(r'[\\/*?:"<>|]', "_", subject_name)
        
        # åˆ†é¡é¡Œç›®
        regular_questions = [q for q in questions if not q.get('é¡Œçµ„', False)]
        group_questions = [q for q in questions if q.get('é¡Œçµ„', False)]
        
        saved_files = []
        
        if regular_questions:
            path = os.path.join(output_dir, f"{clean_subject_name}_ä¸€èˆ¬é¡Œç›®.csv")
            pd.DataFrame(regular_questions).to_csv(path, index=False, encoding='utf-8-sig')
            print(f"   âœ… {path} ({len(regular_questions)}é¡Œ)")
            saved_files.append(path)
        
        if group_questions:
            path = os.path.join(output_dir, f"{clean_subject_name}_é¡Œçµ„é¡Œç›®.csv")
            pd.DataFrame(group_questions).to_csv(path, index=False, encoding='utf-8-sig')
            print(f"   âœ… {path} ({len(group_questions)}é¡Œ)")
            saved_files.append(path)
        
        # åˆä½µæ‰€æœ‰é¡Œç›®
        if questions:
            path = os.path.join(output_dir, f"{clean_subject_name}_å®Œæ•´é¡Œç›®.csv")
            pd.DataFrame(questions).to_csv(path, index=False, encoding='utf-8-sig')
            print(f"   âœ… {path} ({len(questions)}é¡Œ)")
            saved_files.append(path)
        
        return {
            'total_questions': len(questions),
            'regular_questions': len(regular_questions),
            'group_questions': len(group_questions),
            'saved_files': saved_files
        }
    
    @staticmethod
    def extract_questions_from_pdf(pdf_path: str, answer_pdf_path: str = None) -> List[Dict[str, Any]]:
        """å¾PDFä¸­æå–é¡Œç›®"""
        
        try:
            # æå–PDFæ–‡å­—
            with pdfplumber.open(pdf_path) as pdf:
                text = ""
                for page in pdf.pages:
                    text += page.extract_text() or ""
            
            # æª¢æ¸¬é¡Œçµ„
            groups = AllSubjectsProcessor.detect_question_groups(text)
            
            questions = []
            
            if groups:
                # è™•ç†é¡Œçµ„
                for group in groups:
                    group_questions = AllSubjectsProcessor.extract_questions_from_group(group)
                    questions.extend(group_questions)
            
            # è™•ç†éé¡Œçµ„çš„å–®ç¨é¡Œç›®
            # é€™è£¡å¯ä»¥æ·»åŠ è™•ç†å–®ç¨é¡Œç›®çš„é‚è¼¯
            
            return questions
            
        except Exception as e:
            print(f"   âŒ æå–å¤±æ•—: {e}")
            return []
    
    @staticmethod
    def detect_question_groups(text: str) -> List[Dict[str, Any]]:
        """æª¢æ¸¬é¡Œçµ„"""
        groups = []
        
        # æª¢æ¸¬é¡Œçµ„æ¨¡å¼ï¼šè«‹ä¾ä¸‹æ–‡å›ç­”ç¬¬Xé¡Œè‡³ç¬¬Yé¡Œ
        group_patterns = [
            r'è«‹ä¾ä¸‹æ–‡å›ç­”ç¬¬(\d+)é¡Œè‡³ç¬¬(\d+)é¡Œï¼š',
            r'è«‹ä¾ä¸Šæ–‡å›ç­”ç¬¬(\d+)é¡Œè‡³ç¬¬(\d+)é¡Œï¼š',
            r'è«‹ä¾ä¸‹åˆ—æ–‡ç« å›ç­”ç¬¬(\d+)é¡Œè‡³ç¬¬(\d+)é¡Œï¼š',
            r'è«‹ä¾ä¸‹åˆ—çŸ­æ–‡å›ç­”ç¬¬(\d+)é¡Œè‡³ç¬¬(\d+)é¡Œï¼š',
            r'è«‹ä¾ä¸‹åˆ—å…§å®¹å›ç­”ç¬¬(\d+)é¡Œè‡³ç¬¬(\d+)é¡Œï¼š',
        ]
        
        for pattern in group_patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                start_q = int(match.group(1))
                end_q = int(match.group(2))
                
                # æ‰¾åˆ°é¡Œçµ„é–‹å§‹ä½ç½®
                start_pos = match.end()
                
                # å°‹æ‰¾ä¸‹ä¸€å€‹é¡Œçµ„æˆ–æ–‡ç« çµæŸä½ç½®
                next_group_match = re.search(r'è«‹ä¾.*?å›ç­”ç¬¬\d+é¡Œè‡³ç¬¬\d+é¡Œï¼š', text[start_pos:])
                if next_group_match:
                    end_pos = start_pos + next_group_match.start()
                else:
                    # å¦‚æœæ²’æœ‰ä¸‹ä¸€å€‹é¡Œçµ„ï¼Œæ‰¾åˆ°æ–‡ç« çµæŸä½ç½®
                    end_pos = len(text)
                
                # æå–é¡Œçµ„å…§å®¹
                group_content = text[start_pos:end_pos].strip()
                
                groups.append({
                    'start_question': start_q,
                    'end_question': end_q,
                    'content': group_content,
                    'question_count': end_q - start_q + 1
                })
        
        return groups
    
    @staticmethod
    def extract_questions_from_group(group: Dict[str, Any]) -> List[Dict[str, Any]]:
        """å¾é¡Œçµ„ä¸­æå–é¡Œç›®"""
        questions = []
        start_q = group['start_question']
        end_q = group['end_question']
        group_content = group['content']
        
        # åœ¨é¡Œçµ„å…§å®¹ä¸­å°‹æ‰¾é¡Œç›®
        for q_num in range(start_q, end_q + 1):
            # å°‹æ‰¾é¡Œç›®æ¨¡å¼
            question_patterns = [
                rf'{q_num}\s*[ï¼¡ï¼¢ï¼£ï¼¤][^ï¼¡ï¼¢ï¼£ï¼¤]*[ï¼¡ï¼¢ï¼£ï¼¤][^ï¼¡ï¼¢ï¼£ï¼¤]*[ï¼¡ï¼¢ï¼£ï¼¤][^ï¼¡ï¼¢ï¼£ï¼¤]*[ï¼¡ï¼¢ï¼£ï¼¤]',  # å®Œæ•´é¸é …æ¨¡å¼
                rf'{q_num}\s*[ABCD][^ABCD]*[ABCD][^ABCD]*[ABCD][^ABCD]*[ABCD]',  # è‹±æ–‡é¸é …æ¨¡å¼
            ]
            
            question_found = False
            for pattern in question_patterns:
                match = re.search(pattern, group_content)
                if match:
                    question_text = match.group()
                    
                    # æå–é¸é …
                    options = AllSubjectsProcessor.extract_options_from_question(question_text)
                    
                    # å»ºç«‹é¡Œç›®
                    question = {
                        'é¡Œè™Ÿ': str(q_num),
                        'é¡Œç›®': f"é¡Œçµ„é¡Œç›®ï¼ˆç¬¬{q_num}é¡Œï¼‰",
                        'é¸é …A': options.get('A', ''),
                        'é¸é …B': options.get('B', ''),
                        'é¸é …C': options.get('C', ''),
                        'é¸é …D': options.get('D', ''),
                        'é¡Œå‹': 'é¸æ“‡é¡Œ',
                        'æ­£ç¢ºç­”æ¡ˆ': '',
                        'æ›´æ­£ç­”æ¡ˆ': '',
                        'é¡Œçµ„': True,
                        'é¡Œçµ„å…§å®¹': group_content[:200] + '...' if len(group_content) > 200 else group_content,
                        'åŸå§‹é¡Œç›®': question_text
                    }
                    
                    questions.append(question)
                    question_found = True
                    break
            
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°å…·é«”é¡Œç›®ï¼Œå‰µå»ºä¸€å€‹åŸºæœ¬é¡Œç›®
            if not question_found:
                question = {
                    'é¡Œè™Ÿ': str(q_num),
                    'é¡Œç›®': f"é¡Œçµ„é¡Œç›®ï¼ˆç¬¬{q_num}é¡Œï¼‰",
                    'é¸é …A': '',
                    'é¸é …B': '',
                    'é¸é …C': '',
                    'é¸é …D': '',
                    'é¡Œå‹': 'é¸æ“‡é¡Œ',
                    'æ­£ç¢ºç­”æ¡ˆ': '',
                    'æ›´æ­£ç­”æ¡ˆ': '',
                    'é¡Œçµ„': True,
                    'é¡Œçµ„å…§å®¹': group_content[:200] + '...' if len(group_content) > 200 else group_content,
                    'åŸå§‹é¡Œç›®': ''
                }
                questions.append(question)
        
        return questions
    
    @staticmethod
    def extract_options_from_question(question_text: str) -> Dict[str, str]:
        """å¾é¡Œç›®æ–‡å­—ä¸­æå–é¸é …"""
        options = {}
        
        # å˜—è©¦ä¸åŒçš„é¸é …æ¨¡å¼
        option_patterns = [
            # ä¸­æ–‡é¸é …æ¨¡å¼
            r'[ï¼¡ï¼¢ï¼£ï¼¤][^ï¼¡ï¼¢ï¼£ï¼¤]*',
            # è‹±æ–‡é¸é …æ¨¡å¼
            r'[ABCD][^ABCD]*',
        ]
        
        for pattern in option_patterns:
            matches = re.findall(pattern, question_text)
            if len(matches) >= 4:  # è‡³å°‘è¦æœ‰4å€‹é¸é …
                for i, match in enumerate(matches[:4]):
                    if len(match) > 1:
                        option_letter = match[0]
                        option_content = match[1:].strip()
                        options[option_letter] = option_content
                break
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°é¸é …ï¼Œå˜—è©¦æ›´ç°¡å–®çš„æ¨¡å¼
        if not options:
            # å°‹æ‰¾æ•¸å­—å¾Œé¢çš„é¸é …
            simple_pattern = r'(\d+)\s*([ï¼¡ï¼¢ï¼£ï¼¤])\s*([^ï¼¡ï¼¢ï¼£ï¼¤]*)'
            matches = re.findall(simple_pattern, question_text)
            for match in matches:
                option_letter = match[1]
                option_content = match[2].strip()
                if option_content:
                    options[option_letter] = option_content
        
        return options

def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description='è™•ç†æ‰€æœ‰ç§‘ç›® - æ”¯æ´é¡Œçµ„è™•ç†')
    parser.add_argument('input', help='è¼¸å…¥ç›®éŒ„')
    parser.add_argument('-o', '--output', default='', help='è¼¸å‡ºç›®éŒ„')
    
    args = parser.parse_args()
    
    if os.path.isdir(args.input):
        results = AllSubjectsProcessor.process_all_subjects(args.input, args.output)
        
        if results:
            print(f"\nâœ… è™•ç†å®Œæˆ: {len(results)} å€‹ç§‘ç›®")
        else:
            print("\nâŒ è™•ç†å¤±æ•—")
    else:
        print("âŒ è¼¸å…¥ç›®éŒ„ä¸å­˜åœ¨")

if __name__ == "__main__":
    main()