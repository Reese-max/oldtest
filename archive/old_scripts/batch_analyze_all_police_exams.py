#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
import sys
sys.path.append('src')

import pdfplumber
from src.processors.archaeology_processor import ArchaeologyProcessor

def analyze_pdf_structure(pdf_path):
    """åˆ†æå–®å€‹PDFçš„çµæ§‹"""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            text = ''.join([page.extract_text() or '' for page in pdf.pages])
        
        # åŸºæœ¬çµ±è¨ˆ
        total_chars = len(text)
        total_lines = len(text.split('\n'))
        
        # æª¢æ¸¬é¡Œå‹ç‰¹å¾µ
        features = {
            'has_essay_section': 'ç”²ã€ç”³è«–é¡Œéƒ¨åˆ†' in text or 'ç”³è«–é¡Œ' in text,
            'has_test_section': 'ä¹™ã€æ¸¬é©—é¡Œéƒ¨åˆ†' in text or 'æ¸¬é©—é¡Œ' in text,
            'has_essay_questions': any(f'ç¬¬{i}é¡Œ' in text for i in range(1, 11)),
            'has_choice_questions': any(f'{i}.' in text for i in range(1, 51)),
            'has_question_groups': 'è«‹ä¾ä¸‹æ–‡å›ç­”ç¬¬' in text and 'é¡Œè‡³ç¬¬' in text,
            'has_composition': 'ä½œæ–‡' in text,
            'has_english': 'English' in text or 'è‹±æ–‡' in text,
            'has_choice_symbols': any(symbol in text for symbol in ['', '', '', '']),
            'total_questions_mentioned': len([m for m in text.split() if m.isdigit() and 1 <= int(m) <= 100]),
        }
        
        # ä¼°ç®—é¡Œæ•¸
        estimated_questions = 0
        if features['has_essay_questions']:
            estimated_questions += 4  # é€šå¸¸ç”³è«–é¡Œ4é¡Œ
        if features['has_choice_questions']:
            estimated_questions += 20  # é€šå¸¸é¸æ“‡é¡Œ20é¡Œ
        if features['has_question_groups']:
            estimated_questions += 10  # é¡Œçµ„é€šå¸¸10é¡Œ
        
        return {
            'total_chars': total_chars,
            'total_lines': total_lines,
            'features': features,
            'estimated_questions': estimated_questions,
            'text_preview': text[:500] if text else ''
        }
    except Exception as e:
        return {
            'error': str(e),
            'total_chars': 0,
            'total_lines': 0,
            'features': {},
            'estimated_questions': 0,
            'text_preview': ''
        }

def batch_analyze_all_police_exams():
    """æ‰¹é‡åˆ†ææ‰€æœ‰è­¦å¯Ÿç‰¹è€ƒç§‘ç›®"""
    base_dir = "114å¹´è€ƒå¤é¡Œ/æ°‘åœ‹114å¹´/æ°‘åœ‹114å¹´_è­¦å¯Ÿç‰¹è€ƒ"
    
    if not os.path.exists(base_dir):
        print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°ç›®éŒ„ {base_dir}")
        return
    
    results = {}
    total_subjects = 0
    total_questions_estimated = 0
    
    # éæ­·æ‰€æœ‰é¡åˆ¥
    for category in os.listdir(base_dir):
        category_path = os.path.join(base_dir, category)
        if not os.path.isdir(category_path):
            continue
        
        print(f"\n=== åˆ†æé¡åˆ¥: {category} ===")
        results[category] = {}
        
        # éæ­·è©²é¡åˆ¥ä¸‹çš„æ‰€æœ‰ç§‘ç›®
        for subject in os.listdir(category_path):
            subject_path = os.path.join(category_path, subject)
            if not os.path.isdir(subject_path):
                continue
            
            # æŸ¥æ‰¾è©¦é¡ŒPDF
            question_pdf = os.path.join(subject_path, "è©¦é¡Œ.pdf")
            if not os.path.exists(question_pdf):
                print(f"  âš ï¸ {subject}: æœªæ‰¾åˆ°è©¦é¡Œ.pdf")
                continue
            
            print(f"  ğŸ“„ {subject}")
            analysis = analyze_pdf_structure(question_pdf)
            results[category][subject] = analysis
            
            total_subjects += 1
            total_questions_estimated += analysis['estimated_questions']
            
            print(f"    â†’ é ä¼°é¡Œæ•¸: {analysis['estimated_questions']}")
            if 'error' in analysis:
                print(f"    â†’ éŒ¯èª¤: {analysis['error']}")
    
    # ä¿å­˜çµæ§‹åˆ†æçµæœ
    os.makedirs('test_output', exist_ok=True)
    with open('test_output/å…¨éƒ¨è­¦å¯Ÿç‰¹è€ƒ_çµæ§‹åˆ†æ.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    # ç”Ÿæˆçµ±è¨ˆå ±å‘Š
    generate_statistics_report(results, total_subjects, total_questions_estimated)
    
    print(f"\n=== åˆ†æå®Œæˆ ===")
    print(f"ç¸½ç§‘ç›®æ•¸: {total_subjects}")
    print(f"ç¸½é ä¼°é¡Œæ•¸: {total_questions_estimated}")
    print(f"çµæœå·²ä¿å­˜è‡³: test_output/å…¨éƒ¨è­¦å¯Ÿç‰¹è€ƒ_çµæ§‹åˆ†æ.json")

def generate_statistics_report(results, total_subjects, total_questions_estimated):
    """ç”Ÿæˆçµ±è¨ˆå ±å‘Š"""
    report_path = 'test_output/å…¨éƒ¨è­¦å¯Ÿç‰¹è€ƒ_çµ±è¨ˆå ±å‘Š.md'
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("# æ°‘åœ‹114å¹´è­¦å¯Ÿç‰¹è€ƒå…¨é¢çµæ§‹åˆ†æå ±å‘Š\n\n")
        f.write(f"**åˆ†ææ™‚é–“**: {os.popen('date').read().strip()}\n")
        f.write(f"**ç¸½ç§‘ç›®æ•¸**: {total_subjects}\n")
        f.write(f"**ç¸½é ä¼°é¡Œæ•¸**: {total_questions_estimated}\n\n")
        
        f.write("## é¡åˆ¥çµ±è¨ˆ\n\n")
        for category, subjects in results.items():
            f.write(f"### {category}\n\n")
            f.write("| ç§‘ç›® | é ä¼°é¡Œæ•¸ | ç‰¹å¾µ |\n")
            f.write("|------|----------|------|\n")
            
            for subject, analysis in subjects.items():
                features = analysis.get('features', {})
                feature_list = []
                if features.get('has_essay_section'):
                    feature_list.append("ç”³è«–")
                if features.get('has_test_section'):
                    feature_list.append("æ¸¬é©—")
                if features.get('has_composition'):
                    feature_list.append("ä½œæ–‡")
                if features.get('has_question_groups'):
                    feature_list.append("é¡Œçµ„")
                
                feature_str = ", ".join(feature_list) if feature_list else "æœªçŸ¥"
                f.write(f"| {subject} | {analysis['estimated_questions']} | {feature_str} |\n")
            
            f.write("\n")
        
        f.write("## æ ¼å¼ç‰¹å¾µçµ±è¨ˆ\n\n")
        format_stats = {
            'ç”³è«–é¡Œ': 0,
            'æ¸¬é©—é¡Œ': 0,
            'æ··åˆæ ¼å¼': 0,
            'ç¶œåˆæ ¼å¼': 0,
            'æœªçŸ¥æ ¼å¼': 0
        }
        
        for category, subjects in results.items():
            for subject, analysis in subjects.items():
                features = analysis.get('features', {})
                if features.get('has_essay_section') and features.get('has_test_section'):
                    format_stats['ç¶œåˆæ ¼å¼'] += 1
                elif features.get('has_essay_section'):
                    format_stats['ç”³è«–é¡Œ'] += 1
                elif features.get('has_test_section'):
                    format_stats['æ¸¬é©—é¡Œ'] += 1
                elif features.get('has_composition'):
                    format_stats['æ··åˆæ ¼å¼'] += 1
                else:
                    format_stats['æœªçŸ¥æ ¼å¼'] += 1
        
        for format_type, count in format_stats.items():
            f.write(f"- **{format_type}**: {count} ç§‘ç›®\n")
    
    print(f"çµ±è¨ˆå ±å‘Šå·²ä¿å­˜è‡³: {report_path}")

if __name__ == "__main__":
    batch_analyze_all_police_exams()
