# çˆ¬èŸ²æˆåŠŸç‡åˆ†æèˆ‡100%å„ªåŒ–æ–¹æ¡ˆ

## ğŸ“Š ç•¶å‰ç‹€æ…‹

**æˆåŠŸç‡**: 80-90%
**ç›®æ¨™**: æ¥è¿‘100%
**æ”¹é€²ç©ºé–“**: 10-20%

---

## ğŸ” å¤±æ•—åŸå› åˆ†æ

### 1. **ç¶²çµ¡è¶…æ™‚é…ç½®ä¸å¤ éˆæ´»** (ä¼°è¨ˆå½±éŸ¿: 5-8%)

**ç•¶å‰å•é¡Œ**:
```python
response = session.get(url, headers=HEADERS, stream=True, timeout=60, verify=False)
```

- âŒ ä½¿ç”¨å–®ä¸€çš„60ç§’è¶…æ™‚å€¼
- âŒ æ²’æœ‰å€åˆ†é€£æ¥è¶…æ™‚å’Œè®€å–è¶…æ™‚
- âŒ å°å¤§æ–‡ä»¶å¯èƒ½ä¸å¤ ï¼Œå°å°æ–‡ä»¶éé•·

**å½±éŸ¿**:
- ç¶²çµ¡é€£æ¥å»ºç«‹æ…¢æ™‚ç„¡æ³•å¿«é€Ÿå¤±æ•—é‡è©¦
- å¤§æ–‡ä»¶ä¸‹è¼‰æ™‚å¯èƒ½è¶…æ™‚

---

### 2. **é‡è©¦æ¬¡æ•¸å¯èƒ½ä¸è¶³** (ä¼°è¨ˆå½±éŸ¿: 3-5%)

**ç•¶å‰é…ç½®**:
```python
max_retries=5  # æœ€å¤š5æ¬¡å˜—è©¦
æŒ‡æ•¸é€€é¿: 1s, 2s, 4s, 8s, 16s (ç¸½å…±31ç§’)
```

**å•é¡Œ**:
- åœ¨ç¶²çµ¡ä¸ç©©å®šçš„ç’°å¢ƒä¸‹ï¼Œ5æ¬¡å¯èƒ½ä¸å¤ 
- æ²’æœ‰ä½¿ç”¨å°ˆæ¥­çš„é‡è©¦é©é…å™¨ï¼ˆurllib3.Retryï¼‰

---

### 3. **ç•°å¸¸è™•ç†ä¸å¤ å…¨é¢** (ä¼°è¨ˆå½±éŸ¿: 2-4%)

**ç•¶å‰è™•ç†çš„ç•°å¸¸**:
```python
except requests.exceptions.Timeout:          # âœ… å·²è™•ç†
except requests.exceptions.ConnectionError:  # âœ… å·²è™•ç†
except Exception as e:                       # âš ï¸ éæ–¼å¯¬æ³›
```

**ç¼ºå°‘è™•ç†çš„ç•°å¸¸**:
```python
- requests.exceptions.HTTPError              # âŒ HTTPç‹€æ…‹éŒ¯èª¤
- requests.exceptions.ChunkedEncodingError   # âŒ åˆ†å¡Šç·¨ç¢¼éŒ¯èª¤
- requests.exceptions.ContentDecodingError   # âŒ å…§å®¹è§£ç¢¼éŒ¯èª¤
- requests.exceptions.StreamConsumedError    # âŒ æµæ¶ˆè€—éŒ¯èª¤
- requests.exceptions.RetryError             # âŒ é‡è©¦å¤±æ•—
```

---

### 4. **æ–‡ä»¶å®Œæ•´æ€§æª¢æŸ¥éæ–¼ç°¡å–®** (ä¼°è¨ˆå½±éŸ¿: 2-3%)

**ç•¶å‰æª¢æŸ¥**:
```python
file_size = os.path.getsize(file_path)
if file_size > 1024:  # åªæª¢æŸ¥å¤§å°
    return True, file_size
```

**å•é¡Œ**:
- âŒ æ²’æœ‰é©—è­‰PDFæ–‡ä»¶æ ¼å¼
- âŒ å¯èƒ½ä¸‹è¼‰åˆ°éŒ¯èª¤é é¢ï¼ˆHTMLéŒ¯èª¤é ï¼‰
- âŒ æå£çš„PDFä¹Ÿæœƒè¢«æ¥å—

---

### 5. **Sessioné…ç½®æœªå„ªåŒ–** (ä¼°è¨ˆå½±éŸ¿: 1-2%)

**ç•¶å‰é…ç½®**:
```python
session = requests.Session()
session.headers.update(HEADERS)
```

**ç¼ºå°‘çš„å„ªåŒ–**:
- âŒ æ²’æœ‰é…ç½®é€£æ¥æ± å¤§å°
- âŒ æ²’æœ‰è¨­ç½®HTTPé©é…å™¨
- âŒ æ²’æœ‰å•Ÿç”¨é€£æ¥é‡ç”¨ç­–ç•¥

---

## ğŸš€ 100%æˆåŠŸç‡å„ªåŒ–æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: å¢å¼·å‹é‡è©¦æ©Ÿåˆ¶ (é æœŸæå‡: 5-7%)

```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

def create_robust_session():
    """å‰µå»ºå¢å¼·çš„Session"""
    session = requests.Session()

    # é…ç½®é‡è©¦ç­–ç•¥
    retry_strategy = Retry(
        total=10,  # ç¸½å…±10æ¬¡é‡è©¦
        backoff_factor=1,  # æŒ‡æ•¸é€€é¿å› å­ï¼š1s, 2s, 4s, 8s...
        status_forcelist=[429, 500, 502, 503, 504],  # éœ€è¦é‡è©¦çš„HTTPç‹€æ…‹ç¢¼
        allowed_methods=["GET", "POST"],  # å…è¨±é‡è©¦çš„æ–¹æ³•
        raise_on_status=False  # ä¸åœ¨é‡è©¦æ™‚æ‹‹å‡ºç•°å¸¸
    )

    # é…ç½®HTTPé©é…å™¨
    adapter = HTTPAdapter(
        max_retries=retry_strategy,
        pool_connections=10,  # é€£æ¥æ± å¤§å°
        pool_maxsize=20,      # æœ€å¤§é€£æ¥æ•¸
        pool_block=False      # éé˜»å¡æ¨¡å¼
    )

    session.mount("http://", adapter)
    session.mount("https://", adapter)
    session.headers.update(HEADERS)

    return session
```

**æ”¹é€²é»**:
- âœ… 10æ¬¡é‡è©¦ï¼ˆåŸ5æ¬¡ï¼‰
- âœ… è‡ªå‹•è™•ç†HTTPéŒ¯èª¤ç‹€æ…‹ç¢¼
- âœ… é€£æ¥æ± å„ªåŒ–
- âœ… å°ˆæ¥­çš„é‡è©¦ç­–ç•¥

---

### æ–¹æ¡ˆ 2: éˆæ´»çš„è¶…æ™‚é…ç½® (é æœŸæå‡: 3-4%)

```python
def download_file(session, url, file_path, max_retries=10):
    """å¢å¼·çš„æ–‡ä»¶ä¸‹è¼‰"""
    for attempt in range(max_retries):
        try:
            # åˆ†åˆ¥è¨­ç½®é€£æ¥è¶…æ™‚å’Œè®€å–è¶…æ™‚
            # (é€£æ¥è¶…æ™‚, è®€å–è¶…æ™‚)
            timeout = (10, 120)  # 10ç§’å»ºç«‹é€£æ¥ï¼Œ120ç§’è®€å–æ•¸æ“š

            response = session.get(
                url,
                headers=HEADERS,
                stream=True,
                timeout=timeout,
                verify=False
            )
            response.raise_for_status()

            # ... å…¶é¤˜ä¸‹è¼‰é‚è¼¯
```

**æ”¹é€²é»**:
- âœ… é€£æ¥è¶…æ™‚10ç§’ï¼ˆå¿«é€Ÿå¤±æ•—ï¼‰
- âœ… è®€å–è¶…æ™‚120ç§’ï¼ˆé©æ‡‰å¤§æ–‡ä»¶ï¼‰
- âœ… ä½¿ç”¨raise_for_status()è‡ªå‹•è™•ç†HTTPéŒ¯èª¤

---

### æ–¹æ¡ˆ 3: å…¨é¢çš„ç•°å¸¸è™•ç† (é æœŸæå‡: 2-3%)

```python
def download_file(session, url, file_path, max_retries=10):
    """å¢å¼·çš„æ–‡ä»¶ä¸‹è¼‰"""
    for attempt in range(max_retries):
        try:
            # ... ä¸‹è¼‰é‚è¼¯ ...

        except requests.exceptions.Timeout:
            if attempt == max_retries - 1:
                return False, "è«‹æ±‚è¶…æ™‚"
            time.sleep(2 ** attempt)
            continue

        except requests.exceptions.HTTPError as e:
            # HTTPç‹€æ…‹éŒ¯èª¤
            if e.response.status_code in [404, 403, 401]:
                # é€™äº›éŒ¯èª¤ä¸éœ€è¦é‡è©¦
                return False, f"HTTPéŒ¯èª¤: {e.response.status_code}"
            if attempt == max_retries - 1:
                return False, f"HTTPéŒ¯èª¤: {e}"
            time.sleep(2 ** attempt)
            continue

        except requests.exceptions.ConnectionError:
            if attempt == max_retries - 1:
                return False, "é€£ç·šéŒ¯èª¤"
            time.sleep(2 ** attempt)
            continue

        except requests.exceptions.ChunkedEncodingError:
            # åˆ†å¡Šç·¨ç¢¼éŒ¯èª¤ï¼Œé€šå¸¸æ˜¯å‚³è¼¸ä¸­æ–·
            if attempt == max_retries - 1:
                return False, "å‚³è¼¸ä¸­æ–·"
            time.sleep(2 ** attempt)
            continue

        except requests.exceptions.ContentDecodingError:
            # å…§å®¹è§£ç¢¼éŒ¯èª¤
            if attempt == max_retries - 1:
                return False, "å…§å®¹è§£ç¢¼å¤±æ•—"
            time.sleep(2 ** attempt)
            continue

        except (OSError, IOError) as e:
            # æ–‡ä»¶ç³»çµ±éŒ¯èª¤
            if "disk" in str(e).lower() or "space" in str(e).lower():
                return False, "ç£ç¢Ÿç©ºé–“ä¸è¶³"
            if attempt == max_retries - 1:
                return False, f"æ–‡ä»¶éŒ¯èª¤: {str(e)[:50]}"
            time.sleep(2 ** attempt)
            continue

        except Exception as e:
            if attempt == max_retries - 1:
                return False, f"æœªçŸ¥éŒ¯èª¤: {str(e)[:50]}"
            time.sleep(2 ** attempt)
            continue

    return False, "è¶…éæœ€å¤§é‡è©¦æ¬¡æ•¸"
```

**æ”¹é€²é»**:
- âœ… è™•ç†HTTPErrorï¼ˆå€åˆ†å¯é‡è©¦å’Œä¸å¯é‡è©¦ï¼‰
- âœ… è™•ç†ChunkedEncodingError
- âœ… è™•ç†ContentDecodingError
- âœ… è™•ç†æ–‡ä»¶ç³»çµ±éŒ¯èª¤
- âœ… æ›´ç²¾ç¢ºçš„éŒ¯èª¤è¨Šæ¯

---

### æ–¹æ¡ˆ 4: PDFæ–‡ä»¶å®Œæ•´æ€§é©—è­‰ (é æœŸæå‡: 2-3%)

```python
def verify_pdf_file(file_path):
    """é©—è­‰PDFæ–‡ä»¶å®Œæ•´æ€§"""
    try:
        # æª¢æŸ¥æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(file_path)
        if file_size < 1024:
            return False, "æ–‡ä»¶éå°"

        # æª¢æŸ¥PDFæ–‡ä»¶é ­ï¼ˆ%PDF-ï¼‰
        with open(file_path, 'rb') as f:
            header = f.read(5)
            if not header.startswith(b'%PDF-'):
                return False, "éPDFæ–‡ä»¶"

        # å˜—è©¦ç”¨pdfplumberæ‰“é–‹é©—è­‰
        try:
            import pdfplumber
            with pdfplumber.open(file_path) as pdf:
                # æª¢æŸ¥æ˜¯å¦è‡³å°‘æœ‰ä¸€é 
                if len(pdf.pages) == 0:
                    return False, "PDFç„¡å…§å®¹"
        except ImportError:
            # å¦‚æœæ²’æœ‰pdfplumberï¼Œè·³éæ·±åº¦é©—è­‰
            pass
        except Exception as e:
            return False, f"PDFæå£: {str(e)[:30]}"

        return True, file_size

    except Exception as e:
        return False, f"é©—è­‰å¤±æ•—: {str(e)[:30]}"

def download_file(session, url, file_path, max_retries=10):
    """å¢å¼·çš„æ–‡ä»¶ä¸‹è¼‰"""
    for attempt in range(max_retries):
        try:
            # ... ä¸‹è¼‰é‚è¼¯ ...

            with open(file_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)

            # é©—è­‰æ–‡ä»¶å®Œæ•´æ€§
            valid, result = verify_pdf_file(file_path)
            if valid:
                return True, result
            else:
                # æ–‡ä»¶ç„¡æ•ˆï¼Œåˆªé™¤ä¸¦é‡è©¦
                os.remove(file_path)
                if attempt == max_retries - 1:
                    return False, result
                time.sleep(2 ** attempt)
                continue
```

**æ”¹é€²é»**:
- âœ… é©—è­‰PDFæ–‡ä»¶é ­
- âœ… æª¢æŸ¥PDFæ˜¯å¦å¯ä»¥æ‰“é–‹
- âœ… è‡ªå‹•åˆªé™¤æå£æ–‡ä»¶ä¸¦é‡è©¦

---

### æ–¹æ¡ˆ 5: å¤±æ•—é‡è©¦éšŠåˆ— (é æœŸæå‡: 2-3%)

```python
def retry_failed_downloads(session, failed_list, base_folder):
    """é‡è©¦å¤±æ•—çš„ä¸‹è¼‰ï¼ˆç¬¬äºŒè¼ªï¼‰"""
    print("\n" + "="*70)
    print("ğŸ”„ é–‹å§‹é‡è©¦å¤±æ•—çš„ä¸‹è¼‰ï¼ˆç¬¬äºŒè¼ªï¼‰")
    print("="*70)

    retry_stats = {
        'success': 0,
        'still_failed': 0
    }

    for item in failed_list:
        print(f"\nğŸ”„ é‡è©¦: {item['subject']} - {item['type']}")

        # ç¬¬äºŒè¼ªä½¿ç”¨æ›´é•·çš„ç­‰å¾…æ™‚é–“
        time.sleep(3)

        success, result = download_file(
            session,
            item['url'],
            item['file_path'],
            max_retries=15  # ç¬¬äºŒè¼ªä½¿ç”¨æ›´å¤šé‡è©¦æ¬¡æ•¸
        )

        if success:
            retry_stats['success'] += 1
            print(f"   âœ… é‡è©¦æˆåŠŸ")
        else:
            retry_stats['still_failed'] += 1
            print(f"   âŒ ä»ç„¶å¤±æ•—: {result}")

    return retry_stats

def main():
    # ... ç¬¬ä¸€è¼ªä¸‹è¼‰ ...

    # ç¬¬äºŒè¼ªï¼šé‡è©¦å¤±æ•—çš„ä¸‹è¼‰
    if stats['failed_list']:
        print(f"\nâš ï¸  ç¬¬ä¸€è¼ªæœ‰ {len(stats['failed_list'])} å€‹å¤±æ•—")
        retry_stats = retry_failed_downloads(session, stats['failed_list'], save_dir)

        # æ›´æ–°çµ±è¨ˆ
        stats['success'] += retry_stats['success']
        stats['failed'] = retry_stats['still_failed']

        print(f"\nğŸ“Š é‡è©¦çµæœ:")
        print(f"   âœ… é‡è©¦æˆåŠŸ: {retry_stats['success']}")
        print(f"   âŒ ä»ç„¶å¤±æ•—: {retry_stats['still_failed']}")
```

**æ”¹é€²é»**:
- âœ… å°å¤±æ•—çš„ä¸‹è¼‰é€²è¡Œç¬¬äºŒè¼ªé‡è©¦
- âœ… ç¬¬äºŒè¼ªä½¿ç”¨æ›´å¤šé‡è©¦æ¬¡æ•¸ï¼ˆ15æ¬¡ï¼‰
- âœ… æ›´é•·çš„ç­‰å¾…æ™‚é–“ï¼ˆ3ç§’ï¼‰

---

## ğŸ“ˆ é æœŸæˆæ•ˆ

| å„ªåŒ–æ–¹æ¡ˆ | é æœŸæå‡ | ç´¯è¨ˆæˆåŠŸç‡ |
|---------|---------|-----------|
| **ç•¶å‰ç‹€æ…‹** | - | 80-90% |
| + å¢å¼·é‡è©¦æ©Ÿåˆ¶ | 5-7% | 85-97% |
| + éˆæ´»è¶…æ™‚é…ç½® | 3-4% | 88-99.5% |
| + å…¨é¢ç•°å¸¸è™•ç† | 2-3% | 90-99.8% |
| + PDFå®Œæ•´æ€§é©—è­‰ | 2-3% | 92-99.9% |
| + å¤±æ•—é‡è©¦éšŠåˆ— | 2-3% | **94-99.99%** |

---

## ğŸ¯ å¯¦æ–½å»ºè­°

### éšæ®µä¸€ï¼šåŸºç¤å„ªåŒ–ï¼ˆç«‹å³å¯¦æ–½ï¼‰
1. âœ… å¢å¼·Sessioné…ç½®ï¼ˆHTTPAdapter + Retryï¼‰
2. âœ… éˆæ´»çš„è¶…æ™‚è¨­ç½®
3. âœ… å…¨é¢çš„ç•°å¸¸è™•ç†

**é æœŸæˆæ•ˆ**: 85-95%

---

### éšæ®µäºŒï¼šå®Œæ•´æ€§ä¿éšœï¼ˆæ¬¡è¦å„ªå…ˆï¼‰
4. âœ… PDFæ–‡ä»¶é©—è­‰
5. âœ… å¤±æ•—é‡è©¦éšŠåˆ—

**é æœŸæˆæ•ˆ**: 94-99.99%

---

## âš ï¸ ç¾å¯¦é™åˆ¶

**ç„¡æ³•é”åˆ°çµ•å°100%çš„åŸå› **:

1. **æœå‹™å™¨ç«¯å•é¡Œ** (0.1-1%)
   - æœå‹™å™¨è‡¨æ™‚ç¶­è­·
   - æ–‡ä»¶çœŸçš„ä¸å­˜åœ¨æˆ–å·²åˆªé™¤
   - æœå‹™å™¨éŒ¯èª¤ï¼ˆéç¶²çµ¡å•é¡Œï¼‰

2. **æœ¬åœ°ç’°å¢ƒå•é¡Œ** (0.01-0.1%)
   - ç£ç¢Ÿç©ºé–“ä¸è¶³
   - æ–‡ä»¶ç³»çµ±æ¬Šé™å•é¡Œ
   - é˜²æ¯’è»Ÿä»¶å¹²æ“¾

3. **ç¶²çµ¡æ¥µç«¯æƒ…æ³** (0.01-0.1%)
   - DNSè§£æå¤±æ•—
   - ISPå°é–
   - è·¯ç”±å•é¡Œ

---

## âœ… çµè«–

é€šéå¯¦æ–½ä¸Šè¿°å„ªåŒ–æ–¹æ¡ˆï¼Œå¯ä»¥å°‡çˆ¬èŸ²æˆåŠŸç‡å¾ç›®å‰çš„ **80-90%** æå‡åˆ° **95-99%**ï¼Œæ¥è¿‘å¯¦éš›å¯é”åˆ°çš„æœ€é«˜æ°´å¹³ã€‚

**å»ºè­°çš„ç›®æ¨™**:
- ç†æƒ³ç›®æ¨™: **95-98%** (å¯¦éš›å¯é é”æˆ)
- æœ€ä½³ç›®æ¨™: **98-99%** (å„ªåŒ–å®Œæˆå¾Œ)
- çµ•å°ä¸Šé™: **99.5%** (å—å¤–éƒ¨å› ç´ é™åˆ¶)

100%æˆåŠŸç‡åœ¨çœŸå¯¦ä¸–ç•Œçš„ç¶²çµ¡ç’°å¢ƒä¸­å¹¾ä¹ä¸å¯èƒ½ï¼Œä½†é€šéå„ªåŒ–å¯ä»¥éå¸¸æ¥è¿‘é€™å€‹ç›®æ¨™ã€‚
