# API æ–‡æª”

**ç‰ˆæœ¬**: 1.0
**æ—¥æœŸ**: 2025-11-17

---

## ğŸ“š ç›®éŒ„

1. [æ ¸å¿ƒæ¨¡å¡Š API](#æ ¸å¿ƒæ¨¡å¡Š-api)
2. [å·¥å…·æ¨¡å¡Š API](#å·¥å…·æ¨¡å¡Š-api)
3. [è™•ç†å™¨æ¨¡å¡Š API](#è™•ç†å™¨æ¨¡å¡Š-api)
4. [å¿«é€Ÿé–‹å§‹](#å¿«é€Ÿé–‹å§‹)
5. [å¸¸è¦‹ç”¨ä¾‹](#å¸¸è¦‹ç”¨ä¾‹)

---

## æ ¸å¿ƒæ¨¡å¡Š API

### PDFProcessor

PDF è™•ç†å™¨ï¼Œè² è²¬å¾ PDF æ–‡ä»¶æå–æ–‡å­—ã€‚

#### é¡å®šç¾©

```python
from src.core.pdf_processor import PDFProcessor

processor = PDFProcessor()
```

#### æ–¹æ³•

##### `extract_text(pdf_path: str, max_pages: int = 200) -> str`

å¾ PDF æ–‡ä»¶ä¸­æå–æ–‡å­—å…§å®¹ã€‚

**åƒæ•¸:**
- `pdf_path` (str): PDF æ–‡ä»¶è·¯å¾‘
- `max_pages` (int, optional): æœ€å¤§è™•ç†é æ•¸ï¼Œé»˜èª 200

**è¿”å›:**
- `str`: æå–çš„æ–‡å­—å…§å®¹

**ç•°å¸¸:**
- `PDFProcessingError`: PDF è™•ç†å¤±æ•—æ™‚æ‹‹å‡º

**ç¤ºä¾‹:**
```python
processor = PDFProcessor()
text = processor.extract_text("exam.pdf", max_pages=100)
print(f"æå–äº† {len(text)} å€‹å­—ç¬¦")
```

##### `extract_text_from_pages(pdf_path: str, page_numbers: List[int]) -> str`

å¾æŒ‡å®šé é¢æå–æ–‡å­—ã€‚

**åƒæ•¸:**
- `pdf_path` (str): PDF æ–‡ä»¶è·¯å¾‘
- `page_numbers` (List[int]): è¦æå–çš„é ç¢¼åˆ—è¡¨

**è¿”å›:**
- `str`: æå–çš„æ–‡å­—å…§å®¹

**ç¤ºä¾‹:**
```python
text = processor.extract_text_from_pages("exam.pdf", [1, 2, 3])
```

##### `get_page_count(pdf_path: str) -> int`

ç²å– PDF çš„ç¸½é æ•¸ã€‚

**åƒæ•¸:**
- `pdf_path` (str): PDF æ–‡ä»¶è·¯å¾‘

**è¿”å›:**
- `int`: PDF ç¸½é æ•¸

**ç¤ºä¾‹:**
```python
count = processor.get_page_count("exam.pdf")
print(f"PDF å…±æœ‰ {count} é ")
```

---

### QuestionParser

é¡Œç›®è§£æå™¨ï¼Œå¾æ–‡å­—ä¸­è§£æé¡Œç›®å’Œé¸é …ã€‚

#### é¡å®šç¾©

```python
from src.core.question_parser import QuestionParser

parser = QuestionParser()
```

#### æ–¹æ³•

##### `parse_questions(text: str) -> List[Dict[str, Any]]`

è§£ææ–‡å­—ä¸­çš„é¡Œç›®ã€‚

**åƒæ•¸:**
- `text` (str): åŒ…å«é¡Œç›®çš„æ–‡å­—å…§å®¹

**è¿”å›:**
- `List[Dict[str, Any]]`: é¡Œç›®åˆ—è¡¨ï¼Œæ¯å€‹é¡Œç›®åŒ…å«é¡Œè™Ÿã€é¡Œç›®æ–‡å­—ã€é¸é …ç­‰

**ç¤ºä¾‹:**
```python
parser = QuestionParser()
questions = parser.parse_questions(text)

for q in questions:
    print(f"é¡Œè™Ÿ: {q['é¡Œè™Ÿ']}")
    print(f"é¡Œç›®: {q['é¡Œç›®']}")
    print(f"é¸é …: {q['é¸é …']}")
```

---

### ArchaeologyProcessor

è€ƒå¤é¡Œè™•ç†å™¨ï¼Œå®Œæ•´çš„é¡Œç›®è™•ç†æµç¨‹ã€‚

#### é¡å®šç¾©

```python
from src.processors.archaeology_processor import ArchaeologyProcessor

processor = ArchaeologyProcessor()
```

#### æ–¹æ³•

##### `process_pdf(pdf_path: str, answer_pdf_path: Optional[str] = None) -> Dict[str, Any]`

è™•ç†è€ƒå¤é¡Œ PDFã€‚

**åƒæ•¸:**
- `pdf_path` (str): é¡Œç›® PDF è·¯å¾‘
- `answer_pdf_path` (str, optional): ç­”æ¡ˆ PDF è·¯å¾‘

**è¿”å›:**
- `Dict[str, Any]`: è™•ç†çµæœï¼ŒåŒ…å«é¡Œç›®åˆ—è¡¨ã€çµ±è¨ˆä¿¡æ¯ç­‰

**ç¤ºä¾‹:**
```python
processor = ArchaeologyProcessor()
result = processor.process_pdf(
    "exam_questions.pdf",
    answer_pdf_path="exam_answers.pdf"
)

print(f"å…±è§£æ {result['question_count']} é¡Œ")
```

---

## å·¥å…·æ¨¡å¡Š API

### ConcurrentProcessor

ä¸¦ç™¼è™•ç†å™¨ï¼Œæ”¯æŒå¤šç·šç¨‹/å¤šé€²ç¨‹æ‰¹é‡è™•ç†ã€‚

#### é¡å®šç¾©

```python
from src.utils.concurrent_processor import ConcurrentProcessor, ProcessingTask

processor = ConcurrentProcessor(
    max_workers=4,
    use_processes=False
)
```

**åƒæ•¸:**
- `max_workers` (int, optional): æœ€å¤§å·¥ä½œç·šç¨‹/é€²ç¨‹æ•¸ï¼Œé»˜èªç‚º CPU æ ¸å¿ƒæ•¸
- `use_processes` (bool, optional): æ˜¯å¦ä½¿ç”¨å¤šé€²ç¨‹ï¼Œé»˜èª Falseï¼ˆä½¿ç”¨å¤šç·šç¨‹ï¼‰

#### æ–¹æ³•

##### `process_batch(tasks: List[ProcessingTask], processor_func: Callable, fail_fast: bool = False) -> List[ProcessingResult]`

æ‰¹é‡è™•ç†ä»»å‹™ã€‚

**åƒæ•¸:**
- `tasks` (List[ProcessingTask]): ä»»å‹™åˆ—è¡¨
- `processor_func` (Callable): è™•ç†å‡½æ•¸
- `fail_fast` (bool, optional): æ˜¯å¦åœ¨é¦–æ¬¡å¤±æ•—æ™‚åœæ­¢ï¼Œé»˜èª False

**è¿”å›:**
- `List[ProcessingResult]`: è™•ç†çµæœåˆ—è¡¨

**ç¤ºä¾‹:**
```python
from src.utils.concurrent_processor import ConcurrentProcessor, ProcessingTask

def process_pdf(task):
    # è™•ç†é‚è¼¯
    return {"success": True, "data": task.pdf_path}

tasks = [
    ProcessingTask(task_id=1, pdf_path="exam1.pdf"),
    ProcessingTask(task_id=2, pdf_path="exam2.pdf"),
]

processor = ConcurrentProcessor(max_workers=4)
results = processor.process_batch(tasks, process_pdf)

for result in results:
    if result.success:
        print(f"æˆåŠŸ: {result.task_id}")
```

---

### StreamingPDFProcessor

æµå¼ PDF è™•ç†å™¨ï¼Œè¨˜æ†¶é«”é«˜æ•ˆçš„é é¢è™•ç†ã€‚

#### é¡å®šç¾©

```python
from src.utils.streaming_processor import StreamingPDFProcessor, StreamConfig

config = StreamConfig(
    chunk_size=10,
    memory_limit_mb=512
)

processor = StreamingPDFProcessor(config)
```

**é…ç½®åƒæ•¸ (StreamConfig):**
- `chunk_size` (int): æ¯æ¬¡è™•ç†çš„é æ•¸ï¼Œé»˜èª 10
- `memory_limit_mb` (int): è¨˜æ†¶é«”é™åˆ¶ï¼ˆMBï¼‰ï¼Œé»˜èª 512
- `enable_monitoring` (bool): æ˜¯å¦å•Ÿç”¨è¨˜æ†¶é«”ç›£æ§ï¼Œé»˜èª True
- `auto_gc` (bool): æ˜¯å¦è‡ªå‹•åƒåœ¾å›æ”¶ï¼Œé»˜èª True

#### æ–¹æ³•

##### `stream_pages(pdf_path: str, start_page: int = 1, end_page: Optional[int] = None) -> Iterator[PageChunk]`

æµå¼è™•ç† PDF é é¢ï¼ˆç”Ÿæˆå™¨ï¼‰ã€‚

**åƒæ•¸:**
- `pdf_path` (str): PDF æ–‡ä»¶è·¯å¾‘
- `start_page` (int, optional): èµ·å§‹é ç¢¼ï¼Œé»˜èª 1
- `end_page` (int, optional): çµæŸé ç¢¼ï¼Œé»˜èªè™•ç†åˆ°æœ€å¾Œ

**è¿”å›:**
- `Iterator[PageChunk]`: é é¢å€å¡Šè¿­ä»£å™¨

**ç¤ºä¾‹:**
```python
processor = StreamingPDFProcessor()

for chunk in processor.stream_pages("large_exam.pdf"):
    # è™•ç†æ¯å€‹å€å¡Šï¼ˆ10é ï¼‰
    print(f"è™•ç†é é¢ {chunk.pages}")
    questions = extract_questions(chunk.text)
    save_to_db(questions)
    # å€å¡Šè™•ç†å®Œè‡ªå‹•é‡‹æ”¾è¨˜æ†¶é«”
```

##### `process_with_callback(pdf_path: str, callback: Callable, start_page: int = 1, end_page: Optional[int] = None) -> List[Any]`

ä½¿ç”¨å›èª¿å‡½æ•¸è™•ç† PDFã€‚

**åƒæ•¸:**
- `pdf_path` (str): PDF æ–‡ä»¶è·¯å¾‘
- `callback` (Callable): è™•ç†å›èª¿å‡½æ•¸
- `start_page` (int, optional): èµ·å§‹é ç¢¼
- `end_page` (int, optional): çµæŸé ç¢¼

**è¿”å›:**
- `List[Any]`: è™•ç†çµæœåˆ—è¡¨

**ç¤ºä¾‹:**
```python
def process_chunk(chunk):
    return extract_questions(chunk.text)

results = processor.process_with_callback("exam.pdf", process_chunk)
```

---

### PerformanceMonitor

æ€§èƒ½ç›£æ§å™¨ï¼Œæä¾›å®Œæ•´çš„æ€§èƒ½ç›£æ§å’Œåˆ†æã€‚

#### é¡å®šç¾©

```python
from src.utils.performance_monitor import PerformanceMonitor

monitor = PerformanceMonitor()
```

#### è£é£¾å™¨ç”¨æ³•

##### `@monitor.monitor(log_result: bool = True, track_memory: bool = True, track_cpu: bool = True)`

æ€§èƒ½ç›£æ§è£é£¾å™¨ã€‚

**åƒæ•¸:**
- `log_result` (bool): æ˜¯å¦è¨˜éŒ„çµæœï¼Œé»˜èª True
- `track_memory` (bool): æ˜¯å¦è¿½è¹¤è¨˜æ†¶é«”ï¼Œé»˜èª True
- `track_cpu` (bool): æ˜¯å¦è¿½è¹¤ CPUï¼Œé»˜èª True

**ç¤ºä¾‹:**
```python
monitor = PerformanceMonitor()

@monitor.monitor()
def process_file(file_path):
    # è™•ç†é‚è¼¯
    pass

process_file("test.pdf")

# æŸ¥çœ‹çµ±è¨ˆ
stats = monitor.get_function_stats("process_file")
print(f"å¹³å‡è€—æ™‚: {stats['avg_time']:.4f}ç§’")
```

#### æ–¹æ³•

##### `get_function_stats(function_name: str) -> Dict[str, Any]`

ç²å–å‡½æ•¸çµ±è¨ˆä¿¡æ¯ã€‚

**è¿”å›å­—æ®µ:**
- `function_name`: å‡½æ•¸åç¨±
- `call_count`: èª¿ç”¨æ¬¡æ•¸
- `total_time`: ç¸½è€—æ™‚
- `avg_time`: å¹³å‡è€—æ™‚
- `min_time`: æœ€çŸ­è€—æ™‚
- `max_time`: æœ€é•·è€—æ™‚

##### `generate_report(output_file: Optional[str] = None) -> str`

ç”Ÿæˆæ€§èƒ½å ±å‘Šã€‚

**åƒæ•¸:**
- `output_file` (str, optional): è¼¸å‡ºæ–‡ä»¶è·¯å¾‘

**è¿”å›:**
- `str`: å ±å‘Šå…§å®¹

**ç¤ºä¾‹:**
```python
report = monitor.generate_report("performance_report.txt")
print(report)
```

##### `export_metrics(output_file: str)`

å°å‡ºæ€§èƒ½æŒ‡æ¨™åˆ° JSON æ–‡ä»¶ã€‚

**åƒæ•¸:**
- `output_file` (str): è¼¸å‡ºæ–‡ä»¶è·¯å¾‘

**ç¤ºä¾‹:**
```python
monitor.export_metrics("performance_metrics.json")
```

---

### PerformanceTimer

æ€§èƒ½è¨ˆæ™‚å™¨ï¼Œä¸Šä¸‹æ–‡ç®¡ç†å™¨å½¢å¼çš„è¨ˆæ™‚å·¥å…·ã€‚

#### ç”¨æ³•

```python
from src.utils.performance_monitor import PerformanceTimer

with PerformanceTimer("è™•ç†PDF") as timer:
    # åŸ·è¡Œæ“ä½œ
    process_pdf()

print(timer.get_summary())
# è¼¸å‡º: è™•ç†PDF: 2.3456ç§’, è¨˜æ†¶é«”è®ŠåŒ–: +15.23MB
```

#### æ–¹æ³•

##### `get_duration() -> float`

ç²å–æŒçºŒæ™‚é–“ï¼ˆç§’ï¼‰ã€‚

##### `get_memory_delta() -> float`

ç²å–è¨˜æ†¶é«”è®ŠåŒ–ï¼ˆMBï¼‰ã€‚

##### `get_summary() -> str`

ç²å–æ‘˜è¦ä¿¡æ¯ã€‚

---

### RetryHandler

éŒ¯èª¤æ¢å¾©è™•ç†å™¨ï¼Œè‡ªå‹•é‡è©¦å’Œæ–·é»çºŒå‚³ã€‚

#### è£é£¾å™¨ç”¨æ³•

```python
from src.utils.retry_handler import retry_with_backoff

@retry_with_backoff(
    max_retries=3,
    initial_delay=1.0,
    exponential=True,
    exceptions=(IOError, ConnectionError)
)
def process_file(file_path):
    # å¯èƒ½å¤±æ•—çš„æ“ä½œ
    pass
```

**åƒæ•¸:**
- `max_retries` (int): æœ€å¤§é‡è©¦æ¬¡æ•¸ï¼Œé»˜èª 3
- `initial_delay` (float): åˆå§‹å»¶é²ï¼ˆç§’ï¼‰ï¼Œé»˜èª 1.0
- `exponential` (bool): æ˜¯å¦ä½¿ç”¨æŒ‡æ•¸é€€é¿ï¼Œé»˜èª True
- `exceptions` (Tuple): è¦æ•ç²çš„ç•°å¸¸é¡å‹

#### CheckpointManager

æ–·é»ç®¡ç†å™¨ã€‚

```python
from src.utils.retry_handler import CheckpointManager

checkpoint = CheckpointManager("process_checkpoint.json")

# ä¿å­˜æª¢æŸ¥é»
checkpoint.save_checkpoint({
    'completed_tasks': [1, 2, 3],
    'current_task': 4
})

# è¼‰å…¥æª¢æŸ¥é»
data = checkpoint.load_checkpoint()
if data:
    print(f"å¾ä»»å‹™ {data['current_task']} ç¹¼çºŒ")
```

---

### YAMLConfigManager

YAML é…ç½®ç®¡ç†å™¨ã€‚

#### ç”¨æ³•

```python
from src.utils.yaml_config import load_config

# è¼‰å…¥é…ç½®
config = load_config('config.yaml')

# è¨ªå•é…ç½®
dpi = config.ocr.pdf_to_image_dpi
max_workers = config.concurrent.max_workers
```

#### ç’°å¢ƒè®Šæ•¸è¦†è“‹

ä½¿ç”¨ç’°å¢ƒè®Šæ•¸è¦†è“‹é…ç½®ï¼š

```bash
# æ ¼å¼: APP_SECTION_KEY=value
export APP_OCR_PDF_TO_IMAGE_DPI=400
export APP_CONCURRENT_MAX_WORKERS=8
```

---

## è™•ç†å™¨æ¨¡å¡Š API

### è™•ç†å™¨å±¤æ¬¡çµæ§‹

```
ArchaeologyProcessor (ä¸»è™•ç†å™¨)
â”œâ”€â”€ PDFProcessor (PDF è™•ç†)
â”œâ”€â”€ QuestionParser (é¡Œç›®è§£æ)
â”œâ”€â”€ AnswerProcessor (ç­”æ¡ˆè™•ç†)
â””â”€â”€ ScanTracker (æƒæè¿½è¹¤)
```

### å®Œæ•´è™•ç†æµç¨‹

```python
from src.processors.archaeology_processor import ArchaeologyProcessor

# å‰µå»ºè™•ç†å™¨
processor = ArchaeologyProcessor()

# è™•ç†å–®å€‹ PDF
result = processor.process_pdf(
    pdf_path="exam_questions.pdf",
    answer_pdf_path="exam_answers.pdf",
    corrected_answer_pdf_path="corrected_answers.pdf",
    output_dir="output"
)

# æŸ¥çœ‹çµæœ
print(f"é¡Œç›®æ•¸é‡: {result['question_count']}")
print(f"æƒæè¦†è“‹ç‡: {result['scan_coverage']}%")
print(f"è¼¸å‡ºæ–‡ä»¶: {result['output_file']}")
```

---

## å¿«é€Ÿé–‹å§‹

### å®‰è£ä¾è³´

```bash
pip install -r requirements.txt
```

### åŸºæœ¬ä½¿ç”¨

#### 1. è™•ç†å–®å€‹ PDF

```python
from src.processors.archaeology_processor import ArchaeologyProcessor

processor = ArchaeologyProcessor()
result = processor.process_pdf("exam.pdf")
```

#### 2. æ‰¹é‡è™•ç†

```python
from src.utils.concurrent_processor import ConcurrentProcessor, ProcessingTask

def process_pdf(task):
    processor = ArchaeologyProcessor()
    return processor.process_pdf(task.pdf_path)

tasks = [
    ProcessingTask(task_id=1, pdf_path="exam1.pdf"),
    ProcessingTask(task_id=2, pdf_path="exam2.pdf"),
]

concurrent = ConcurrentProcessor(max_workers=4)
results = concurrent.process_batch(tasks, process_pdf)
```

#### 3. æµå¼è™•ç†å¤§æ–‡ä»¶

```python
from src.utils.streaming_processor import StreamingPDFProcessor

processor = StreamingPDFProcessor()

for chunk in processor.stream_pages("large_exam.pdf"):
    # è™•ç†æ¯å€‹å€å¡Š
    process_chunk(chunk.text)
```

#### 4. æ€§èƒ½ç›£æ§

```python
from src.utils.performance_monitor import monitor_performance

@monitor_performance
def process_file(file_path):
    # è™•ç†é‚è¼¯
    pass

# è‡ªå‹•è¨˜éŒ„æ€§èƒ½
process_file("exam.pdf")
```

---

## å¸¸è¦‹ç”¨ä¾‹

### ç”¨ä¾‹ 1: å®Œæ•´çš„è€ƒå¤é¡Œè™•ç†æµç¨‹

```python
from src.processors.archaeology_processor import ArchaeologyProcessor
from src.utils.performance_monitor import monitor_performance
from src.utils.retry_handler import retry_with_backoff

@monitor_performance
@retry_with_backoff(max_retries=3)
def process_exam(pdf_path, answer_path):
    processor = ArchaeologyProcessor()
    return processor.process_pdf(
        pdf_path=pdf_path,
        answer_pdf_path=answer_path,
        output_dir="output"
    )

# è™•ç†
result = process_exam("exam.pdf", "answers.pdf")
```

### ç”¨ä¾‹ 2: æ‰¹é‡è™•ç† + éŒ¯èª¤æ¢å¾©

```python
from src.utils.concurrent_processor import ConcurrentProcessor
from src.utils.retry_handler import CheckpointManager, ErrorRecovery

# è¨­ç½®æ–·é»ç®¡ç†
checkpoint = CheckpointManager("batch_checkpoint.json")

# è¼‰å…¥é€²åº¦
data = checkpoint.load_checkpoint()
completed = data.get('completed', []) if data else []

# éæ¿¾å·²å®Œæˆçš„ä»»å‹™
tasks = [t for t in all_tasks if t.task_id not in completed]

# ä¸¦ç™¼è™•ç†
processor = ConcurrentProcessor(max_workers=4)
results = processor.process_batch(tasks, process_func)

# æ›´æ–°æª¢æŸ¥é»
completed.extend([r.task_id for r in results if r.success])
checkpoint.save_checkpoint({'completed': completed})
```

### ç”¨ä¾‹ 3: è¨˜æ†¶é«”é«˜æ•ˆè™•ç† + æ€§èƒ½ç›£æ§

```python
from src.utils.streaming_processor import StreamingPDFProcessor
from src.utils.performance_monitor import PerformanceTimer

processor = StreamingPDFProcessor()

with PerformanceTimer("å®Œæ•´è™•ç†") as timer:
    for chunk in processor.stream_pages("huge_exam.pdf"):
        # è™•ç†å€å¡Š
        questions = extract_questions(chunk.text)
        save_to_db(questions)

print(timer.get_summary())
```

### ç”¨ä¾‹ 4: è‡ªå®šç¾©é…ç½®

```python
from src.utils.yaml_config import load_config
from src.processors.archaeology_processor import ArchaeologyProcessor

# è¼‰å…¥è‡ªå®šç¾©é…ç½®
config = load_config('custom_config.yaml')

# ä½¿ç”¨é…ç½®
processor = ArchaeologyProcessor()
processor.config = config

# è™•ç†
result = processor.process_pdf("exam.pdf")
```

---

## ç•°å¸¸è™•ç†

### å¸¸è¦‹ç•°å¸¸

| ç•°å¸¸é¡å‹ | èªªæ˜ | è™•ç†æ–¹å¼ |
|---------|------|---------|
| `PDFProcessingError` | PDF è™•ç†å¤±æ•— | æª¢æŸ¥æ–‡ä»¶è·¯å¾‘å’Œæ ¼å¼ |
| `QuestionParsingError` | é¡Œç›®è§£æå¤±æ•— | æª¢æŸ¥æ–‡å­—æ ¼å¼ |
| `ConfigurationError` | é…ç½®éŒ¯èª¤ | æª¢æŸ¥é…ç½®æ–‡ä»¶ |

### ç¤ºä¾‹

```python
from src.utils.exceptions import PDFProcessingError

try:
    text = processor.extract_text("exam.pdf")
except PDFProcessingError as e:
    print(f"è™•ç†å¤±æ•—: {e}")
    # éŒ¯èª¤è™•ç†é‚è¼¯
```

---

## æœ€ä½³å¯¦è¸

### 1. ä½¿ç”¨ä¸¦ç™¼è™•ç†æé«˜æ•ˆç‡

```python
# âœ… å¥½
concurrent = ConcurrentProcessor(max_workers=4)
results = concurrent.process_batch(tasks, process_func)

# âŒ é¿å…
for task in tasks:
    result = process_func(task)  # ä¸²è¡Œè™•ç†
```

### 2. è™•ç†å¤§æ–‡ä»¶ä½¿ç”¨æµå¼è™•ç†

```python
# âœ… å¥½ - è¨˜æ†¶é«”ç©©å®š
for chunk in processor.stream_pages("large.pdf"):
    process(chunk)

# âŒ é¿å… - è¨˜æ†¶é«”çˆ†ç‚¸
text = processor.extract_text("large.pdf")  # ä¸€æ¬¡æ€§è¼‰å…¥
```

### 3. å•Ÿç”¨æ€§èƒ½ç›£æ§

```python
# âœ… å¥½ - å¯è§€æ¸¬
@monitor_performance
def critical_function():
    pass

# âŒ é¿å… - ç„¡æ³•è¿½è¹¤æ€§èƒ½
def critical_function():
    pass
```

### 4. ä½¿ç”¨è‡ªå‹•é‡è©¦

```python
# âœ… å¥½ - è‡ªå‹•æ¢å¾©
@retry_with_backoff(max_retries=3)
def process_file(path):
    pass

# âŒ é¿å… - æ‰‹å‹•é‡è©¦
def process_file(path):
    for i in range(3):
        try:
            # è™•ç†
            break
        except:
            continue
```

---

## ç‰ˆæœ¬æ­·å²

| ç‰ˆæœ¬ | æ—¥æœŸ | æ›´æ–°å…§å®¹ |
|-----|------|---------|
| 1.0 | 2025-11-17 | åˆå§‹ç‰ˆæœ¬ï¼Œå®Œæ•´ API æ–‡æª” |

---

## ç›¸é—œè³‡æº

- [æ”¹é€²ç¸½çµå ±å‘Š](../IMPROVEMENTS_SUMMARY.md)
- [æ¸¬è©¦è¦†è“‹å ±å‘Š](TEST_COVERAGE_REPORT.md)
- [å¿«é€Ÿé–‹å§‹æŒ‡å—](QUICK_START.md)
- [è²¢ç»æŒ‡å—](CONTRIBUTING.md)

---

**æ–‡æª”å®Œæˆ**
å¦‚æœ‰å•é¡Œæˆ–å»ºè­°ï¼Œè«‹æäº¤ Issueã€‚
