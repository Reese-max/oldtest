# å¿«é€Ÿé–‹å§‹æŒ‡å—

æ­¡è¿ä½¿ç”¨è€ƒå¤é¡Œè™•ç†ç³»çµ±ï¼æœ¬æŒ‡å—å°‡å¹«åŠ©æ‚¨å¿«é€Ÿä¸Šæ‰‹ã€‚

---

## ğŸ“‹ ç›®éŒ„

1. [ç³»çµ±è¦æ±‚](#ç³»çµ±è¦æ±‚)
2. [å®‰è£](#å®‰è£)
3. [åŸºæœ¬ä½¿ç”¨](#åŸºæœ¬ä½¿ç”¨)
4. [é€²éšåŠŸèƒ½](#é€²éšåŠŸèƒ½)
5. [å¸¸è¦‹å•é¡Œ](#å¸¸è¦‹å•é¡Œ)

---

## ç³»çµ±è¦æ±‚

- **Python**: 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬
- **ä½œæ¥­ç³»çµ±**: Windows / Linux / macOS
- **è¨˜æ†¶é«”**: å»ºè­° 4GB ä»¥ä¸Š
- **ç£ç›¤ç©ºé–“**: 100MBï¼ˆä¸å« PDF æ–‡ä»¶ï¼‰

---

## å®‰è£

### 1. å…‹éš†é …ç›®

```bash
git clone https://github.com/your-repo/oldtest.git
cd oldtest
```

### 2. å®‰è£ä¾è³´

```bash
pip install -r requirements.txt
```

### 3. é©—è­‰å®‰è£

```bash
python -m unittest discover tests
```

---

## åŸºæœ¬ä½¿ç”¨

### å ´æ™¯ 1: è™•ç†å–®å€‹ PDF

æœ€åŸºæœ¬çš„ä½¿ç”¨æ–¹å¼ï¼š

```python
from src.processors.archaeology_processor import ArchaeologyProcessor

# å‰µå»ºè™•ç†å™¨
processor = ArchaeologyProcessor()

# è™•ç† PDF
result = processor.process_pdf("exam_questions.pdf")

# æŸ¥çœ‹çµæœ
print(f"âœ… æˆåŠŸè™•ç† {result['question_count']} é¡Œ")
print(f"ğŸ“„ è¼¸å‡ºæ–‡ä»¶: {result['output_file']}")
```

**è¼¸å‡ºç¤ºä¾‹:**
```
âœ… æˆåŠŸè™•ç† 60 é¡Œ
ğŸ“„ è¼¸å‡ºæ–‡ä»¶: output/exam_questions.csv
```

---

### å ´æ™¯ 2: è™•ç†é¡Œç›® + ç­”æ¡ˆ

å¦‚æœæœ‰ç­”æ¡ˆ PDFï¼š

```python
processor = ArchaeologyProcessor()

result = processor.process_pdf(
    pdf_path="exam_questions.pdf",
    answer_pdf_path="exam_answers.pdf"
)

print(f"âœ… è™•ç†å®Œæˆï¼Œå…± {result['question_count']} é¡Œ")
```

---

### å ´æ™¯ 3: æ‰¹é‡è™•ç†å¤šå€‹ PDF

è™•ç†å¤šå€‹æ–‡ä»¶ï¼š

```python
from src.utils.concurrent_processor import ConcurrentProcessor, ProcessingTask
from src.processors.archaeology_processor import ArchaeologyProcessor

# å®šç¾©è™•ç†å‡½æ•¸
def process_exam(task):
    processor = ArchaeologyProcessor()
    return processor.process_pdf(task.pdf_path)

# æº–å‚™ä»»å‹™
tasks = [
    ProcessingTask(task_id=1, pdf_path="exam1.pdf"),
    ProcessingTask(task_id=2, pdf_path="exam2.pdf"),
    ProcessingTask(task_id=3, pdf_path="exam3.pdf"),
]

# ä¸¦ç™¼è™•ç†ï¼ˆ4å€‹å·¥ä½œç·šç¨‹ï¼‰
concurrent = ConcurrentProcessor(max_workers=4)
results = concurrent.process_batch(tasks, process_exam)

# çµ±è¨ˆçµæœ
successful = [r for r in results if r.success]
print(f"âœ… æˆåŠŸ: {len(successful)}/{len(results)}")
```

**å„ªå‹¢:**
- ğŸš€ é€Ÿåº¦æå‡ 3-4 å€
- âš¡ è‡ªå‹•ä¸¦ç™¼è™•ç†
- ğŸ“Š å¯¦æ™‚é€²åº¦é¡¯ç¤º

---

### å ´æ™¯ 4: è™•ç†è¶…å¤§ PDFï¼ˆè¨˜æ†¶é«”å„ªåŒ–ï¼‰

è™•ç† 1000+ é çš„å¤§æ–‡ä»¶ï¼š

```python
from src.utils.streaming_processor import StreamingPDFProcessor

# å‰µå»ºæµå¼è™•ç†å™¨
processor = StreamingPDFProcessor()

# é€å€å¡Šè™•ç†ï¼ˆæ¯æ¬¡ 10 é ï¼‰
for chunk in processor.stream_pages("huge_exam.pdf"):
    print(f"è™•ç†é é¢ {chunk.pages}")

    # æå–é¡Œç›®
    questions = extract_questions(chunk.text)

    # ä¿å­˜åˆ°è³‡æ–™åº«
    save_to_database(questions)

print("âœ… å¤§æ–‡ä»¶è™•ç†å®Œæˆï¼")
```

**å„ªå‹¢:**
- ğŸ’¾ è¨˜æ†¶é«”ä½¿ç”¨é™ä½ 10 å€ä»¥ä¸Š
- ğŸ“ˆ å¯è™•ç† 10000+ é  PDF
- ğŸ”„ è‡ªå‹•è¨˜æ†¶é«”ç®¡ç†

---

## é€²éšåŠŸèƒ½

### åŠŸèƒ½ 1: æ€§èƒ½ç›£æ§

ç›£æ§è™•ç†æ€§èƒ½ï¼š

```python
from src.utils.performance_monitor import monitor_performance, get_global_report

@monitor_performance
def process_file(pdf_path):
    processor = ArchaeologyProcessor()
    return processor.process_pdf(pdf_path)

# è™•ç†æ–‡ä»¶
result = process_file("exam.pdf")

# æŸ¥çœ‹æ€§èƒ½å ±å‘Š
report = get_global_report()
print(report)
```

**å ±å‘Šç¤ºä¾‹:**
```
================================================================================
æ€§èƒ½ç›£æ§å ±å‘Š
================================================================================

## ç¸½é«”çµ±è¨ˆ
ç¸½è¨˜éŒ„æ•¸: 1
ç¸½è€—æ™‚: 2.3456ç§’
å¹³å‡CPU: 45.2%

## å‡½æ•¸çµ±è¨ˆ

### process_file
  èª¿ç”¨æ¬¡æ•¸: 1
  ç¸½è€—æ™‚: 2.3456ç§’
  å¹³å‡è€—æ™‚: 2.3456ç§’
```

---

### åŠŸèƒ½ 2: è‡ªå‹•éŒ¯èª¤æ¢å¾©

è™•ç†å¯èƒ½å¤±æ•—çš„ä»»å‹™ï¼š

```python
from src.utils.retry_handler import retry_with_backoff

@retry_with_backoff(max_retries=3, initial_delay=1.0)
def process_unreliable_pdf(pdf_path):
    # å¯èƒ½æœƒå¤±æ•—çš„è™•ç†
    return processor.process_pdf(pdf_path)

# è‡ªå‹•é‡è©¦æœ€å¤š 3 æ¬¡
result = process_unreliable_pdf("exam.pdf")
```

**ç‰¹é»:**
- ğŸ”„ è‡ªå‹•é‡è©¦
- â° æŒ‡æ•¸é€€é¿
- ğŸ“ éŒ¯èª¤è¨˜éŒ„

---

### åŠŸèƒ½ 3: æ–·é»çºŒå‚³

è™•ç†å¤§æ‰¹é‡ä»»å‹™æ™‚ä¿å­˜é€²åº¦ï¼š

```python
from src.utils.retry_handler import CheckpointManager

checkpoint = CheckpointManager("batch_progress.json")

# è¼‰å…¥ä¹‹å‰çš„é€²åº¦
data = checkpoint.load_checkpoint()
completed = data.get('completed', []) if data else []

# åªè™•ç†æœªå®Œæˆçš„ä»»å‹™
pending_tasks = [t for t in all_tasks if t.id not in completed]

# è™•ç†ä»»å‹™
for task in pending_tasks:
    result = process_task(task)
    if result.success:
        completed.append(task.id)
        # ä¿å­˜é€²åº¦
        checkpoint.save_checkpoint({'completed': completed})

print(f"âœ… å®Œæˆ {len(completed)} å€‹ä»»å‹™")
```

---

### åŠŸèƒ½ 4: è‡ªå®šç¾©é…ç½®

ä½¿ç”¨é…ç½®æ–‡ä»¶è‡ªå®šç¾©è¡Œç‚ºï¼š

#### config.yaml
```yaml
processing:
  max_pages: 200
  output_encoding: utf-8-sig

ocr:
  pdf_to_image_dpi: 300
  use_gpu: false

concurrent:
  max_workers: 4
  use_processes: false
```

#### ä½¿ç”¨é…ç½®
```python
from src.utils.yaml_config import load_config

# è¼‰å…¥é…ç½®
config = load_config('config.yaml')

# ä½¿ç”¨é…ç½®
max_pages = config.processing.max_pages
dpi = config.ocr.pdf_to_image_dpi
```

---

## å¸¸è¦‹å•é¡Œ

### Q1: PDF è™•ç†å¤±æ•—æ€éº¼è¾¦ï¼Ÿ

**A:** æª¢æŸ¥ä»¥ä¸‹å¹¾é»ï¼š
1. ç¢ºèª PDF æ–‡ä»¶å­˜åœ¨ä¸”å¯è®€
2. æª¢æŸ¥ PDF æ˜¯å¦åŠ å¯†
3. ç¢ºèªæ–‡ä»¶æ ¼å¼æ­£ç¢ºï¼ˆéæƒæç‰ˆï¼‰
4. æŸ¥çœ‹æ—¥èªŒäº†è§£å…·é«”éŒ¯èª¤

```python
import logging
logging.basicConfig(level=logging.DEBUG)

# å†æ¬¡è™•ç†ï¼ŒæŸ¥çœ‹è©³ç´°æ—¥èªŒ
result = processor.process_pdf("exam.pdf")
```

---

### Q2: è¨˜æ†¶é«”ä¸è¶³æ€éº¼è¾¦ï¼Ÿ

**A:** ä½¿ç”¨æµå¼è™•ç†ï¼š

```python
# æ”¹ç”¨æµå¼è™•ç†å™¨
from src.utils.streaming_processor import StreamingPDFProcessor

processor = StreamingPDFProcessor()
for chunk in processor.stream_pages("large.pdf"):
    process(chunk)  # é€å€å¡Šè™•ç†ï¼Œè¨˜æ†¶é«”ç©©å®š
```

---

### Q3: è™•ç†é€Ÿåº¦å¤ªæ…¢æ€éº¼è¾¦ï¼Ÿ

**A:** å•Ÿç”¨ä¸¦ç™¼è™•ç†ï¼š

```python
# ä½¿ç”¨ä¸¦ç™¼è™•ç†å™¨
from src.utils.concurrent_processor import ConcurrentProcessor

concurrent = ConcurrentProcessor(max_workers=8)  # å¢åŠ å·¥ä½œç·šç¨‹
results = concurrent.process_batch(tasks, process_func)
```

---

### Q4: å¦‚ä½•æŸ¥çœ‹è™•ç†é€²åº¦ï¼Ÿ

**A:** ä½¿ç”¨é€²åº¦è¿½è¹¤ï¼š

```python
from src.utils.concurrent_processor import ConcurrentProcessor

processor = ConcurrentProcessor(max_workers=4)

# è‡ªå‹•é¡¯ç¤ºé€²åº¦
results = processor.process_batch(
    tasks,
    process_func,
    progress_callback=lambda i, total: print(f"é€²åº¦: {i}/{total}")
)
```

---

### Q5: å¦‚ä½•æå–ç‰¹å®šé é¢ï¼Ÿ

**A:** ä½¿ç”¨é é¢ç¯„åœåƒæ•¸ï¼š

```python
from src.core.pdf_processor import PDFProcessor

processor = PDFProcessor()

# åªæå–ç¬¬ 10-20 é 
text = processor.extract_text_from_pages("exam.pdf", list(range(10, 21)))
```

---

### Q6: æ”¯æŒå“ªäº› PDF æ ¼å¼ï¼Ÿ

**A:** æ”¯æŒï¼š
- âœ… æ¨™æº– PDFï¼ˆæ–‡å­—å‹ï¼‰
- âœ… æƒæ PDFï¼ˆéœ€è¦ OCRï¼Œä½¿ç”¨ PaddleOCRï¼‰
- âœ… æ··åˆæ ¼å¼ PDF
- âŒ åŠ å¯† PDFï¼ˆéœ€å…ˆè§£å¯†ï¼‰

---

### Q7: å¦‚ä½•å°å‡ºå…¶ä»–æ ¼å¼ï¼Ÿ

**A:** é»˜èªå°å‡º CSVï¼Œå¯è‡ªå®šç¾©ï¼š

```python
import pandas as pd

# è®€å– CSV
df = pd.read_csv("output.csv")

# è½‰æ›æ ¼å¼
df.to_excel("output.xlsx", index=False)  # Excel
df.to_json("output.json", orient='records')  # JSON
```

---

## ğŸ“š ä¸‹ä¸€æ­¥

- é–±è®€ [API æ–‡æª”](API_DOCUMENTATION.md) äº†è§£è©³ç´°åŠŸèƒ½
- æŸ¥çœ‹ [ç¤ºä¾‹ä»£ç¢¼](../examples/) å­¸ç¿’æ›´å¤šç”¨æ³•
- é–±è®€ [æ”¹é€²ç¸½çµ](../IMPROVEMENTS_SUMMARY.md) äº†è§£ç³»çµ±ç‰¹æ€§

---

## ğŸ†˜ ç²å–å¹«åŠ©

é‡åˆ°å•é¡Œï¼Ÿ

1. æŸ¥çœ‹ [å¸¸è¦‹å•é¡Œ](#å¸¸è¦‹å•é¡Œ)
2. é–±è®€ [API æ–‡æª”](API_DOCUMENTATION.md)
3. æŸ¥çœ‹ [ç¤ºä¾‹ä»£ç¢¼](../examples/)
4. æäº¤ Issue

---

## ğŸ¯ å¿«é€Ÿåƒè€ƒ

### å‘½ä»¤é€ŸæŸ¥

```bash
# é‹è¡Œæ¸¬è©¦
python -m unittest discover tests

# é‹è¡Œç‰¹å®šæ¸¬è©¦
python -m unittest tests.test_concurrent_processor

# æŸ¥çœ‹æ€§èƒ½å ±å‘Š
python examples/performance_monitoring_example.py

# é‹è¡Œä¸¦ç™¼ç¤ºä¾‹
python examples/concurrent_processing_example.py
```

### å¸¸ç”¨ä»£ç¢¼ç‰‡æ®µ

```python
# åŸºæœ¬è™•ç†
from src.processors.archaeology_processor import ArchaeologyProcessor
processor = ArchaeologyProcessor()
result = processor.process_pdf("exam.pdf")

# ä¸¦ç™¼è™•ç†
from src.utils.concurrent_processor import ConcurrentProcessor
concurrent = ConcurrentProcessor(max_workers=4)
results = concurrent.process_batch(tasks, process_func)

# æµå¼è™•ç†
from src.utils.streaming_processor import StreamingPDFProcessor
processor = StreamingPDFProcessor()
for chunk in processor.stream_pages("large.pdf"):
    process(chunk)

# æ€§èƒ½ç›£æ§
from src.utils.performance_monitor import monitor_performance
@monitor_performance
def my_function():
    pass
```

---

**ç¥ä½¿ç”¨æ„‰å¿«ï¼** ğŸ‰
